{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import BatchNormalization, Input, Dense, Reshape,Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\ismail\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement keras.optimizers.Adam (from versions: none)\n",
      "ERROR: No matching distribution found for keras.optimizers.Adam\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\ismail\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install keras.optimizers.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim: int):\n",
    "    model = Sequential([Dense(128, input_dim=latent_dim),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    BatchNormalization(momentum=0.8),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    BatchNormalization(momentum=0.8),\n",
    "    Dense(512),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    BatchNormalization(momentum=0.8),\n",
    "    Dense(np.prod((28, 28, 1)), activation='tanh'),\n",
    "    # reshape to MNIST image size\n",
    "    Reshape((28, 28, 1))\n",
    "    ])\n",
    "    model.summary()\n",
    "    #the latent input vector z\n",
    "    z=Input(shape=(latent_dim,))\n",
    "    generated = model(z)\n",
    "    return Model(z,generated)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Build discriminator network\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(128),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "    ], name='discriminator')\n",
    "    model.summary()\n",
    "    image = Input(shape=(28, 28, 1))\n",
    "    output = model(image)\n",
    "    return Model(image, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, combined, steps, batch_size):\n",
    "    \"\"\"\n",
    "    Train the GAN system\n",
    "    :param generator: generator\n",
    "    :param discriminator: discriminator\n",
    "    :param combined: stacked generator and discriminator\n",
    "    we'll use the combined network when we train the generator\n",
    "    :param steps: number of alternating steps for training\n",
    "    :param batch_size: size of the minibatch\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    (x_train, _), _ = mnist.load_data()\n",
    "    # Rescale in [-1, 1] interval\n",
    "    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
    "    x_train = np.expand_dims(x_train, axis=-1)\n",
    "    # Discriminator ground truths\n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    latent_dim = generator.input_shape[1]\n",
    "    for step in range(steps):\n",
    "        # Train the discriminator\n",
    "        # Select a random batch of images\n",
    "        real_images = x_train[np.random.randint(0,\n",
    "        x_train.shape[0], batch_size)]\n",
    "        # Random batch of noise\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        # Generate a batch of new images\n",
    "        generated_images = generator.predict(noise)\n",
    "        # Train the discriminator\n",
    "        discriminator_real_loss =discriminator.train_on_batch(real_images, real)\n",
    "        discriminator_fake_loss =discriminator.train_on_batch(generated_images, fake)\n",
    "        discriminator_loss = 0.5 * np.add(discriminator_real_loss,discriminator_fake_loss)\n",
    "        # Train the generator\n",
    "        # random latent vector z\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        # Train the generator\n",
    "        # Note that we use the \"valid\" labels for the generate images\n",
    "        # That's because we try to maximize the discriminator loss\n",
    "        generator_loss = combined.train_on_batch(noise, real)\n",
    "        # Display progress\n",
    "        print(\"%d [Discriminator loss: %.4f%%, acc.: %.2f%%][Generator loss: %.4f%%]\" %\n",
    "        (step, discriminator_loss[0], 100 *\n",
    "        discriminator_loss[1], generator_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(generator):\n",
    "    \"\"\"\n",
    "    Display a nxn 2D manifold of digits\n",
    "    :param generator: the generator\n",
    "    \"\"\"\n",
    "    n = 10\n",
    "    digit_size = 28\n",
    "    # big array containing all images\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    latent_dim = generator.input_shape[1]\n",
    "    # n*n random latent distributions\n",
    "    noise = np.random.normal(0, 1, (n * n, latent_dim))\n",
    "    # generate the images\n",
    "    generated_images = generator.predict(noise)\n",
    "    # fill the big array with images\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            slice_i = slice(i * digit_size, (i + 1) * digit_size)\n",
    "            slice_j = slice(j * digit_size, (j + 1) * digit_size)\n",
    "            figure[slice_i, slice_j] =np.reshape(generated_images[i * n + j], (28, 28))\n",
    "    # plot the results\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 256)               200960    \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 233,985\n",
      "Trainable params: 233,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 784)               402192    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 578,704\n",
      "Trainable params: 576,912\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "0 [Discriminator loss: 0.8534%, acc.: 28.12%][Generator loss: 0.6711%]\n",
      "1 [Discriminator loss: 0.5484%, acc.: 51.17%][Generator loss: 0.6683%]\n",
      "2 [Discriminator loss: 0.4220%, acc.: 62.11%][Generator loss: 0.5439%]\n",
      "3 [Discriminator loss: 0.4712%, acc.: 55.47%][Generator loss: 0.6031%]\n",
      "4 [Discriminator loss: 0.5122%, acc.: 54.30%][Generator loss: 0.7385%]\n",
      "5 [Discriminator loss: 0.4171%, acc.: 65.23%][Generator loss: 1.1193%]\n",
      "6 [Discriminator loss: 0.4131%, acc.: 73.44%][Generator loss: 1.3913%]\n",
      "7 [Discriminator loss: 0.3458%, acc.: 78.91%][Generator loss: 1.6988%]\n",
      "8 [Discriminator loss: 0.2273%, acc.: 91.80%][Generator loss: 2.0116%]\n",
      "9 [Discriminator loss: 0.1527%, acc.: 99.61%][Generator loss: 2.1031%]\n",
      "10 [Discriminator loss: 0.1195%, acc.: 100.00%][Generator loss: 2.3952%]\n",
      "11 [Discriminator loss: 0.1107%, acc.: 100.00%][Generator loss: 2.6499%]\n",
      "12 [Discriminator loss: 0.1130%, acc.: 98.83%][Generator loss: 2.8969%]\n",
      "13 [Discriminator loss: 0.0986%, acc.: 99.22%][Generator loss: 3.0496%]\n",
      "14 [Discriminator loss: 0.0600%, acc.: 100.00%][Generator loss: 3.0478%]\n",
      "15 [Discriminator loss: 0.0685%, acc.: 100.00%][Generator loss: 3.3684%]\n",
      "16 [Discriminator loss: 0.0530%, acc.: 100.00%][Generator loss: 3.3968%]\n",
      "17 [Discriminator loss: 0.0417%, acc.: 100.00%][Generator loss: 3.5443%]\n",
      "18 [Discriminator loss: 0.0517%, acc.: 100.00%][Generator loss: 3.6786%]\n",
      "19 [Discriminator loss: 0.0715%, acc.: 98.83%][Generator loss: 3.9591%]\n",
      "20 [Discriminator loss: 0.0300%, acc.: 100.00%][Generator loss: 3.9212%]\n",
      "21 [Discriminator loss: 0.0339%, acc.: 100.00%][Generator loss: 4.0152%]\n",
      "22 [Discriminator loss: 0.0394%, acc.: 100.00%][Generator loss: 4.2325%]\n",
      "23 [Discriminator loss: 0.1959%, acc.: 88.67%][Generator loss: 4.2337%]\n",
      "24 [Discriminator loss: 0.0341%, acc.: 100.00%][Generator loss: 4.1466%]\n",
      "25 [Discriminator loss: 0.0277%, acc.: 100.00%][Generator loss: 4.0752%]\n",
      "26 [Discriminator loss: 0.0268%, acc.: 100.00%][Generator loss: 4.2653%]\n",
      "27 [Discriminator loss: 0.0333%, acc.: 100.00%][Generator loss: 4.5609%]\n",
      "28 [Discriminator loss: 0.1245%, acc.: 95.31%][Generator loss: 5.2637%]\n",
      "29 [Discriminator loss: 0.8144%, acc.: 76.56%][Generator loss: 4.8313%]\n",
      "30 [Discriminator loss: 0.3295%, acc.: 80.47%][Generator loss: 3.7353%]\n",
      "31 [Discriminator loss: 0.0783%, acc.: 96.48%][Generator loss: 3.3277%]\n",
      "32 [Discriminator loss: 0.0724%, acc.: 98.83%][Generator loss: 3.2607%]\n",
      "33 [Discriminator loss: 0.0562%, acc.: 99.61%][Generator loss: 3.2695%]\n",
      "34 [Discriminator loss: 0.0581%, acc.: 99.61%][Generator loss: 3.4052%]\n",
      "35 [Discriminator loss: 0.0644%, acc.: 99.22%][Generator loss: 3.5731%]\n",
      "36 [Discriminator loss: 0.0474%, acc.: 100.00%][Generator loss: 3.6424%]\n",
      "37 [Discriminator loss: 0.0495%, acc.: 99.61%][Generator loss: 3.8768%]\n",
      "38 [Discriminator loss: 0.0614%, acc.: 99.61%][Generator loss: 3.9641%]\n",
      "39 [Discriminator loss: 0.0557%, acc.: 100.00%][Generator loss: 4.3013%]\n",
      "40 [Discriminator loss: 0.0924%, acc.: 97.66%][Generator loss: 4.4720%]\n",
      "41 [Discriminator loss: 0.1063%, acc.: 96.48%][Generator loss: 4.4655%]\n",
      "42 [Discriminator loss: 0.0934%, acc.: 97.66%][Generator loss: 5.2883%]\n",
      "43 [Discriminator loss: 1.2090%, acc.: 49.22%][Generator loss: 3.5313%]\n",
      "44 [Discriminator loss: 0.5338%, acc.: 77.34%][Generator loss: 2.8662%]\n",
      "45 [Discriminator loss: 0.2672%, acc.: 86.33%][Generator loss: 2.3157%]\n",
      "46 [Discriminator loss: 0.2266%, acc.: 86.33%][Generator loss: 2.3930%]\n",
      "47 [Discriminator loss: 0.2362%, acc.: 86.72%][Generator loss: 2.4545%]\n",
      "48 [Discriminator loss: 0.1635%, acc.: 92.58%][Generator loss: 2.5307%]\n",
      "49 [Discriminator loss: 0.1301%, acc.: 95.31%][Generator loss: 2.7036%]\n",
      "50 [Discriminator loss: 0.0826%, acc.: 99.22%][Generator loss: 2.7365%]\n",
      "51 [Discriminator loss: 0.0984%, acc.: 98.44%][Generator loss: 2.8365%]\n",
      "52 [Discriminator loss: 0.0928%, acc.: 98.05%][Generator loss: 3.0121%]\n",
      "53 [Discriminator loss: 0.1219%, acc.: 98.05%][Generator loss: 3.3549%]\n",
      "54 [Discriminator loss: 0.1397%, acc.: 95.31%][Generator loss: 3.6598%]\n",
      "55 [Discriminator loss: 0.1497%, acc.: 94.92%][Generator loss: 3.8333%]\n",
      "56 [Discriminator loss: 0.1643%, acc.: 93.75%][Generator loss: 4.2030%]\n",
      "57 [Discriminator loss: 0.3615%, acc.: 82.42%][Generator loss: 4.2737%]\n",
      "58 [Discriminator loss: 0.3611%, acc.: 80.47%][Generator loss: 4.0102%]\n",
      "59 [Discriminator loss: 0.1618%, acc.: 94.14%][Generator loss: 4.3873%]\n",
      "60 [Discriminator loss: 0.8151%, acc.: 67.58%][Generator loss: 2.3609%]\n",
      "61 [Discriminator loss: 0.2435%, acc.: 86.72%][Generator loss: 3.0481%]\n",
      "62 [Discriminator loss: 0.1330%, acc.: 96.88%][Generator loss: 3.4541%]\n",
      "63 [Discriminator loss: 0.2466%, acc.: 93.36%][Generator loss: 3.6877%]\n",
      "64 [Discriminator loss: 0.0878%, acc.: 99.61%][Generator loss: 4.1693%]\n",
      "65 [Discriminator loss: 0.2384%, acc.: 89.84%][Generator loss: 4.6290%]\n",
      "66 [Discriminator loss: 0.4757%, acc.: 75.39%][Generator loss: 3.4033%]\n",
      "67 [Discriminator loss: 0.1216%, acc.: 96.88%][Generator loss: 4.2518%]\n",
      "68 [Discriminator loss: 0.8472%, acc.: 64.06%][Generator loss: 2.5795%]\n",
      "69 [Discriminator loss: 0.1919%, acc.: 91.02%][Generator loss: 4.0161%]\n",
      "70 [Discriminator loss: 0.6502%, acc.: 69.92%][Generator loss: 2.3836%]\n",
      "71 [Discriminator loss: 0.2469%, acc.: 85.55%][Generator loss: 3.4589%]\n",
      "72 [Discriminator loss: 0.3115%, acc.: 86.72%][Generator loss: 3.3511%]\n",
      "73 [Discriminator loss: 0.1783%, acc.: 96.48%][Generator loss: 4.0086%]\n",
      "74 [Discriminator loss: 0.5604%, acc.: 68.36%][Generator loss: 3.2383%]\n",
      "75 [Discriminator loss: 0.2374%, acc.: 91.02%][Generator loss: 4.3558%]\n",
      "76 [Discriminator loss: 0.9854%, acc.: 55.08%][Generator loss: 1.1414%]\n",
      "77 [Discriminator loss: 0.4370%, acc.: 75.00%][Generator loss: 2.3005%]\n",
      "78 [Discriminator loss: 0.3928%, acc.: 75.39%][Generator loss: 2.4653%]\n",
      "79 [Discriminator loss: 0.5565%, acc.: 66.02%][Generator loss: 1.7392%]\n",
      "80 [Discriminator loss: 0.3006%, acc.: 85.16%][Generator loss: 3.0714%]\n",
      "81 [Discriminator loss: 0.8577%, acc.: 51.56%][Generator loss: 1.1345%]\n",
      "82 [Discriminator loss: 0.3968%, acc.: 73.44%][Generator loss: 2.2369%]\n",
      "83 [Discriminator loss: 0.5991%, acc.: 68.75%][Generator loss: 1.6185%]\n",
      "84 [Discriminator loss: 0.3920%, acc.: 78.12%][Generator loss: 2.2518%]\n",
      "85 [Discriminator loss: 0.6221%, acc.: 58.59%][Generator loss: 1.5537%]\n",
      "86 [Discriminator loss: 0.3807%, acc.: 77.73%][Generator loss: 2.7104%]\n",
      "87 [Discriminator loss: 0.9956%, acc.: 41.80%][Generator loss: 0.7325%]\n",
      "88 [Discriminator loss: 0.5146%, acc.: 60.55%][Generator loss: 1.1323%]\n",
      "89 [Discriminator loss: 0.5673%, acc.: 63.28%][Generator loss: 1.1844%]\n",
      "90 [Discriminator loss: 0.5342%, acc.: 68.36%][Generator loss: 1.3870%]\n",
      "91 [Discriminator loss: 0.5937%, acc.: 64.84%][Generator loss: 1.3787%]\n",
      "92 [Discriminator loss: 0.5353%, acc.: 69.92%][Generator loss: 1.3791%]\n",
      "93 [Discriminator loss: 0.5863%, acc.: 66.80%][Generator loss: 1.5302%]\n",
      "94 [Discriminator loss: 0.5428%, acc.: 67.19%][Generator loss: 1.5340%]\n",
      "95 [Discriminator loss: 0.7691%, acc.: 50.39%][Generator loss: 0.8353%]\n",
      "96 [Discriminator loss: 0.6021%, acc.: 53.12%][Generator loss: 0.9058%]\n",
      "97 [Discriminator loss: 0.6028%, acc.: 52.73%][Generator loss: 1.0508%]\n",
      "98 [Discriminator loss: 0.6476%, acc.: 52.73%][Generator loss: 1.0344%]\n",
      "99 [Discriminator loss: 0.6358%, acc.: 52.73%][Generator loss: 1.2734%]\n",
      "100 [Discriminator loss: 0.7536%, acc.: 50.39%][Generator loss: 0.7428%]\n",
      "101 [Discriminator loss: 0.6285%, acc.: 50.39%][Generator loss: 0.8170%]\n",
      "102 [Discriminator loss: 0.6469%, acc.: 50.39%][Generator loss: 0.8467%]\n",
      "103 [Discriminator loss: 0.6648%, acc.: 51.17%][Generator loss: 0.8657%]\n",
      "104 [Discriminator loss: 0.6493%, acc.: 52.34%][Generator loss: 0.8784%]\n",
      "105 [Discriminator loss: 0.6487%, acc.: 50.00%][Generator loss: 0.8990%]\n",
      "106 [Discriminator loss: 0.6392%, acc.: 51.17%][Generator loss: 0.9469%]\n",
      "107 [Discriminator loss: 0.6766%, acc.: 51.17%][Generator loss: 0.7865%]\n",
      "108 [Discriminator loss: 0.6257%, acc.: 50.78%][Generator loss: 0.9969%]\n",
      "109 [Discriminator loss: 0.7478%, acc.: 46.88%][Generator loss: 0.8387%]\n",
      "110 [Discriminator loss: 0.7207%, acc.: 49.22%][Generator loss: 0.6758%]\n",
      "111 [Discriminator loss: 0.6587%, acc.: 50.00%][Generator loss: 0.6674%]\n",
      "112 [Discriminator loss: 0.6405%, acc.: 50.00%][Generator loss: 0.7929%]\n",
      "113 [Discriminator loss: 0.7082%, acc.: 49.22%][Generator loss: 0.7604%]\n",
      "114 [Discriminator loss: 0.7066%, acc.: 50.00%][Generator loss: 0.7068%]\n",
      "115 [Discriminator loss: 0.6773%, acc.: 50.00%][Generator loss: 0.6912%]\n",
      "116 [Discriminator loss: 0.6733%, acc.: 50.39%][Generator loss: 0.7142%]\n",
      "117 [Discriminator loss: 0.6634%, acc.: 51.17%][Generator loss: 1.0106%]\n",
      "118 [Discriminator loss: 0.8051%, acc.: 41.41%][Generator loss: 1.2095%]\n",
      "119 [Discriminator loss: 1.1106%, acc.: 0.00%][Generator loss: 0.6068%]\n",
      "120 [Discriminator loss: 0.6932%, acc.: 50.00%][Generator loss: 0.6067%]\n",
      "121 [Discriminator loss: 0.6830%, acc.: 50.00%][Generator loss: 0.6140%]\n",
      "122 [Discriminator loss: 0.6858%, acc.: 50.00%][Generator loss: 0.6329%]\n",
      "123 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.6276%]\n",
      "124 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.6832%]\n",
      "125 [Discriminator loss: 0.7106%, acc.: 50.00%][Generator loss: 0.6544%]\n",
      "126 [Discriminator loss: 0.7051%, acc.: 50.00%][Generator loss: 0.6749%]\n",
      "127 [Discriminator loss: 0.6924%, acc.: 50.39%][Generator loss: 0.7567%]\n",
      "128 [Discriminator loss: 0.7361%, acc.: 51.95%][Generator loss: 0.7334%]\n",
      "129 [Discriminator loss: 0.7326%, acc.: 50.00%][Generator loss: 0.6981%]\n",
      "130 [Discriminator loss: 0.7106%, acc.: 51.95%][Generator loss: 0.7571%]\n",
      "131 [Discriminator loss: 0.7195%, acc.: 51.17%][Generator loss: 0.7511%]\n",
      "132 [Discriminator loss: 0.7006%, acc.: 57.03%][Generator loss: 1.0276%]\n",
      "133 [Discriminator loss: 0.7450%, acc.: 55.47%][Generator loss: 1.1822%]\n",
      "134 [Discriminator loss: 0.8068%, acc.: 46.88%][Generator loss: 0.9151%]\n",
      "135 [Discriminator loss: 0.7402%, acc.: 53.91%][Generator loss: 0.7945%]\n",
      "136 [Discriminator loss: 0.6692%, acc.: 54.30%][Generator loss: 0.7606%]\n",
      "137 [Discriminator loss: 0.6969%, acc.: 50.78%][Generator loss: 0.7615%]\n",
      "138 [Discriminator loss: 0.7559%, acc.: 49.22%][Generator loss: 0.6777%]\n",
      "139 [Discriminator loss: 0.7247%, acc.: 50.00%][Generator loss: 0.6653%]\n",
      "140 [Discriminator loss: 0.7188%, acc.: 50.78%][Generator loss: 0.6803%]\n",
      "141 [Discriminator loss: 0.7192%, acc.: 50.00%][Generator loss: 0.8975%]\n",
      "142 [Discriminator loss: 0.8273%, acc.: 32.81%][Generator loss: 1.2285%]\n",
      "143 [Discriminator loss: 1.0561%, acc.: 1.17%][Generator loss: 0.7037%]\n",
      "144 [Discriminator loss: 0.7653%, acc.: 50.00%][Generator loss: 0.6478%]\n",
      "145 [Discriminator loss: 0.7553%, acc.: 50.00%][Generator loss: 0.6336%]\n",
      "146 [Discriminator loss: 0.7288%, acc.: 50.00%][Generator loss: 0.6320%]\n",
      "147 [Discriminator loss: 0.7359%, acc.: 50.39%][Generator loss: 0.6644%]\n",
      "148 [Discriminator loss: 0.7414%, acc.: 50.39%][Generator loss: 0.6705%]\n",
      "149 [Discriminator loss: 0.7395%, acc.: 50.00%][Generator loss: 0.8589%]\n",
      "150 [Discriminator loss: 0.8182%, acc.: 41.41%][Generator loss: 0.8925%]\n",
      "151 [Discriminator loss: 0.8560%, acc.: 29.69%][Generator loss: 0.6927%]\n",
      "152 [Discriminator loss: 0.7680%, acc.: 49.61%][Generator loss: 0.6509%]\n",
      "153 [Discriminator loss: 0.7504%, acc.: 50.00%][Generator loss: 0.6430%]\n",
      "154 [Discriminator loss: 0.7363%, acc.: 50.39%][Generator loss: 0.6413%]\n",
      "155 [Discriminator loss: 0.7365%, acc.: 50.00%][Generator loss: 0.7029%]\n",
      "156 [Discriminator loss: 0.7569%, acc.: 48.83%][Generator loss: 0.9551%]\n",
      "157 [Discriminator loss: 0.8692%, acc.: 5.86%][Generator loss: 0.9046%]\n",
      "158 [Discriminator loss: 0.8635%, acc.: 24.22%][Generator loss: 0.7814%]\n",
      "159 [Discriminator loss: 0.8134%, acc.: 47.27%][Generator loss: 0.6424%]\n",
      "160 [Discriminator loss: 0.7552%, acc.: 50.00%][Generator loss: 0.6409%]\n",
      "161 [Discriminator loss: 0.7454%, acc.: 50.00%][Generator loss: 0.6525%]\n",
      "162 [Discriminator loss: 0.7357%, acc.: 49.61%][Generator loss: 0.6495%]\n",
      "163 [Discriminator loss: 0.7393%, acc.: 50.00%][Generator loss: 0.6563%]\n",
      "164 [Discriminator loss: 0.7313%, acc.: 50.00%][Generator loss: 0.6873%]\n",
      "165 [Discriminator loss: 0.7323%, acc.: 49.61%][Generator loss: 0.7760%]\n",
      "166 [Discriminator loss: 0.7520%, acc.: 46.48%][Generator loss: 0.9660%]\n",
      "167 [Discriminator loss: 0.8155%, acc.: 10.55%][Generator loss: 0.9265%]\n",
      "168 [Discriminator loss: 0.7832%, acc.: 39.45%][Generator loss: 0.9094%]\n",
      "169 [Discriminator loss: 0.8023%, acc.: 33.20%][Generator loss: 0.7357%]\n",
      "170 [Discriminator loss: 0.7750%, acc.: 50.00%][Generator loss: 0.6892%]\n",
      "171 [Discriminator loss: 0.7479%, acc.: 50.39%][Generator loss: 0.6778%]\n",
      "172 [Discriminator loss: 0.7426%, acc.: 50.00%][Generator loss: 0.6978%]\n",
      "173 [Discriminator loss: 0.7495%, acc.: 49.61%][Generator loss: 0.6967%]\n",
      "174 [Discriminator loss: 0.7419%, acc.: 50.00%][Generator loss: 0.6924%]\n",
      "175 [Discriminator loss: 0.7396%, acc.: 50.00%][Generator loss: 0.8842%]\n",
      "176 [Discriminator loss: 0.8018%, acc.: 5.47%][Generator loss: 1.3964%]\n",
      "177 [Discriminator loss: 1.1196%, acc.: 0.78%][Generator loss: 1.0441%]\n",
      "178 [Discriminator loss: 0.9463%, acc.: 0.39%][Generator loss: 0.6689%]\n",
      "179 [Discriminator loss: 0.7596%, acc.: 50.00%][Generator loss: 0.6515%]\n",
      "180 [Discriminator loss: 0.7457%, acc.: 50.00%][Generator loss: 0.6573%]\n",
      "181 [Discriminator loss: 0.7426%, acc.: 50.00%][Generator loss: 0.6680%]\n",
      "182 [Discriminator loss: 0.7474%, acc.: 50.00%][Generator loss: 0.6825%]\n",
      "183 [Discriminator loss: 0.7437%, acc.: 50.00%][Generator loss: 0.7250%]\n",
      "184 [Discriminator loss: 0.7551%, acc.: 47.66%][Generator loss: 0.6835%]\n",
      "185 [Discriminator loss: 0.7467%, acc.: 50.39%][Generator loss: 0.6840%]\n",
      "186 [Discriminator loss: 0.7474%, acc.: 49.61%][Generator loss: 0.7059%]\n",
      "187 [Discriminator loss: 0.7645%, acc.: 46.88%][Generator loss: 0.7466%]\n",
      "188 [Discriminator loss: 0.7585%, acc.: 37.50%][Generator loss: 0.9252%]\n",
      "189 [Discriminator loss: 0.8100%, acc.: 1.95%][Generator loss: 0.9234%]\n",
      "190 [Discriminator loss: 0.8463%, acc.: 2.73%][Generator loss: 0.7415%]\n",
      "191 [Discriminator loss: 0.7785%, acc.: 40.62%][Generator loss: 0.6861%]\n",
      "192 [Discriminator loss: 0.7601%, acc.: 49.61%][Generator loss: 0.6799%]\n",
      "193 [Discriminator loss: 0.7475%, acc.: 49.61%][Generator loss: 0.6722%]\n",
      "194 [Discriminator loss: 0.7476%, acc.: 50.00%][Generator loss: 0.7006%]\n",
      "195 [Discriminator loss: 0.7413%, acc.: 50.00%][Generator loss: 0.7347%]\n",
      "196 [Discriminator loss: 0.7418%, acc.: 48.44%][Generator loss: 1.0941%]\n",
      "197 [Discriminator loss: 0.8937%, acc.: 3.52%][Generator loss: 0.9717%]\n",
      "198 [Discriminator loss: 0.8629%, acc.: 0.39%][Generator loss: 0.9261%]\n",
      "199 [Discriminator loss: 0.8568%, acc.: 1.95%][Generator loss: 0.7048%]\n",
      "200 [Discriminator loss: 0.7540%, acc.: 49.61%][Generator loss: 0.6986%]\n",
      "201 [Discriminator loss: 0.7433%, acc.: 49.22%][Generator loss: 0.7000%]\n",
      "202 [Discriminator loss: 0.7419%, acc.: 47.66%][Generator loss: 0.7099%]\n",
      "203 [Discriminator loss: 0.7414%, acc.: 48.44%][Generator loss: 0.7039%]\n",
      "204 [Discriminator loss: 0.7364%, acc.: 48.44%][Generator loss: 0.7078%]\n",
      "205 [Discriminator loss: 0.7420%, acc.: 44.92%][Generator loss: 0.7371%]\n",
      "206 [Discriminator loss: 0.7389%, acc.: 42.19%][Generator loss: 0.7755%]\n",
      "207 [Discriminator loss: 0.7669%, acc.: 17.58%][Generator loss: 0.8055%]\n",
      "208 [Discriminator loss: 0.7820%, acc.: 11.72%][Generator loss: 0.7806%]\n",
      "209 [Discriminator loss: 0.7738%, acc.: 12.11%][Generator loss: 0.7190%]\n",
      "210 [Discriminator loss: 0.7642%, acc.: 37.89%][Generator loss: 0.7250%]\n",
      "211 [Discriminator loss: 0.7461%, acc.: 38.67%][Generator loss: 0.7227%]\n",
      "212 [Discriminator loss: 0.7663%, acc.: 31.25%][Generator loss: 0.7130%]\n",
      "213 [Discriminator loss: 0.7613%, acc.: 45.31%][Generator loss: 0.7332%]\n",
      "214 [Discriminator loss: 0.7673%, acc.: 27.34%][Generator loss: 0.7239%]\n",
      "215 [Discriminator loss: 0.7475%, acc.: 35.16%][Generator loss: 0.9955%]\n",
      "216 [Discriminator loss: 0.8434%, acc.: 3.91%][Generator loss: 2.5004%]\n",
      "217 [Discriminator loss: 1.7504%, acc.: 0.39%][Generator loss: 0.7720%]\n",
      "218 [Discriminator loss: 0.7961%, acc.: 17.58%][Generator loss: 0.7127%]\n",
      "219 [Discriminator loss: 0.7624%, acc.: 45.70%][Generator loss: 0.7153%]\n",
      "220 [Discriminator loss: 0.7468%, acc.: 45.70%][Generator loss: 0.7168%]\n",
      "221 [Discriminator loss: 0.7540%, acc.: 42.19%][Generator loss: 0.7135%]\n",
      "222 [Discriminator loss: 0.7495%, acc.: 43.75%][Generator loss: 0.7097%]\n",
      "223 [Discriminator loss: 0.7449%, acc.: 40.62%][Generator loss: 0.7199%]\n",
      "224 [Discriminator loss: 0.7467%, acc.: 39.45%][Generator loss: 0.7217%]\n",
      "225 [Discriminator loss: 0.7455%, acc.: 42.19%][Generator loss: 0.7111%]\n",
      "226 [Discriminator loss: 0.7457%, acc.: 40.62%][Generator loss: 0.7260%]\n",
      "227 [Discriminator loss: 0.7444%, acc.: 38.28%][Generator loss: 0.7328%]\n",
      "228 [Discriminator loss: 0.7528%, acc.: 35.55%][Generator loss: 0.7360%]\n",
      "229 [Discriminator loss: 0.7429%, acc.: 29.69%][Generator loss: 0.7699%]\n",
      "230 [Discriminator loss: 0.7601%, acc.: 20.31%][Generator loss: 0.7972%]\n",
      "231 [Discriminator loss: 0.7823%, acc.: 14.84%][Generator loss: 0.7564%]\n",
      "232 [Discriminator loss: 0.7955%, acc.: 20.70%][Generator loss: 0.7319%]\n",
      "233 [Discriminator loss: 0.7599%, acc.: 27.34%][Generator loss: 0.7946%]\n",
      "234 [Discriminator loss: 0.7628%, acc.: 7.42%][Generator loss: 0.9669%]\n",
      "235 [Discriminator loss: 0.8400%, acc.: 0.78%][Generator loss: 0.8529%]\n",
      "236 [Discriminator loss: 0.8051%, acc.: 3.91%][Generator loss: 0.7612%]\n",
      "237 [Discriminator loss: 0.7527%, acc.: 19.14%][Generator loss: 0.7282%]\n",
      "238 [Discriminator loss: 0.7455%, acc.: 27.34%][Generator loss: 0.7845%]\n",
      "239 [Discriminator loss: 0.7417%, acc.: 35.55%][Generator loss: 0.7526%]\n",
      "240 [Discriminator loss: 0.7410%, acc.: 19.14%][Generator loss: 0.7354%]\n",
      "241 [Discriminator loss: 0.7374%, acc.: 24.22%][Generator loss: 0.7456%]\n",
      "242 [Discriminator loss: 0.7357%, acc.: 21.48%][Generator loss: 1.0346%]\n",
      "243 [Discriminator loss: 0.8869%, acc.: 0.39%][Generator loss: 1.1956%]\n",
      "244 [Discriminator loss: 0.9735%, acc.: 0.00%][Generator loss: 0.7843%]\n",
      "245 [Discriminator loss: 0.7843%, acc.: 6.64%][Generator loss: 0.7472%]\n",
      "246 [Discriminator loss: 0.7605%, acc.: 14.06%][Generator loss: 0.7335%]\n",
      "247 [Discriminator loss: 0.7614%, acc.: 18.75%][Generator loss: 0.7298%]\n",
      "248 [Discriminator loss: 0.7566%, acc.: 18.75%][Generator loss: 0.7230%]\n",
      "249 [Discriminator loss: 0.7559%, acc.: 20.70%][Generator loss: 0.7294%]\n",
      "250 [Discriminator loss: 0.7570%, acc.: 23.83%][Generator loss: 0.7233%]\n",
      "251 [Discriminator loss: 0.7575%, acc.: 24.61%][Generator loss: 0.7361%]\n",
      "252 [Discriminator loss: 0.7628%, acc.: 22.27%][Generator loss: 0.7361%]\n",
      "253 [Discriminator loss: 0.7611%, acc.: 21.88%][Generator loss: 0.7581%]\n",
      "254 [Discriminator loss: 0.7503%, acc.: 15.62%][Generator loss: 0.7776%]\n",
      "255 [Discriminator loss: 0.7606%, acc.: 7.03%][Generator loss: 0.7646%]\n",
      "256 [Discriminator loss: 0.7540%, acc.: 12.89%][Generator loss: 0.7250%]\n",
      "257 [Discriminator loss: 0.7727%, acc.: 13.67%][Generator loss: 0.9400%]\n",
      "258 [Discriminator loss: 0.8324%, acc.: 0.39%][Generator loss: 0.9061%]\n",
      "259 [Discriminator loss: 0.8272%, acc.: 0.00%][Generator loss: 0.7896%]\n",
      "260 [Discriminator loss: 0.7736%, acc.: 6.25%][Generator loss: 0.7481%]\n",
      "261 [Discriminator loss: 0.7700%, acc.: 11.72%][Generator loss: 0.7505%]\n",
      "262 [Discriminator loss: 0.7568%, acc.: 12.50%][Generator loss: 0.7500%]\n",
      "263 [Discriminator loss: 0.7402%, acc.: 16.41%][Generator loss: 0.7470%]\n",
      "264 [Discriminator loss: 0.7485%, acc.: 14.06%][Generator loss: 0.7541%]\n",
      "265 [Discriminator loss: 0.7812%, acc.: 11.33%][Generator loss: 0.8978%]\n",
      "266 [Discriminator loss: 0.8206%, acc.: 1.17%][Generator loss: 0.8148%]\n",
      "267 [Discriminator loss: 0.7820%, acc.: 3.52%][Generator loss: 0.7794%]\n",
      "268 [Discriminator loss: 0.7705%, acc.: 7.81%][Generator loss: 0.7569%]\n",
      "269 [Discriminator loss: 0.7684%, acc.: 8.59%][Generator loss: 0.7397%]\n",
      "270 [Discriminator loss: 0.7513%, acc.: 10.94%][Generator loss: 0.7793%]\n",
      "271 [Discriminator loss: 0.7525%, acc.: 10.16%][Generator loss: 0.8173%]\n",
      "272 [Discriminator loss: 0.7834%, acc.: 3.12%][Generator loss: 0.7723%]\n",
      "273 [Discriminator loss: 0.7876%, acc.: 4.69%][Generator loss: 0.7306%]\n",
      "274 [Discriminator loss: 0.7738%, acc.: 13.28%][Generator loss: 0.8461%]\n",
      "275 [Discriminator loss: 0.7843%, acc.: 7.81%][Generator loss: 0.9111%]\n",
      "276 [Discriminator loss: 0.8262%, acc.: 0.00%][Generator loss: 0.8111%]\n",
      "277 [Discriminator loss: 0.7701%, acc.: 1.95%][Generator loss: 0.7805%]\n",
      "278 [Discriminator loss: 0.7991%, acc.: 12.50%][Generator loss: 0.7965%]\n",
      "279 [Discriminator loss: 0.7930%, acc.: 6.25%][Generator loss: 0.7858%]\n",
      "280 [Discriminator loss: 0.7658%, acc.: 7.42%][Generator loss: 0.7683%]\n",
      "281 [Discriminator loss: 0.7581%, acc.: 5.86%][Generator loss: 0.7737%]\n",
      "282 [Discriminator loss: 0.7386%, acc.: 14.06%][Generator loss: 0.7640%]\n",
      "283 [Discriminator loss: 0.7451%, acc.: 18.36%][Generator loss: 0.7622%]\n",
      "284 [Discriminator loss: 0.7530%, acc.: 11.33%][Generator loss: 0.7871%]\n",
      "285 [Discriminator loss: 0.7588%, acc.: 6.25%][Generator loss: 0.8053%]\n",
      "286 [Discriminator loss: 0.7355%, acc.: 24.61%][Generator loss: 0.9625%]\n",
      "287 [Discriminator loss: 0.8486%, acc.: 4.69%][Generator loss: 0.9301%]\n",
      "288 [Discriminator loss: 0.8460%, acc.: 0.00%][Generator loss: 0.8205%]\n",
      "289 [Discriminator loss: 0.7741%, acc.: 5.08%][Generator loss: 0.7967%]\n",
      "290 [Discriminator loss: 0.7520%, acc.: 10.94%][Generator loss: 0.8365%]\n",
      "291 [Discriminator loss: 0.7357%, acc.: 16.41%][Generator loss: 0.7822%]\n",
      "292 [Discriminator loss: 0.7235%, acc.: 21.09%][Generator loss: 0.7693%]\n",
      "293 [Discriminator loss: 0.7299%, acc.: 19.53%][Generator loss: 0.7823%]\n",
      "294 [Discriminator loss: 0.7285%, acc.: 21.88%][Generator loss: 0.7743%]\n",
      "295 [Discriminator loss: 0.7579%, acc.: 16.02%][Generator loss: 0.8122%]\n",
      "296 [Discriminator loss: 0.7568%, acc.: 9.38%][Generator loss: 0.9657%]\n",
      "297 [Discriminator loss: 0.8255%, acc.: 5.86%][Generator loss: 0.8572%]\n",
      "298 [Discriminator loss: 0.7731%, acc.: 8.59%][Generator loss: 0.8064%]\n",
      "299 [Discriminator loss: 0.7650%, acc.: 8.98%][Generator loss: 0.7546%]\n",
      "300 [Discriminator loss: 0.7525%, acc.: 10.55%][Generator loss: 0.7628%]\n",
      "301 [Discriminator loss: 0.7510%, acc.: 16.80%][Generator loss: 0.7597%]\n",
      "302 [Discriminator loss: 0.7453%, acc.: 19.14%][Generator loss: 0.7952%]\n",
      "303 [Discriminator loss: 0.7362%, acc.: 16.02%][Generator loss: 0.7838%]\n",
      "304 [Discriminator loss: 0.7600%, acc.: 15.23%][Generator loss: 0.8486%]\n",
      "305 [Discriminator loss: 0.7559%, acc.: 15.62%][Generator loss: 0.9009%]\n",
      "306 [Discriminator loss: 0.8033%, acc.: 7.03%][Generator loss: 0.8266%]\n",
      "307 [Discriminator loss: 0.7591%, acc.: 8.59%][Generator loss: 0.7909%]\n",
      "308 [Discriminator loss: 0.7545%, acc.: 20.31%][Generator loss: 0.7527%]\n",
      "309 [Discriminator loss: 0.7373%, acc.: 21.48%][Generator loss: 0.7932%]\n",
      "310 [Discriminator loss: 0.7302%, acc.: 17.58%][Generator loss: 0.8100%]\n",
      "311 [Discriminator loss: 0.7576%, acc.: 19.92%][Generator loss: 0.7657%]\n",
      "312 [Discriminator loss: 0.7444%, acc.: 14.45%][Generator loss: 0.7706%]\n",
      "313 [Discriminator loss: 0.7569%, acc.: 19.14%][Generator loss: 0.7855%]\n",
      "314 [Discriminator loss: 0.7759%, acc.: 23.44%][Generator loss: 0.8430%]\n",
      "315 [Discriminator loss: 0.7845%, acc.: 2.73%][Generator loss: 0.7960%]\n",
      "316 [Discriminator loss: 0.7343%, acc.: 17.97%][Generator loss: 0.7708%]\n",
      "317 [Discriminator loss: 0.7484%, acc.: 19.14%][Generator loss: 0.7709%]\n",
      "318 [Discriminator loss: 0.7287%, acc.: 26.56%][Generator loss: 0.8026%]\n",
      "319 [Discriminator loss: 0.7482%, acc.: 13.67%][Generator loss: 0.8067%]\n",
      "320 [Discriminator loss: 0.7712%, acc.: 14.84%][Generator loss: 0.7815%]\n",
      "321 [Discriminator loss: 0.7756%, acc.: 12.11%][Generator loss: 0.7963%]\n",
      "322 [Discriminator loss: 0.7748%, acc.: 10.55%][Generator loss: 0.7803%]\n",
      "323 [Discriminator loss: 0.7579%, acc.: 12.11%][Generator loss: 0.7767%]\n",
      "324 [Discriminator loss: 0.7499%, acc.: 18.36%][Generator loss: 0.7768%]\n",
      "325 [Discriminator loss: 0.7529%, acc.: 16.41%][Generator loss: 0.7733%]\n",
      "326 [Discriminator loss: 0.7557%, acc.: 16.80%][Generator loss: 0.7708%]\n",
      "327 [Discriminator loss: 0.7650%, acc.: 8.98%][Generator loss: 0.7859%]\n",
      "328 [Discriminator loss: 0.7741%, acc.: 16.41%][Generator loss: 0.7523%]\n",
      "329 [Discriminator loss: 0.7629%, acc.: 15.62%][Generator loss: 0.8155%]\n",
      "330 [Discriminator loss: 0.7663%, acc.: 7.81%][Generator loss: 0.8915%]\n",
      "331 [Discriminator loss: 0.7979%, acc.: 4.30%][Generator loss: 0.8232%]\n",
      "332 [Discriminator loss: 0.7683%, acc.: 9.38%][Generator loss: 0.7710%]\n",
      "333 [Discriminator loss: 0.7376%, acc.: 19.14%][Generator loss: 0.7960%]\n",
      "334 [Discriminator loss: 0.7337%, acc.: 25.78%][Generator loss: 0.8679%]\n",
      "335 [Discriminator loss: 0.8060%, acc.: 11.33%][Generator loss: 0.7743%]\n",
      "336 [Discriminator loss: 0.7578%, acc.: 10.55%][Generator loss: 0.7671%]\n",
      "337 [Discriminator loss: 0.7560%, acc.: 15.23%][Generator loss: 0.7579%]\n",
      "338 [Discriminator loss: 0.7483%, acc.: 20.70%][Generator loss: 0.7772%]\n",
      "339 [Discriminator loss: 0.7397%, acc.: 22.27%][Generator loss: 0.8479%]\n",
      "340 [Discriminator loss: 0.7535%, acc.: 14.06%][Generator loss: 0.8478%]\n",
      "341 [Discriminator loss: 0.7990%, acc.: 2.73%][Generator loss: 0.7908%]\n",
      "342 [Discriminator loss: 0.7448%, acc.: 17.97%][Generator loss: 0.7645%]\n",
      "343 [Discriminator loss: 0.7333%, acc.: 17.19%][Generator loss: 0.7697%]\n",
      "344 [Discriminator loss: 0.7359%, acc.: 25.00%][Generator loss: 0.7922%]\n",
      "345 [Discriminator loss: 0.7747%, acc.: 9.77%][Generator loss: 0.7819%]\n",
      "346 [Discriminator loss: 0.7561%, acc.: 14.45%][Generator loss: 0.7678%]\n",
      "347 [Discriminator loss: 0.7784%, acc.: 15.23%][Generator loss: 0.7623%]\n",
      "348 [Discriminator loss: 0.7541%, acc.: 10.94%][Generator loss: 0.7726%]\n",
      "349 [Discriminator loss: 0.7331%, acc.: 23.83%][Generator loss: 0.8087%]\n",
      "350 [Discriminator loss: 0.7561%, acc.: 16.02%][Generator loss: 0.8071%]\n",
      "351 [Discriminator loss: 0.7634%, acc.: 15.23%][Generator loss: 0.7551%]\n",
      "352 [Discriminator loss: 0.7557%, acc.: 16.41%][Generator loss: 0.8052%]\n",
      "353 [Discriminator loss: 0.7499%, acc.: 12.50%][Generator loss: 0.8672%]\n",
      "354 [Discriminator loss: 0.7718%, acc.: 13.28%][Generator loss: 0.8043%]\n",
      "355 [Discriminator loss: 0.7579%, acc.: 13.67%][Generator loss: 0.7715%]\n",
      "356 [Discriminator loss: 0.7342%, acc.: 23.05%][Generator loss: 0.9124%]\n",
      "357 [Discriminator loss: 0.7741%, acc.: 10.55%][Generator loss: 0.8883%]\n",
      "358 [Discriminator loss: 0.7788%, acc.: 19.53%][Generator loss: 0.7943%]\n",
      "359 [Discriminator loss: 0.7358%, acc.: 21.09%][Generator loss: 0.7893%]\n",
      "360 [Discriminator loss: 0.7424%, acc.: 23.44%][Generator loss: 0.7662%]\n",
      "361 [Discriminator loss: 0.7471%, acc.: 16.02%][Generator loss: 0.7551%]\n",
      "362 [Discriminator loss: 0.7421%, acc.: 17.19%][Generator loss: 0.7615%]\n",
      "363 [Discriminator loss: 0.7274%, acc.: 23.83%][Generator loss: 0.7629%]\n",
      "364 [Discriminator loss: 0.7397%, acc.: 15.23%][Generator loss: 0.7740%]\n",
      "365 [Discriminator loss: 0.7654%, acc.: 21.88%][Generator loss: 0.7826%]\n",
      "366 [Discriminator loss: 0.7644%, acc.: 9.77%][Generator loss: 0.8171%]\n",
      "367 [Discriminator loss: 0.7869%, acc.: 8.59%][Generator loss: 0.7650%]\n",
      "368 [Discriminator loss: 0.7508%, acc.: 8.98%][Generator loss: 0.7720%]\n",
      "369 [Discriminator loss: 0.7710%, acc.: 21.09%][Generator loss: 0.8009%]\n",
      "370 [Discriminator loss: 0.7491%, acc.: 11.72%][Generator loss: 0.8302%]\n",
      "371 [Discriminator loss: 0.7754%, acc.: 4.69%][Generator loss: 0.7780%]\n",
      "372 [Discriminator loss: 0.7662%, acc.: 16.02%][Generator loss: 0.9923%]\n",
      "373 [Discriminator loss: 0.8571%, acc.: 3.91%][Generator loss: 0.9231%]\n",
      "374 [Discriminator loss: 0.8454%, acc.: 2.34%][Generator loss: 0.7923%]\n",
      "375 [Discriminator loss: 0.7728%, acc.: 4.69%][Generator loss: 0.7904%]\n",
      "376 [Discriminator loss: 0.7537%, acc.: 5.86%][Generator loss: 0.7721%]\n",
      "377 [Discriminator loss: 0.7515%, acc.: 9.77%][Generator loss: 0.7872%]\n",
      "378 [Discriminator loss: 0.7509%, acc.: 9.38%][Generator loss: 0.7673%]\n",
      "379 [Discriminator loss: 0.7415%, acc.: 16.80%][Generator loss: 0.7598%]\n",
      "380 [Discriminator loss: 0.7330%, acc.: 17.19%][Generator loss: 0.7676%]\n",
      "381 [Discriminator loss: 0.7682%, acc.: 23.05%][Generator loss: 0.7614%]\n",
      "382 [Discriminator loss: 0.7707%, acc.: 7.03%][Generator loss: 0.7693%]\n",
      "383 [Discriminator loss: 0.7597%, acc.: 9.38%][Generator loss: 0.7730%]\n",
      "384 [Discriminator loss: 0.7487%, acc.: 5.86%][Generator loss: 0.7810%]\n",
      "385 [Discriminator loss: 0.7623%, acc.: 14.06%][Generator loss: 0.7549%]\n",
      "386 [Discriminator loss: 0.7581%, acc.: 9.77%][Generator loss: 0.8020%]\n",
      "387 [Discriminator loss: 0.7465%, acc.: 16.41%][Generator loss: 0.7994%]\n",
      "388 [Discriminator loss: 0.7607%, acc.: 9.77%][Generator loss: 0.7774%]\n",
      "389 [Discriminator loss: 0.7647%, acc.: 6.25%][Generator loss: 0.8170%]\n",
      "390 [Discriminator loss: 0.7792%, acc.: 10.16%][Generator loss: 0.8137%]\n",
      "391 [Discriminator loss: 0.7712%, acc.: 7.03%][Generator loss: 0.7850%]\n",
      "392 [Discriminator loss: 0.7470%, acc.: 10.55%][Generator loss: 0.8140%]\n",
      "393 [Discriminator loss: 0.7429%, acc.: 28.12%][Generator loss: 0.7774%]\n",
      "394 [Discriminator loss: 0.7307%, acc.: 14.45%][Generator loss: 0.7970%]\n",
      "395 [Discriminator loss: 0.7664%, acc.: 16.80%][Generator loss: 0.7688%]\n",
      "396 [Discriminator loss: 0.7723%, acc.: 7.42%][Generator loss: 0.7649%]\n",
      "397 [Discriminator loss: 0.7342%, acc.: 19.14%][Generator loss: 0.7779%]\n",
      "398 [Discriminator loss: 0.7110%, acc.: 33.20%][Generator loss: 0.8068%]\n",
      "399 [Discriminator loss: 0.7599%, acc.: 26.17%][Generator loss: 0.8285%]\n",
      "400 [Discriminator loss: 0.7454%, acc.: 14.84%][Generator loss: 0.8647%]\n",
      "401 [Discriminator loss: 0.7469%, acc.: 27.73%][Generator loss: 0.8098%]\n",
      "402 [Discriminator loss: 0.7318%, acc.: 30.47%][Generator loss: 0.7866%]\n",
      "403 [Discriminator loss: 0.7762%, acc.: 19.92%][Generator loss: 0.7617%]\n",
      "404 [Discriminator loss: 0.7383%, acc.: 15.62%][Generator loss: 0.7824%]\n",
      "405 [Discriminator loss: 0.6979%, acc.: 39.84%][Generator loss: 0.7920%]\n",
      "406 [Discriminator loss: 0.7055%, acc.: 45.31%][Generator loss: 0.8357%]\n",
      "407 [Discriminator loss: 0.7026%, acc.: 43.75%][Generator loss: 0.9037%]\n",
      "408 [Discriminator loss: 0.7587%, acc.: 42.58%][Generator loss: 0.8346%]\n",
      "409 [Discriminator loss: 0.7672%, acc.: 36.72%][Generator loss: 0.8181%]\n",
      "410 [Discriminator loss: 0.7312%, acc.: 25.78%][Generator loss: 0.8040%]\n",
      "411 [Discriminator loss: 0.7609%, acc.: 30.08%][Generator loss: 0.7836%]\n",
      "412 [Discriminator loss: 0.7287%, acc.: 30.86%][Generator loss: 0.8346%]\n",
      "413 [Discriminator loss: 0.7780%, acc.: 35.55%][Generator loss: 0.7846%]\n",
      "414 [Discriminator loss: 0.7616%, acc.: 31.64%][Generator loss: 1.0489%]\n",
      "415 [Discriminator loss: 0.8249%, acc.: 30.08%][Generator loss: 0.9007%]\n",
      "416 [Discriminator loss: 0.7922%, acc.: 24.22%][Generator loss: 0.8365%]\n",
      "417 [Discriminator loss: 0.7429%, acc.: 25.00%][Generator loss: 0.8113%]\n",
      "418 [Discriminator loss: 0.7561%, acc.: 41.02%][Generator loss: 0.7972%]\n",
      "419 [Discriminator loss: 0.7256%, acc.: 26.95%][Generator loss: 0.7985%]\n",
      "420 [Discriminator loss: 0.7187%, acc.: 42.19%][Generator loss: 0.8050%]\n",
      "421 [Discriminator loss: 0.7580%, acc.: 47.27%][Generator loss: 0.7773%]\n",
      "422 [Discriminator loss: 0.7569%, acc.: 26.95%][Generator loss: 0.8134%]\n",
      "423 [Discriminator loss: 0.7153%, acc.: 34.38%][Generator loss: 0.7711%]\n",
      "424 [Discriminator loss: 0.7107%, acc.: 41.80%][Generator loss: 0.8378%]\n",
      "425 [Discriminator loss: 0.7303%, acc.: 35.16%][Generator loss: 0.8545%]\n",
      "426 [Discriminator loss: 0.7696%, acc.: 17.97%][Generator loss: 0.8013%]\n",
      "427 [Discriminator loss: 0.7421%, acc.: 28.12%][Generator loss: 0.8024%]\n",
      "428 [Discriminator loss: 0.7245%, acc.: 40.62%][Generator loss: 0.8307%]\n",
      "429 [Discriminator loss: 0.7450%, acc.: 28.91%][Generator loss: 0.7843%]\n",
      "430 [Discriminator loss: 0.7718%, acc.: 30.47%][Generator loss: 0.7677%]\n",
      "431 [Discriminator loss: 0.7502%, acc.: 25.78%][Generator loss: 0.8065%]\n",
      "432 [Discriminator loss: 0.7348%, acc.: 21.48%][Generator loss: 0.8747%]\n",
      "433 [Discriminator loss: 0.7588%, acc.: 26.17%][Generator loss: 0.7960%]\n",
      "434 [Discriminator loss: 0.7477%, acc.: 19.14%][Generator loss: 0.7721%]\n",
      "435 [Discriminator loss: 0.7399%, acc.: 34.38%][Generator loss: 0.7797%]\n",
      "436 [Discriminator loss: 0.7308%, acc.: 26.95%][Generator loss: 0.8188%]\n",
      "437 [Discriminator loss: 0.7530%, acc.: 25.78%][Generator loss: 0.7745%]\n",
      "438 [Discriminator loss: 0.7142%, acc.: 30.47%][Generator loss: 0.7926%]\n",
      "439 [Discriminator loss: 0.7419%, acc.: 31.25%][Generator loss: 0.8489%]\n",
      "440 [Discriminator loss: 0.7549%, acc.: 29.30%][Generator loss: 0.8963%]\n",
      "441 [Discriminator loss: 0.7851%, acc.: 14.06%][Generator loss: 0.8012%]\n",
      "442 [Discriminator loss: 0.7530%, acc.: 24.61%][Generator loss: 0.7813%]\n",
      "443 [Discriminator loss: 0.7384%, acc.: 28.52%][Generator loss: 0.7705%]\n",
      "444 [Discriminator loss: 0.7318%, acc.: 28.91%][Generator loss: 0.7755%]\n",
      "445 [Discriminator loss: 0.7629%, acc.: 24.61%][Generator loss: 0.8075%]\n",
      "446 [Discriminator loss: 0.7549%, acc.: 16.41%][Generator loss: 0.8116%]\n",
      "447 [Discriminator loss: 0.7789%, acc.: 8.98%][Generator loss: 0.7724%]\n",
      "448 [Discriminator loss: 0.7464%, acc.: 17.19%][Generator loss: 0.7678%]\n",
      "449 [Discriminator loss: 0.7563%, acc.: 23.83%][Generator loss: 0.7461%]\n",
      "450 [Discriminator loss: 0.7458%, acc.: 23.83%][Generator loss: 0.7678%]\n",
      "451 [Discriminator loss: 0.7529%, acc.: 25.39%][Generator loss: 0.7824%]\n",
      "452 [Discriminator loss: 0.7627%, acc.: 12.50%][Generator loss: 0.7665%]\n",
      "453 [Discriminator loss: 0.7247%, acc.: 26.17%][Generator loss: 0.7715%]\n",
      "454 [Discriminator loss: 0.7290%, acc.: 28.12%][Generator loss: 0.7562%]\n",
      "455 [Discriminator loss: 0.7318%, acc.: 24.22%][Generator loss: 0.8919%]\n",
      "456 [Discriminator loss: 0.7673%, acc.: 25.39%][Generator loss: 0.9291%]\n",
      "457 [Discriminator loss: 0.7821%, acc.: 23.44%][Generator loss: 0.8251%]\n",
      "458 [Discriminator loss: 0.7574%, acc.: 19.14%][Generator loss: 0.7851%]\n",
      "459 [Discriminator loss: 0.7482%, acc.: 27.73%][Generator loss: 0.7903%]\n",
      "460 [Discriminator loss: 0.7400%, acc.: 20.70%][Generator loss: 0.7629%]\n",
      "461 [Discriminator loss: 0.7164%, acc.: 28.12%][Generator loss: 0.7550%]\n",
      "462 [Discriminator loss: 0.7246%, acc.: 28.91%][Generator loss: 0.7615%]\n",
      "463 [Discriminator loss: 0.7077%, acc.: 30.86%][Generator loss: 0.7877%]\n",
      "464 [Discriminator loss: 0.7365%, acc.: 20.70%][Generator loss: 0.7682%]\n",
      "465 [Discriminator loss: 0.7401%, acc.: 26.56%][Generator loss: 0.7627%]\n",
      "466 [Discriminator loss: 0.7250%, acc.: 37.11%][Generator loss: 0.7537%]\n",
      "467 [Discriminator loss: 0.7310%, acc.: 26.56%][Generator loss: 0.7638%]\n",
      "468 [Discriminator loss: 0.7178%, acc.: 26.56%][Generator loss: 0.7583%]\n",
      "469 [Discriminator loss: 0.7269%, acc.: 31.64%][Generator loss: 0.7549%]\n",
      "470 [Discriminator loss: 0.7286%, acc.: 38.67%][Generator loss: 0.8581%]\n",
      "471 [Discriminator loss: 0.7584%, acc.: 27.34%][Generator loss: 0.8151%]\n",
      "472 [Discriminator loss: 0.7488%, acc.: 29.30%][Generator loss: 0.7756%]\n",
      "473 [Discriminator loss: 0.7295%, acc.: 27.73%][Generator loss: 0.7518%]\n",
      "474 [Discriminator loss: 0.7448%, acc.: 28.12%][Generator loss: 0.7822%]\n",
      "475 [Discriminator loss: 0.7334%, acc.: 29.30%][Generator loss: 0.7929%]\n",
      "476 [Discriminator loss: 0.7633%, acc.: 20.31%][Generator loss: 0.7749%]\n",
      "477 [Discriminator loss: 0.7342%, acc.: 28.12%][Generator loss: 0.7700%]\n",
      "478 [Discriminator loss: 0.7414%, acc.: 30.86%][Generator loss: 0.7880%]\n",
      "479 [Discriminator loss: 0.7410%, acc.: 27.34%][Generator loss: 0.8004%]\n",
      "480 [Discriminator loss: 0.7618%, acc.: 19.14%][Generator loss: 0.7708%]\n",
      "481 [Discriminator loss: 0.7349%, acc.: 26.95%][Generator loss: 0.7637%]\n",
      "482 [Discriminator loss: 0.7437%, acc.: 28.52%][Generator loss: 0.9674%]\n",
      "483 [Discriminator loss: 0.8027%, acc.: 21.09%][Generator loss: 0.9238%]\n",
      "484 [Discriminator loss: 0.7886%, acc.: 17.58%][Generator loss: 0.8220%]\n",
      "485 [Discriminator loss: 0.7443%, acc.: 26.56%][Generator loss: 0.7911%]\n",
      "486 [Discriminator loss: 0.7467%, acc.: 27.73%][Generator loss: 0.7720%]\n",
      "487 [Discriminator loss: 0.7318%, acc.: 23.44%][Generator loss: 0.7705%]\n",
      "488 [Discriminator loss: 0.7287%, acc.: 32.03%][Generator loss: 0.7482%]\n",
      "489 [Discriminator loss: 0.7305%, acc.: 30.47%][Generator loss: 0.7996%]\n",
      "490 [Discriminator loss: 0.7390%, acc.: 24.22%][Generator loss: 0.7775%]\n",
      "491 [Discriminator loss: 0.7377%, acc.: 21.09%][Generator loss: 0.7500%]\n",
      "492 [Discriminator loss: 0.7296%, acc.: 28.52%][Generator loss: 0.7348%]\n",
      "493 [Discriminator loss: 0.7347%, acc.: 25.78%][Generator loss: 0.9284%]\n",
      "494 [Discriminator loss: 0.7587%, acc.: 21.88%][Generator loss: 0.8759%]\n",
      "495 [Discriminator loss: 0.7880%, acc.: 17.97%][Generator loss: 0.7853%]\n",
      "496 [Discriminator loss: 0.7484%, acc.: 20.70%][Generator loss: 0.7793%]\n",
      "497 [Discriminator loss: 0.7443%, acc.: 19.53%][Generator loss: 0.7461%]\n",
      "498 [Discriminator loss: 0.7422%, acc.: 25.00%][Generator loss: 0.7741%]\n",
      "499 [Discriminator loss: 0.7375%, acc.: 27.73%][Generator loss: 0.7538%]\n",
      "500 [Discriminator loss: 0.7363%, acc.: 23.44%][Generator loss: 0.7946%]\n",
      "501 [Discriminator loss: 0.7267%, acc.: 28.91%][Generator loss: 0.7675%]\n",
      "502 [Discriminator loss: 0.7350%, acc.: 23.44%][Generator loss: 0.7476%]\n",
      "503 [Discriminator loss: 0.7246%, acc.: 32.03%][Generator loss: 0.7589%]\n",
      "504 [Discriminator loss: 0.7254%, acc.: 34.38%][Generator loss: 0.7619%]\n",
      "505 [Discriminator loss: 0.7396%, acc.: 28.52%][Generator loss: 0.7607%]\n",
      "506 [Discriminator loss: 0.7435%, acc.: 21.88%][Generator loss: 0.7600%]\n",
      "507 [Discriminator loss: 0.7160%, acc.: 30.86%][Generator loss: 0.7650%]\n",
      "508 [Discriminator loss: 0.7303%, acc.: 37.11%][Generator loss: 0.7559%]\n",
      "509 [Discriminator loss: 0.7383%, acc.: 27.73%][Generator loss: 0.7712%]\n",
      "510 [Discriminator loss: 0.7347%, acc.: 26.17%][Generator loss: 0.7651%]\n",
      "511 [Discriminator loss: 0.7141%, acc.: 36.72%][Generator loss: 0.7822%]\n",
      "512 [Discriminator loss: 0.7530%, acc.: 32.03%][Generator loss: 0.7937%]\n",
      "513 [Discriminator loss: 0.7628%, acc.: 12.11%][Generator loss: 0.7626%]\n",
      "514 [Discriminator loss: 0.7283%, acc.: 29.69%][Generator loss: 0.7541%]\n",
      "515 [Discriminator loss: 0.7201%, acc.: 29.30%][Generator loss: 1.9828%]\n",
      "516 [Discriminator loss: 1.2825%, acc.: 19.14%][Generator loss: 0.9422%]\n",
      "517 [Discriminator loss: 0.7975%, acc.: 21.88%][Generator loss: 0.8416%]\n",
      "518 [Discriminator loss: 0.7563%, acc.: 25.39%][Generator loss: 0.8152%]\n",
      "519 [Discriminator loss: 0.7474%, acc.: 21.88%][Generator loss: 0.8006%]\n",
      "520 [Discriminator loss: 0.7333%, acc.: 23.44%][Generator loss: 0.7860%]\n",
      "521 [Discriminator loss: 0.7597%, acc.: 27.73%][Generator loss: 0.7699%]\n",
      "522 [Discriminator loss: 0.7371%, acc.: 19.14%][Generator loss: 0.7672%]\n",
      "523 [Discriminator loss: 0.7205%, acc.: 28.91%][Generator loss: 0.7802%]\n",
      "524 [Discriminator loss: 0.7134%, acc.: 32.81%][Generator loss: 0.7684%]\n",
      "525 [Discriminator loss: 0.7323%, acc.: 31.64%][Generator loss: 0.7586%]\n",
      "526 [Discriminator loss: 0.7202%, acc.: 29.30%][Generator loss: 0.7709%]\n",
      "527 [Discriminator loss: 0.7263%, acc.: 30.08%][Generator loss: 0.8153%]\n",
      "528 [Discriminator loss: 0.7300%, acc.: 28.12%][Generator loss: 0.7809%]\n",
      "529 [Discriminator loss: 0.7434%, acc.: 29.30%][Generator loss: 0.7450%]\n",
      "530 [Discriminator loss: 0.7477%, acc.: 28.52%][Generator loss: 0.7586%]\n",
      "531 [Discriminator loss: 0.7230%, acc.: 32.81%][Generator loss: 0.7671%]\n",
      "532 [Discriminator loss: 0.7175%, acc.: 32.81%][Generator loss: 0.8085%]\n",
      "533 [Discriminator loss: 0.7312%, acc.: 27.34%][Generator loss: 0.8251%]\n",
      "534 [Discriminator loss: 0.7429%, acc.: 23.44%][Generator loss: 0.7699%]\n",
      "535 [Discriminator loss: 0.7405%, acc.: 24.61%][Generator loss: 0.7637%]\n",
      "536 [Discriminator loss: 0.7316%, acc.: 32.81%][Generator loss: 0.7566%]\n",
      "537 [Discriminator loss: 0.7297%, acc.: 28.52%][Generator loss: 0.8218%]\n",
      "538 [Discriminator loss: 0.7341%, acc.: 38.28%][Generator loss: 0.8289%]\n",
      "539 [Discriminator loss: 0.7576%, acc.: 13.67%][Generator loss: 0.7859%]\n",
      "540 [Discriminator loss: 0.7477%, acc.: 21.09%][Generator loss: 0.7876%]\n",
      "541 [Discriminator loss: 0.7463%, acc.: 24.22%][Generator loss: 0.7580%]\n",
      "542 [Discriminator loss: 0.7393%, acc.: 15.23%][Generator loss: 0.7590%]\n",
      "543 [Discriminator loss: 0.7325%, acc.: 26.17%][Generator loss: 0.7329%]\n",
      "544 [Discriminator loss: 0.7192%, acc.: 28.12%][Generator loss: 0.7484%]\n",
      "545 [Discriminator loss: 0.7307%, acc.: 25.78%][Generator loss: 0.7574%]\n",
      "546 [Discriminator loss: 0.7266%, acc.: 22.27%][Generator loss: 0.7628%]\n",
      "547 [Discriminator loss: 0.7086%, acc.: 32.03%][Generator loss: 0.8179%]\n",
      "548 [Discriminator loss: 0.7347%, acc.: 19.92%][Generator loss: 0.7683%]\n",
      "549 [Discriminator loss: 0.7309%, acc.: 28.91%][Generator loss: 0.7770%]\n",
      "550 [Discriminator loss: 0.7454%, acc.: 26.56%][Generator loss: 0.8075%]\n",
      "551 [Discriminator loss: 0.7531%, acc.: 11.33%][Generator loss: 0.7798%]\n",
      "552 [Discriminator loss: 0.7071%, acc.: 28.52%][Generator loss: 0.7666%]\n",
      "553 [Discriminator loss: 0.7152%, acc.: 32.03%][Generator loss: 0.7326%]\n",
      "554 [Discriminator loss: 0.7312%, acc.: 35.16%][Generator loss: 0.7786%]\n",
      "555 [Discriminator loss: 0.7114%, acc.: 26.17%][Generator loss: 0.7491%]\n",
      "556 [Discriminator loss: 0.7001%, acc.: 32.03%][Generator loss: 0.7824%]\n",
      "557 [Discriminator loss: 0.6842%, acc.: 44.53%][Generator loss: 0.8207%]\n",
      "558 [Discriminator loss: 0.7164%, acc.: 39.06%][Generator loss: 0.7884%]\n",
      "559 [Discriminator loss: 0.6983%, acc.: 40.23%][Generator loss: 0.7605%]\n",
      "560 [Discriminator loss: 0.7036%, acc.: 37.89%][Generator loss: 0.8056%]\n",
      "561 [Discriminator loss: 0.7007%, acc.: 35.55%][Generator loss: 0.7820%]\n",
      "562 [Discriminator loss: 0.7184%, acc.: 26.95%][Generator loss: 0.8470%]\n",
      "563 [Discriminator loss: 0.6890%, acc.: 44.92%][Generator loss: 0.8435%]\n",
      "564 [Discriminator loss: 0.6912%, acc.: 48.05%][Generator loss: 0.8129%]\n",
      "565 [Discriminator loss: 0.6827%, acc.: 50.78%][Generator loss: 0.8032%]\n",
      "566 [Discriminator loss: 0.7663%, acc.: 37.50%][Generator loss: 0.7532%]\n",
      "567 [Discriminator loss: 0.7568%, acc.: 23.44%][Generator loss: 0.7780%]\n",
      "568 [Discriminator loss: 0.6846%, acc.: 40.23%][Generator loss: 0.8309%]\n",
      "569 [Discriminator loss: 0.7064%, acc.: 51.17%][Generator loss: 0.8616%]\n",
      "570 [Discriminator loss: 0.7115%, acc.: 41.80%][Generator loss: 0.8053%]\n",
      "571 [Discriminator loss: 0.7459%, acc.: 42.58%][Generator loss: 0.8289%]\n",
      "572 [Discriminator loss: 0.7165%, acc.: 36.72%][Generator loss: 0.7944%]\n",
      "573 [Discriminator loss: 0.7345%, acc.: 35.55%][Generator loss: 0.7686%]\n",
      "574 [Discriminator loss: 0.7104%, acc.: 39.84%][Generator loss: 0.8469%]\n",
      "575 [Discriminator loss: 0.6983%, acc.: 44.53%][Generator loss: 0.8670%]\n",
      "576 [Discriminator loss: 0.7715%, acc.: 32.42%][Generator loss: 0.7988%]\n",
      "577 [Discriminator loss: 0.7389%, acc.: 22.66%][Generator loss: 0.7699%]\n",
      "578 [Discriminator loss: 0.7458%, acc.: 32.03%][Generator loss: 0.7629%]\n",
      "579 [Discriminator loss: 0.7247%, acc.: 34.77%][Generator loss: 0.7582%]\n",
      "580 [Discriminator loss: 0.7238%, acc.: 32.81%][Generator loss: 0.7916%]\n",
      "581 [Discriminator loss: 0.7033%, acc.: 40.23%][Generator loss: 0.7991%]\n",
      "582 [Discriminator loss: 0.7372%, acc.: 26.56%][Generator loss: 0.7858%]\n",
      "583 [Discriminator loss: 0.7283%, acc.: 30.47%][Generator loss: 0.7811%]\n",
      "584 [Discriminator loss: 0.7225%, acc.: 31.25%][Generator loss: 0.8106%]\n",
      "585 [Discriminator loss: 0.7152%, acc.: 38.28%][Generator loss: 0.8163%]\n",
      "586 [Discriminator loss: 0.7240%, acc.: 35.16%][Generator loss: 0.8391%]\n",
      "587 [Discriminator loss: 0.7352%, acc.: 30.08%][Generator loss: 0.7954%]\n",
      "588 [Discriminator loss: 0.7410%, acc.: 23.44%][Generator loss: 0.7722%]\n",
      "589 [Discriminator loss: 0.7145%, acc.: 35.55%][Generator loss: 0.8134%]\n",
      "590 [Discriminator loss: 0.7221%, acc.: 33.20%][Generator loss: 0.8245%]\n",
      "591 [Discriminator loss: 0.7473%, acc.: 25.00%][Generator loss: 0.7771%]\n",
      "592 [Discriminator loss: 0.7234%, acc.: 33.59%][Generator loss: 0.7692%]\n",
      "593 [Discriminator loss: 0.6957%, acc.: 50.39%][Generator loss: 0.7817%]\n",
      "594 [Discriminator loss: 0.7125%, acc.: 42.19%][Generator loss: 0.8705%]\n",
      "595 [Discriminator loss: 0.7169%, acc.: 47.27%][Generator loss: 0.8937%]\n",
      "596 [Discriminator loss: 0.7513%, acc.: 39.06%][Generator loss: 0.8161%]\n",
      "597 [Discriminator loss: 0.7268%, acc.: 41.02%][Generator loss: 0.7836%]\n",
      "598 [Discriminator loss: 0.7108%, acc.: 41.02%][Generator loss: 0.7739%]\n",
      "599 [Discriminator loss: 0.7010%, acc.: 50.00%][Generator loss: 0.7852%]\n",
      "600 [Discriminator loss: 0.7003%, acc.: 41.41%][Generator loss: 0.9169%]\n",
      "601 [Discriminator loss: 0.7193%, acc.: 49.61%][Generator loss: 0.9224%]\n",
      "602 [Discriminator loss: 0.7821%, acc.: 38.67%][Generator loss: 0.8094%]\n",
      "603 [Discriminator loss: 0.7383%, acc.: 35.55%][Generator loss: 0.7851%]\n",
      "604 [Discriminator loss: 0.7334%, acc.: 31.25%][Generator loss: 0.7603%]\n",
      "605 [Discriminator loss: 0.7233%, acc.: 35.94%][Generator loss: 0.7625%]\n",
      "606 [Discriminator loss: 0.7269%, acc.: 39.84%][Generator loss: 0.7435%]\n",
      "607 [Discriminator loss: 0.7160%, acc.: 28.52%][Generator loss: 0.8024%]\n",
      "608 [Discriminator loss: 0.7195%, acc.: 42.97%][Generator loss: 0.7928%]\n",
      "609 [Discriminator loss: 0.7480%, acc.: 26.17%][Generator loss: 0.7546%]\n",
      "610 [Discriminator loss: 0.7352%, acc.: 37.11%][Generator loss: 0.7833%]\n",
      "611 [Discriminator loss: 0.7098%, acc.: 40.62%][Generator loss: 0.8167%]\n",
      "612 [Discriminator loss: 0.7680%, acc.: 35.55%][Generator loss: 0.7798%]\n",
      "613 [Discriminator loss: 0.7437%, acc.: 31.25%][Generator loss: 0.7859%]\n",
      "614 [Discriminator loss: 0.7367%, acc.: 26.17%][Generator loss: 0.7658%]\n",
      "615 [Discriminator loss: 0.7296%, acc.: 37.50%][Generator loss: 0.8506%]\n",
      "616 [Discriminator loss: 0.7229%, acc.: 38.28%][Generator loss: 0.8634%]\n",
      "617 [Discriminator loss: 0.7892%, acc.: 23.83%][Generator loss: 0.7936%]\n",
      "618 [Discriminator loss: 0.7428%, acc.: 23.44%][Generator loss: 0.7547%]\n",
      "619 [Discriminator loss: 0.7267%, acc.: 30.47%][Generator loss: 0.8180%]\n",
      "620 [Discriminator loss: 0.7419%, acc.: 30.86%][Generator loss: 0.8200%]\n",
      "621 [Discriminator loss: 0.7403%, acc.: 26.17%][Generator loss: 0.7627%]\n",
      "622 [Discriminator loss: 0.7224%, acc.: 31.25%][Generator loss: 0.7753%]\n",
      "623 [Discriminator loss: 0.7291%, acc.: 39.45%][Generator loss: 0.7848%]\n",
      "624 [Discriminator loss: 0.7316%, acc.: 35.16%][Generator loss: 0.7571%]\n",
      "625 [Discriminator loss: 0.7330%, acc.: 30.86%][Generator loss: 0.8029%]\n",
      "626 [Discriminator loss: 0.7260%, acc.: 44.92%][Generator loss: 0.8019%]\n",
      "627 [Discriminator loss: 0.7357%, acc.: 29.69%][Generator loss: 0.7776%]\n",
      "628 [Discriminator loss: 0.7228%, acc.: 32.03%][Generator loss: 0.7656%]\n",
      "629 [Discriminator loss: 0.7124%, acc.: 26.56%][Generator loss: 0.7683%]\n",
      "630 [Discriminator loss: 0.6958%, acc.: 43.75%][Generator loss: 0.7741%]\n",
      "631 [Discriminator loss: 0.7167%, acc.: 33.59%][Generator loss: 0.8455%]\n",
      "632 [Discriminator loss: 0.7513%, acc.: 33.20%][Generator loss: 0.8743%]\n",
      "633 [Discriminator loss: 0.7569%, acc.: 26.56%][Generator loss: 0.8047%]\n",
      "634 [Discriminator loss: 0.7234%, acc.: 36.33%][Generator loss: 0.8085%]\n",
      "635 [Discriminator loss: 0.7080%, acc.: 39.45%][Generator loss: 0.7643%]\n",
      "636 [Discriminator loss: 0.7364%, acc.: 32.81%][Generator loss: 0.8652%]\n",
      "637 [Discriminator loss: 0.7144%, acc.: 35.16%][Generator loss: 0.8031%]\n",
      "638 [Discriminator loss: 0.7345%, acc.: 26.56%][Generator loss: 0.7539%]\n",
      "639 [Discriminator loss: 0.7173%, acc.: 32.81%][Generator loss: 0.7513%]\n",
      "640 [Discriminator loss: 0.7039%, acc.: 36.33%][Generator loss: 0.7654%]\n",
      "641 [Discriminator loss: 0.6859%, acc.: 48.83%][Generator loss: 0.7646%]\n",
      "642 [Discriminator loss: 0.7220%, acc.: 35.55%][Generator loss: 0.7306%]\n",
      "643 [Discriminator loss: 0.7309%, acc.: 38.67%][Generator loss: 0.7715%]\n",
      "644 [Discriminator loss: 0.7077%, acc.: 34.77%][Generator loss: 0.7602%]\n",
      "645 [Discriminator loss: 0.6969%, acc.: 39.84%][Generator loss: 0.8045%]\n",
      "646 [Discriminator loss: 0.7083%, acc.: 48.83%][Generator loss: 0.8296%]\n",
      "647 [Discriminator loss: 0.7313%, acc.: 34.38%][Generator loss: 0.7800%]\n",
      "648 [Discriminator loss: 0.6999%, acc.: 37.11%][Generator loss: 0.7621%]\n",
      "649 [Discriminator loss: 0.7327%, acc.: 33.98%][Generator loss: 0.7425%]\n",
      "650 [Discriminator loss: 0.7255%, acc.: 32.42%][Generator loss: 0.8014%]\n",
      "651 [Discriminator loss: 0.7093%, acc.: 43.75%][Generator loss: 0.8012%]\n",
      "652 [Discriminator loss: 0.7160%, acc.: 34.77%][Generator loss: 0.7846%]\n",
      "653 [Discriminator loss: 0.7002%, acc.: 42.97%][Generator loss: 0.7698%]\n",
      "654 [Discriminator loss: 0.7196%, acc.: 36.72%][Generator loss: 0.7763%]\n",
      "655 [Discriminator loss: 0.6763%, acc.: 57.81%][Generator loss: 0.7820%]\n",
      "656 [Discriminator loss: 0.7146%, acc.: 37.11%][Generator loss: 0.7813%]\n",
      "657 [Discriminator loss: 0.7181%, acc.: 41.41%][Generator loss: 0.7816%]\n",
      "658 [Discriminator loss: 0.7237%, acc.: 33.98%][Generator loss: 0.8829%]\n",
      "659 [Discriminator loss: 0.7292%, acc.: 38.67%][Generator loss: 0.8732%]\n",
      "660 [Discriminator loss: 0.7441%, acc.: 35.16%][Generator loss: 0.8057%]\n",
      "661 [Discriminator loss: 0.7293%, acc.: 34.77%][Generator loss: 0.7781%]\n",
      "662 [Discriminator loss: 0.6992%, acc.: 42.58%][Generator loss: 0.7878%]\n",
      "663 [Discriminator loss: 0.7206%, acc.: 42.58%][Generator loss: 0.7731%]\n",
      "664 [Discriminator loss: 0.7178%, acc.: 33.59%][Generator loss: 0.7699%]\n",
      "665 [Discriminator loss: 0.7200%, acc.: 44.14%][Generator loss: 0.7659%]\n",
      "666 [Discriminator loss: 0.6987%, acc.: 47.66%][Generator loss: 0.7887%]\n",
      "667 [Discriminator loss: 0.6812%, acc.: 56.64%][Generator loss: 0.7949%]\n",
      "668 [Discriminator loss: 0.7267%, acc.: 42.19%][Generator loss: 0.7854%]\n",
      "669 [Discriminator loss: 0.7222%, acc.: 47.27%][Generator loss: 0.8075%]\n",
      "670 [Discriminator loss: 0.7237%, acc.: 37.89%][Generator loss: 0.7517%]\n",
      "671 [Discriminator loss: 0.7145%, acc.: 40.62%][Generator loss: 0.8228%]\n",
      "672 [Discriminator loss: 0.6962%, acc.: 56.64%][Generator loss: 0.8715%]\n",
      "673 [Discriminator loss: 0.7619%, acc.: 34.77%][Generator loss: 0.8005%]\n",
      "674 [Discriminator loss: 0.7299%, acc.: 32.81%][Generator loss: 0.8017%]\n",
      "675 [Discriminator loss: 0.7229%, acc.: 40.62%][Generator loss: 0.7679%]\n",
      "676 [Discriminator loss: 0.7333%, acc.: 33.98%][Generator loss: 0.7825%]\n",
      "677 [Discriminator loss: 0.7350%, acc.: 36.33%][Generator loss: 0.8008%]\n",
      "678 [Discriminator loss: 0.7176%, acc.: 42.97%][Generator loss: 0.8049%]\n",
      "679 [Discriminator loss: 0.7279%, acc.: 35.16%][Generator loss: 0.7631%]\n",
      "680 [Discriminator loss: 0.7067%, acc.: 39.84%][Generator loss: 0.7968%]\n",
      "681 [Discriminator loss: 0.6995%, acc.: 46.88%][Generator loss: 0.7991%]\n",
      "682 [Discriminator loss: 0.7231%, acc.: 38.67%][Generator loss: 0.8622%]\n",
      "683 [Discriminator loss: 0.7246%, acc.: 39.45%][Generator loss: 0.8537%]\n",
      "684 [Discriminator loss: 0.7329%, acc.: 37.11%][Generator loss: 0.7886%]\n",
      "685 [Discriminator loss: 0.7193%, acc.: 35.94%][Generator loss: 0.7658%]\n",
      "686 [Discriminator loss: 0.6975%, acc.: 42.19%][Generator loss: 0.8030%]\n",
      "687 [Discriminator loss: 0.7098%, acc.: 46.48%][Generator loss: 0.7957%]\n",
      "688 [Discriminator loss: 0.7104%, acc.: 41.80%][Generator loss: 0.7844%]\n",
      "689 [Discriminator loss: 0.7071%, acc.: 43.36%][Generator loss: 0.7971%]\n",
      "690 [Discriminator loss: 0.7199%, acc.: 39.45%][Generator loss: 0.7752%]\n",
      "691 [Discriminator loss: 0.7011%, acc.: 51.56%][Generator loss: 0.7901%]\n",
      "692 [Discriminator loss: 0.7101%, acc.: 37.50%][Generator loss: 0.7825%]\n",
      "693 [Discriminator loss: 0.6863%, acc.: 42.58%][Generator loss: 0.7774%]\n",
      "694 [Discriminator loss: 0.6887%, acc.: 58.59%][Generator loss: 0.8093%]\n",
      "695 [Discriminator loss: 0.7267%, acc.: 35.94%][Generator loss: 0.8500%]\n",
      "696 [Discriminator loss: 0.7288%, acc.: 47.27%][Generator loss: 0.8965%]\n",
      "697 [Discriminator loss: 0.7512%, acc.: 33.59%][Generator loss: 0.8241%]\n",
      "698 [Discriminator loss: 0.7129%, acc.: 39.06%][Generator loss: 0.7959%]\n",
      "699 [Discriminator loss: 0.7249%, acc.: 38.67%][Generator loss: 0.7701%]\n",
      "700 [Discriminator loss: 0.7082%, acc.: 43.75%][Generator loss: 0.7696%]\n",
      "701 [Discriminator loss: 0.6893%, acc.: 50.00%][Generator loss: 0.7903%]\n",
      "702 [Discriminator loss: 0.7161%, acc.: 30.47%][Generator loss: 0.7494%]\n",
      "703 [Discriminator loss: 0.6994%, acc.: 42.19%][Generator loss: 0.9329%]\n",
      "704 [Discriminator loss: 0.7327%, acc.: 46.48%][Generator loss: 0.9261%]\n",
      "705 [Discriminator loss: 0.7716%, acc.: 35.16%][Generator loss: 0.8240%]\n",
      "706 [Discriminator loss: 0.7274%, acc.: 35.55%][Generator loss: 0.8209%]\n",
      "707 [Discriminator loss: 0.7163%, acc.: 35.94%][Generator loss: 0.7806%]\n",
      "708 [Discriminator loss: 0.7251%, acc.: 35.16%][Generator loss: 0.7686%]\n",
      "709 [Discriminator loss: 0.7306%, acc.: 32.42%][Generator loss: 0.7475%]\n",
      "710 [Discriminator loss: 0.7065%, acc.: 34.77%][Generator loss: 0.7408%]\n",
      "711 [Discriminator loss: 0.7031%, acc.: 45.31%][Generator loss: 0.8294%]\n",
      "712 [Discriminator loss: 0.7224%, acc.: 38.67%][Generator loss: 0.8104%]\n",
      "713 [Discriminator loss: 0.7418%, acc.: 36.33%][Generator loss: 0.7596%]\n",
      "714 [Discriminator loss: 0.7174%, acc.: 36.72%][Generator loss: 0.8363%]\n",
      "715 [Discriminator loss: 0.7014%, acc.: 48.83%][Generator loss: 0.8326%]\n",
      "716 [Discriminator loss: 0.7322%, acc.: 28.52%][Generator loss: 0.7871%]\n",
      "717 [Discriminator loss: 0.7137%, acc.: 41.41%][Generator loss: 0.8384%]\n",
      "718 [Discriminator loss: 0.7194%, acc.: 44.92%][Generator loss: 0.8209%]\n",
      "719 [Discriminator loss: 0.7123%, acc.: 39.84%][Generator loss: 0.7731%]\n",
      "720 [Discriminator loss: 0.7065%, acc.: 37.89%][Generator loss: 0.7992%]\n",
      "721 [Discriminator loss: 0.7065%, acc.: 39.06%][Generator loss: 0.7762%]\n",
      "722 [Discriminator loss: 0.7148%, acc.: 33.59%][Generator loss: 0.7911%]\n",
      "723 [Discriminator loss: 0.6962%, acc.: 52.73%][Generator loss: 0.8053%]\n",
      "724 [Discriminator loss: 0.7188%, acc.: 43.36%][Generator loss: 0.7652%]\n",
      "725 [Discriminator loss: 0.7222%, acc.: 38.67%][Generator loss: 0.7680%]\n",
      "726 [Discriminator loss: 0.7111%, acc.: 44.14%][Generator loss: 0.7932%]\n",
      "727 [Discriminator loss: 0.7087%, acc.: 39.84%][Generator loss: 0.8112%]\n",
      "728 [Discriminator loss: 0.6912%, acc.: 47.66%][Generator loss: 0.7691%]\n",
      "729 [Discriminator loss: 0.6903%, acc.: 51.17%][Generator loss: 1.0502%]\n",
      "730 [Discriminator loss: 0.7859%, acc.: 46.88%][Generator loss: 0.9505%]\n",
      "731 [Discriminator loss: 0.7602%, acc.: 41.80%][Generator loss: 0.8564%]\n",
      "732 [Discriminator loss: 0.7306%, acc.: 44.92%][Generator loss: 0.8442%]\n",
      "733 [Discriminator loss: 0.7202%, acc.: 35.55%][Generator loss: 0.8036%]\n",
      "734 [Discriminator loss: 0.7104%, acc.: 36.33%][Generator loss: 0.7846%]\n",
      "735 [Discriminator loss: 0.6976%, acc.: 43.75%][Generator loss: 0.7940%]\n",
      "736 [Discriminator loss: 0.7173%, acc.: 41.41%][Generator loss: 0.7804%]\n",
      "737 [Discriminator loss: 0.7135%, acc.: 39.84%][Generator loss: 0.7623%]\n",
      "738 [Discriminator loss: 0.7040%, acc.: 43.36%][Generator loss: 0.7527%]\n",
      "739 [Discriminator loss: 0.7092%, acc.: 45.70%][Generator loss: 0.7577%]\n",
      "740 [Discriminator loss: 0.7173%, acc.: 41.02%][Generator loss: 0.7708%]\n",
      "741 [Discriminator loss: 0.7022%, acc.: 43.36%][Generator loss: 0.7362%]\n",
      "742 [Discriminator loss: 0.7137%, acc.: 43.75%][Generator loss: 0.9478%]\n",
      "743 [Discriminator loss: 0.7292%, acc.: 54.30%][Generator loss: 0.9107%]\n",
      "744 [Discriminator loss: 0.7493%, acc.: 46.48%][Generator loss: 0.8305%]\n",
      "745 [Discriminator loss: 0.7607%, acc.: 32.81%][Generator loss: 0.7819%]\n",
      "746 [Discriminator loss: 0.7340%, acc.: 37.50%][Generator loss: 0.7721%]\n",
      "747 [Discriminator loss: 0.7262%, acc.: 37.50%][Generator loss: 0.7447%]\n",
      "748 [Discriminator loss: 0.7364%, acc.: 38.28%][Generator loss: 0.7382%]\n",
      "749 [Discriminator loss: 0.7199%, acc.: 37.50%][Generator loss: 0.7261%]\n",
      "750 [Discriminator loss: 0.7051%, acc.: 50.39%][Generator loss: 0.7442%]\n",
      "751 [Discriminator loss: 0.7130%, acc.: 43.36%][Generator loss: 0.7434%]\n",
      "752 [Discriminator loss: 0.7209%, acc.: 35.55%][Generator loss: 0.7602%]\n",
      "753 [Discriminator loss: 0.7030%, acc.: 51.95%][Generator loss: 0.7711%]\n",
      "754 [Discriminator loss: 0.7146%, acc.: 36.33%][Generator loss: 0.7731%]\n",
      "755 [Discriminator loss: 0.6957%, acc.: 48.44%][Generator loss: 0.7960%]\n",
      "756 [Discriminator loss: 0.7188%, acc.: 45.31%][Generator loss: 0.7691%]\n",
      "757 [Discriminator loss: 0.7242%, acc.: 33.59%][Generator loss: 0.8227%]\n",
      "758 [Discriminator loss: 0.6855%, acc.: 60.94%][Generator loss: 0.8743%]\n",
      "759 [Discriminator loss: 0.7582%, acc.: 30.08%][Generator loss: 0.7800%]\n",
      "760 [Discriminator loss: 0.7248%, acc.: 40.62%][Generator loss: 0.7994%]\n",
      "761 [Discriminator loss: 0.7097%, acc.: 42.97%][Generator loss: 0.7826%]\n",
      "762 [Discriminator loss: 0.7263%, acc.: 35.55%][Generator loss: 0.7488%]\n",
      "763 [Discriminator loss: 0.7061%, acc.: 39.84%][Generator loss: 0.7614%]\n",
      "764 [Discriminator loss: 0.7014%, acc.: 44.92%][Generator loss: 0.7598%]\n",
      "765 [Discriminator loss: 0.7200%, acc.: 35.94%][Generator loss: 0.7642%]\n",
      "766 [Discriminator loss: 0.7109%, acc.: 48.05%][Generator loss: 0.7604%]\n",
      "767 [Discriminator loss: 0.6970%, acc.: 50.39%][Generator loss: 0.7558%]\n",
      "768 [Discriminator loss: 0.7073%, acc.: 46.09%][Generator loss: 0.8915%]\n",
      "769 [Discriminator loss: 0.7130%, acc.: 57.03%][Generator loss: 0.9117%]\n",
      "770 [Discriminator loss: 0.7501%, acc.: 41.02%][Generator loss: 0.8343%]\n",
      "771 [Discriminator loss: 0.7358%, acc.: 41.02%][Generator loss: 0.7874%]\n",
      "772 [Discriminator loss: 0.6972%, acc.: 46.09%][Generator loss: 0.7792%]\n",
      "773 [Discriminator loss: 0.7018%, acc.: 48.83%][Generator loss: 0.7613%]\n",
      "774 [Discriminator loss: 0.7071%, acc.: 48.83%][Generator loss: 0.7850%]\n",
      "775 [Discriminator loss: 0.6904%, acc.: 50.00%][Generator loss: 0.7726%]\n",
      "776 [Discriminator loss: 0.6957%, acc.: 51.17%][Generator loss: 0.8158%]\n",
      "777 [Discriminator loss: 0.7159%, acc.: 44.14%][Generator loss: 0.8043%]\n",
      "778 [Discriminator loss: 0.7237%, acc.: 40.23%][Generator loss: 0.7714%]\n",
      "779 [Discriminator loss: 0.7083%, acc.: 39.84%][Generator loss: 0.8302%]\n",
      "780 [Discriminator loss: 0.6921%, acc.: 56.64%][Generator loss: 0.8248%]\n",
      "781 [Discriminator loss: 0.7465%, acc.: 32.42%][Generator loss: 0.7882%]\n",
      "782 [Discriminator loss: 0.7188%, acc.: 44.53%][Generator loss: 0.7537%]\n",
      "783 [Discriminator loss: 0.6973%, acc.: 51.17%][Generator loss: 0.7865%]\n",
      "784 [Discriminator loss: 0.7211%, acc.: 50.00%][Generator loss: 0.7778%]\n",
      "785 [Discriminator loss: 0.7028%, acc.: 41.02%][Generator loss: 0.8406%]\n",
      "786 [Discriminator loss: 0.6900%, acc.: 57.81%][Generator loss: 0.8536%]\n",
      "787 [Discriminator loss: 0.7473%, acc.: 31.64%][Generator loss: 0.8217%]\n",
      "788 [Discriminator loss: 0.7206%, acc.: 45.31%][Generator loss: 0.7789%]\n",
      "789 [Discriminator loss: 0.7059%, acc.: 47.27%][Generator loss: 0.8295%]\n",
      "790 [Discriminator loss: 0.7041%, acc.: 48.83%][Generator loss: 0.8369%]\n",
      "791 [Discriminator loss: 0.7453%, acc.: 33.20%][Generator loss: 0.7945%]\n",
      "792 [Discriminator loss: 0.7087%, acc.: 37.89%][Generator loss: 0.7578%]\n",
      "793 [Discriminator loss: 0.7055%, acc.: 39.45%][Generator loss: 0.7706%]\n",
      "794 [Discriminator loss: 0.6960%, acc.: 53.52%][Generator loss: 0.7692%]\n",
      "795 [Discriminator loss: 0.7245%, acc.: 35.94%][Generator loss: 0.7829%]\n",
      "796 [Discriminator loss: 0.7148%, acc.: 46.09%][Generator loss: 0.7913%]\n",
      "797 [Discriminator loss: 0.7100%, acc.: 38.28%][Generator loss: 0.7632%]\n",
      "798 [Discriminator loss: 0.7064%, acc.: 43.75%][Generator loss: 0.8546%]\n",
      "799 [Discriminator loss: 0.6977%, acc.: 55.86%][Generator loss: 0.9016%]\n",
      "800 [Discriminator loss: 0.7608%, acc.: 35.94%][Generator loss: 0.7991%]\n",
      "801 [Discriminator loss: 0.7088%, acc.: 43.75%][Generator loss: 0.7730%]\n",
      "802 [Discriminator loss: 0.7108%, acc.: 43.36%][Generator loss: 0.7633%]\n",
      "803 [Discriminator loss: 0.7112%, acc.: 43.75%][Generator loss: 0.7609%]\n",
      "804 [Discriminator loss: 0.6941%, acc.: 50.78%][Generator loss: 0.7866%]\n",
      "805 [Discriminator loss: 0.7151%, acc.: 43.75%][Generator loss: 0.7832%]\n",
      "806 [Discriminator loss: 0.7098%, acc.: 46.48%][Generator loss: 0.8344%]\n",
      "807 [Discriminator loss: 0.7197%, acc.: 42.97%][Generator loss: 0.7748%]\n",
      "808 [Discriminator loss: 0.7172%, acc.: 40.23%][Generator loss: 0.7948%]\n",
      "809 [Discriminator loss: 0.6987%, acc.: 50.00%][Generator loss: 0.7906%]\n",
      "810 [Discriminator loss: 0.7216%, acc.: 35.16%][Generator loss: 0.7785%]\n",
      "811 [Discriminator loss: 0.7118%, acc.: 46.88%][Generator loss: 0.7713%]\n",
      "812 [Discriminator loss: 0.7382%, acc.: 26.95%][Generator loss: 0.9190%]\n",
      "813 [Discriminator loss: 0.7253%, acc.: 46.48%][Generator loss: 0.8476%]\n",
      "814 [Discriminator loss: 0.7463%, acc.: 28.12%][Generator loss: 0.7900%]\n",
      "815 [Discriminator loss: 0.7153%, acc.: 39.84%][Generator loss: 0.7802%]\n",
      "816 [Discriminator loss: 0.7208%, acc.: 36.72%][Generator loss: 0.7633%]\n",
      "817 [Discriminator loss: 0.7143%, acc.: 42.58%][Generator loss: 0.7417%]\n",
      "818 [Discriminator loss: 0.7063%, acc.: 42.97%][Generator loss: 0.8138%]\n",
      "819 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7903%]\n",
      "820 [Discriminator loss: 0.7019%, acc.: 42.58%][Generator loss: 0.7970%]\n",
      "821 [Discriminator loss: 0.7144%, acc.: 45.70%][Generator loss: 0.8135%]\n",
      "822 [Discriminator loss: 0.7259%, acc.: 29.30%][Generator loss: 0.7711%]\n",
      "823 [Discriminator loss: 0.7046%, acc.: 44.53%][Generator loss: 0.7908%]\n",
      "824 [Discriminator loss: 0.7127%, acc.: 46.88%][Generator loss: 0.8163%]\n",
      "825 [Discriminator loss: 0.7195%, acc.: 38.28%][Generator loss: 0.7726%]\n",
      "826 [Discriminator loss: 0.7068%, acc.: 48.83%][Generator loss: 0.7746%]\n",
      "827 [Discriminator loss: 0.7109%, acc.: 37.89%][Generator loss: 1.0799%]\n",
      "828 [Discriminator loss: 0.7450%, acc.: 48.44%][Generator loss: 0.9481%]\n",
      "829 [Discriminator loss: 0.7429%, acc.: 43.75%][Generator loss: 0.8614%]\n",
      "830 [Discriminator loss: 0.7281%, acc.: 40.62%][Generator loss: 0.8093%]\n",
      "831 [Discriminator loss: 0.7069%, acc.: 47.27%][Generator loss: 0.7819%]\n",
      "832 [Discriminator loss: 0.7045%, acc.: 37.50%][Generator loss: 0.7704%]\n",
      "833 [Discriminator loss: 0.7052%, acc.: 48.05%][Generator loss: 0.7729%]\n",
      "834 [Discriminator loss: 0.6934%, acc.: 43.75%][Generator loss: 0.7695%]\n",
      "835 [Discriminator loss: 0.7092%, acc.: 43.75%][Generator loss: 0.7648%]\n",
      "836 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7703%]\n",
      "837 [Discriminator loss: 0.6803%, acc.: 44.53%][Generator loss: 0.7768%]\n",
      "838 [Discriminator loss: 0.6771%, acc.: 58.20%][Generator loss: 0.8325%]\n",
      "839 [Discriminator loss: 0.7105%, acc.: 46.09%][Generator loss: 0.7736%]\n",
      "840 [Discriminator loss: 0.7137%, acc.: 40.62%][Generator loss: 0.7832%]\n",
      "841 [Discriminator loss: 0.7041%, acc.: 50.39%][Generator loss: 0.7871%]\n",
      "842 [Discriminator loss: 0.7023%, acc.: 44.92%][Generator loss: 0.7832%]\n",
      "843 [Discriminator loss: 0.6893%, acc.: 45.70%][Generator loss: 0.7804%]\n",
      "844 [Discriminator loss: 0.6909%, acc.: 44.53%][Generator loss: 0.8094%]\n",
      "845 [Discriminator loss: 0.6981%, acc.: 51.56%][Generator loss: 0.8192%]\n",
      "846 [Discriminator loss: 0.7526%, acc.: 33.20%][Generator loss: 0.7751%]\n",
      "847 [Discriminator loss: 0.7209%, acc.: 37.11%][Generator loss: 0.7729%]\n",
      "848 [Discriminator loss: 0.7048%, acc.: 39.06%][Generator loss: 0.7772%]\n",
      "849 [Discriminator loss: 0.6801%, acc.: 52.73%][Generator loss: 0.7956%]\n",
      "850 [Discriminator loss: 0.7128%, acc.: 40.23%][Generator loss: 0.8518%]\n",
      "851 [Discriminator loss: 0.6970%, acc.: 52.73%][Generator loss: 0.8989%]\n",
      "852 [Discriminator loss: 0.7613%, acc.: 35.55%][Generator loss: 0.8051%]\n",
      "853 [Discriminator loss: 0.7090%, acc.: 44.92%][Generator loss: 0.7848%]\n",
      "854 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7660%]\n",
      "855 [Discriminator loss: 0.6962%, acc.: 43.36%][Generator loss: 0.9170%]\n",
      "856 [Discriminator loss: 0.7322%, acc.: 45.70%][Generator loss: 0.8530%]\n",
      "857 [Discriminator loss: 0.7159%, acc.: 45.31%][Generator loss: 0.8151%]\n",
      "858 [Discriminator loss: 0.7215%, acc.: 40.62%][Generator loss: 0.7685%]\n",
      "859 [Discriminator loss: 0.7069%, acc.: 47.66%][Generator loss: 0.7790%]\n",
      "860 [Discriminator loss: 0.6957%, acc.: 47.27%][Generator loss: 0.8067%]\n",
      "861 [Discriminator loss: 0.6791%, acc.: 60.94%][Generator loss: 0.8550%]\n",
      "862 [Discriminator loss: 0.7320%, acc.: 37.89%][Generator loss: 0.7676%]\n",
      "863 [Discriminator loss: 0.7278%, acc.: 39.06%][Generator loss: 0.8050%]\n",
      "864 [Discriminator loss: 0.7042%, acc.: 47.27%][Generator loss: 0.8245%]\n",
      "865 [Discriminator loss: 0.7314%, acc.: 38.67%][Generator loss: 0.8054%]\n",
      "866 [Discriminator loss: 0.7087%, acc.: 44.53%][Generator loss: 0.7917%]\n",
      "867 [Discriminator loss: 0.7124%, acc.: 39.06%][Generator loss: 0.7827%]\n",
      "868 [Discriminator loss: 0.7112%, acc.: 49.61%][Generator loss: 0.7836%]\n",
      "869 [Discriminator loss: 0.7059%, acc.: 39.84%][Generator loss: 0.7909%]\n",
      "870 [Discriminator loss: 0.7049%, acc.: 48.05%][Generator loss: 0.8184%]\n",
      "871 [Discriminator loss: 0.7275%, acc.: 39.45%][Generator loss: 0.7893%]\n",
      "872 [Discriminator loss: 0.7052%, acc.: 47.66%][Generator loss: 0.7678%]\n",
      "873 [Discriminator loss: 0.6893%, acc.: 50.00%][Generator loss: 0.7834%]\n",
      "874 [Discriminator loss: 0.7146%, acc.: 38.28%][Generator loss: 0.8650%]\n",
      "875 [Discriminator loss: 0.6973%, acc.: 54.30%][Generator loss: 0.8925%]\n",
      "876 [Discriminator loss: 0.7473%, acc.: 41.02%][Generator loss: 0.7793%]\n",
      "877 [Discriminator loss: 0.7263%, acc.: 41.02%][Generator loss: 0.7621%]\n",
      "878 [Discriminator loss: 0.6984%, acc.: 48.83%][Generator loss: 0.7535%]\n",
      "879 [Discriminator loss: 0.7097%, acc.: 48.05%][Generator loss: 0.7650%]\n",
      "880 [Discriminator loss: 0.7024%, acc.: 44.92%][Generator loss: 0.8106%]\n",
      "881 [Discriminator loss: 0.7034%, acc.: 49.61%][Generator loss: 0.8444%]\n",
      "882 [Discriminator loss: 0.7509%, acc.: 35.16%][Generator loss: 0.7831%]\n",
      "883 [Discriminator loss: 0.7270%, acc.: 41.02%][Generator loss: 0.7891%]\n",
      "884 [Discriminator loss: 0.6999%, acc.: 49.22%][Generator loss: 0.7661%]\n",
      "885 [Discriminator loss: 0.7220%, acc.: 39.06%][Generator loss: 0.8028%]\n",
      "886 [Discriminator loss: 0.7072%, acc.: 52.34%][Generator loss: 0.8403%]\n",
      "887 [Discriminator loss: 0.7246%, acc.: 42.19%][Generator loss: 0.7818%]\n",
      "888 [Discriminator loss: 0.7117%, acc.: 43.36%][Generator loss: 0.7474%]\n",
      "889 [Discriminator loss: 0.7144%, acc.: 50.78%][Generator loss: 0.7669%]\n",
      "890 [Discriminator loss: 0.7270%, acc.: 39.45%][Generator loss: 0.7669%]\n",
      "891 [Discriminator loss: 0.7117%, acc.: 38.67%][Generator loss: 0.7851%]\n",
      "892 [Discriminator loss: 0.7041%, acc.: 48.83%][Generator loss: 0.8037%]\n",
      "893 [Discriminator loss: 0.7141%, acc.: 39.06%][Generator loss: 0.7631%]\n",
      "894 [Discriminator loss: 0.6949%, acc.: 44.53%][Generator loss: 0.9091%]\n",
      "895 [Discriminator loss: 0.7118%, acc.: 55.86%][Generator loss: 0.8961%]\n",
      "896 [Discriminator loss: 0.7644%, acc.: 30.47%][Generator loss: 0.8069%]\n",
      "897 [Discriminator loss: 0.7148%, acc.: 40.23%][Generator loss: 0.7892%]\n",
      "898 [Discriminator loss: 0.6944%, acc.: 53.12%][Generator loss: 0.7775%]\n",
      "899 [Discriminator loss: 0.7100%, acc.: 42.58%][Generator loss: 0.7751%]\n",
      "900 [Discriminator loss: 0.7094%, acc.: 37.50%][Generator loss: 0.7612%]\n",
      "901 [Discriminator loss: 0.6845%, acc.: 51.17%][Generator loss: 0.7642%]\n",
      "902 [Discriminator loss: 0.6988%, acc.: 55.86%][Generator loss: 0.7720%]\n",
      "903 [Discriminator loss: 0.7189%, acc.: 41.02%][Generator loss: 0.7829%]\n",
      "904 [Discriminator loss: 0.6898%, acc.: 59.77%][Generator loss: 0.8183%]\n",
      "905 [Discriminator loss: 0.7504%, acc.: 37.11%][Generator loss: 0.7854%]\n",
      "906 [Discriminator loss: 0.7039%, acc.: 50.39%][Generator loss: 0.7901%]\n",
      "907 [Discriminator loss: 0.7085%, acc.: 43.75%][Generator loss: 0.8730%]\n",
      "908 [Discriminator loss: 0.6833%, acc.: 60.55%][Generator loss: 0.8987%]\n",
      "909 [Discriminator loss: 0.7419%, acc.: 39.06%][Generator loss: 0.8196%]\n",
      "910 [Discriminator loss: 0.7260%, acc.: 40.62%][Generator loss: 0.7778%]\n",
      "911 [Discriminator loss: 0.7114%, acc.: 39.84%][Generator loss: 0.7654%]\n",
      "912 [Discriminator loss: 0.7092%, acc.: 47.27%][Generator loss: 0.7512%]\n",
      "913 [Discriminator loss: 0.7052%, acc.: 46.09%][Generator loss: 0.8171%]\n",
      "914 [Discriminator loss: 0.7074%, acc.: 51.17%][Generator loss: 0.7974%]\n",
      "915 [Discriminator loss: 0.7284%, acc.: 36.33%][Generator loss: 0.7802%]\n",
      "916 [Discriminator loss: 0.7021%, acc.: 47.27%][Generator loss: 0.8268%]\n",
      "917 [Discriminator loss: 0.7189%, acc.: 44.53%][Generator loss: 0.8425%]\n",
      "918 [Discriminator loss: 0.7532%, acc.: 35.16%][Generator loss: 0.7607%]\n",
      "919 [Discriminator loss: 0.7073%, acc.: 41.80%][Generator loss: 0.8008%]\n",
      "920 [Discriminator loss: 0.7111%, acc.: 48.83%][Generator loss: 0.7898%]\n",
      "921 [Discriminator loss: 0.7487%, acc.: 33.98%][Generator loss: 0.7474%]\n",
      "922 [Discriminator loss: 0.7057%, acc.: 47.66%][Generator loss: 0.7664%]\n",
      "923 [Discriminator loss: 0.7095%, acc.: 37.50%][Generator loss: 0.7806%]\n",
      "924 [Discriminator loss: 0.6821%, acc.: 56.64%][Generator loss: 0.8154%]\n",
      "925 [Discriminator loss: 0.7305%, acc.: 29.69%][Generator loss: 0.7810%]\n",
      "926 [Discriminator loss: 0.7210%, acc.: 36.33%][Generator loss: 0.7813%]\n",
      "927 [Discriminator loss: 0.7091%, acc.: 39.45%][Generator loss: 0.7713%]\n",
      "928 [Discriminator loss: 0.7097%, acc.: 44.92%][Generator loss: 0.7586%]\n",
      "929 [Discriminator loss: 0.6846%, acc.: 51.17%][Generator loss: 0.8018%]\n",
      "930 [Discriminator loss: 0.7315%, acc.: 38.67%][Generator loss: 1.0037%]\n",
      "931 [Discriminator loss: 0.7409%, acc.: 46.88%][Generator loss: 0.9010%]\n",
      "932 [Discriminator loss: 0.7468%, acc.: 39.06%][Generator loss: 0.8299%]\n",
      "933 [Discriminator loss: 0.7124%, acc.: 44.92%][Generator loss: 0.8095%]\n",
      "934 [Discriminator loss: 0.7135%, acc.: 41.41%][Generator loss: 0.7792%]\n",
      "935 [Discriminator loss: 0.7073%, acc.: 45.31%][Generator loss: 0.7494%]\n",
      "936 [Discriminator loss: 0.6977%, acc.: 53.52%][Generator loss: 0.7774%]\n",
      "937 [Discriminator loss: 0.7047%, acc.: 48.05%][Generator loss: 0.7636%]\n",
      "938 [Discriminator loss: 0.7140%, acc.: 44.53%][Generator loss: 0.7541%]\n",
      "939 [Discriminator loss: 0.7150%, acc.: 40.23%][Generator loss: 0.8371%]\n",
      "940 [Discriminator loss: 0.7081%, acc.: 49.22%][Generator loss: 0.8440%]\n",
      "941 [Discriminator loss: 0.7399%, acc.: 32.42%][Generator loss: 0.7706%]\n",
      "942 [Discriminator loss: 0.7047%, acc.: 37.11%][Generator loss: 0.7641%]\n",
      "943 [Discriminator loss: 0.6893%, acc.: 54.30%][Generator loss: 0.7719%]\n",
      "944 [Discriminator loss: 0.7145%, acc.: 40.23%][Generator loss: 0.8143%]\n",
      "945 [Discriminator loss: 0.7031%, acc.: 48.05%][Generator loss: 0.8156%]\n",
      "946 [Discriminator loss: 0.7187%, acc.: 37.50%][Generator loss: 0.7697%]\n",
      "947 [Discriminator loss: 0.7089%, acc.: 41.41%][Generator loss: 0.7866%]\n",
      "948 [Discriminator loss: 0.7161%, acc.: 41.41%][Generator loss: 0.7788%]\n",
      "949 [Discriminator loss: 0.7100%, acc.: 38.28%][Generator loss: 0.8136%]\n",
      "950 [Discriminator loss: 0.7103%, acc.: 54.30%][Generator loss: 0.8416%]\n",
      "951 [Discriminator loss: 0.7509%, acc.: 32.03%][Generator loss: 0.7876%]\n",
      "952 [Discriminator loss: 0.7199%, acc.: 37.11%][Generator loss: 0.7936%]\n",
      "953 [Discriminator loss: 0.7050%, acc.: 44.53%][Generator loss: 0.8088%]\n",
      "954 [Discriminator loss: 0.7370%, acc.: 39.06%][Generator loss: 0.8211%]\n",
      "955 [Discriminator loss: 0.7227%, acc.: 42.97%][Generator loss: 0.8009%]\n",
      "956 [Discriminator loss: 0.7167%, acc.: 37.50%][Generator loss: 0.7672%]\n",
      "957 [Discriminator loss: 0.7031%, acc.: 41.02%][Generator loss: 0.7841%]\n",
      "958 [Discriminator loss: 0.7015%, acc.: 47.66%][Generator loss: 0.7892%]\n",
      "959 [Discriminator loss: 0.7307%, acc.: 34.77%][Generator loss: 0.7535%]\n",
      "960 [Discriminator loss: 0.7208%, acc.: 38.67%][Generator loss: 0.7365%]\n",
      "961 [Discriminator loss: 0.6973%, acc.: 46.09%][Generator loss: 0.7636%]\n",
      "962 [Discriminator loss: 0.6922%, acc.: 49.61%][Generator loss: 0.7864%]\n",
      "963 [Discriminator loss: 0.7152%, acc.: 43.36%][Generator loss: 0.7604%]\n",
      "964 [Discriminator loss: 0.7093%, acc.: 47.27%][Generator loss: 0.7597%]\n",
      "965 [Discriminator loss: 0.7155%, acc.: 43.36%][Generator loss: 0.7536%]\n",
      "966 [Discriminator loss: 0.7109%, acc.: 43.36%][Generator loss: 0.7621%]\n",
      "967 [Discriminator loss: 0.7075%, acc.: 42.19%][Generator loss: 0.7826%]\n",
      "968 [Discriminator loss: 0.7146%, acc.: 38.28%][Generator loss: 0.8504%]\n",
      "969 [Discriminator loss: 0.7138%, acc.: 53.91%][Generator loss: 0.8506%]\n",
      "970 [Discriminator loss: 0.7576%, acc.: 26.17%][Generator loss: 0.7865%]\n",
      "971 [Discriminator loss: 0.7323%, acc.: 33.98%][Generator loss: 0.7534%]\n",
      "972 [Discriminator loss: 0.7128%, acc.: 41.80%][Generator loss: 0.7512%]\n",
      "973 [Discriminator loss: 0.7127%, acc.: 42.58%][Generator loss: 0.7491%]\n",
      "974 [Discriminator loss: 0.7008%, acc.: 45.31%][Generator loss: 0.7930%]\n",
      "975 [Discriminator loss: 0.7046%, acc.: 53.52%][Generator loss: 0.8479%]\n",
      "976 [Discriminator loss: 0.7711%, acc.: 30.86%][Generator loss: 0.7561%]\n",
      "977 [Discriminator loss: 0.7340%, acc.: 32.81%][Generator loss: 0.7413%]\n",
      "978 [Discriminator loss: 0.7168%, acc.: 38.28%][Generator loss: 0.7474%]\n",
      "979 [Discriminator loss: 0.7164%, acc.: 38.28%][Generator loss: 0.7348%]\n",
      "980 [Discriminator loss: 0.7211%, acc.: 39.45%][Generator loss: 0.7441%]\n",
      "981 [Discriminator loss: 0.7045%, acc.: 42.58%][Generator loss: 0.7816%]\n",
      "982 [Discriminator loss: 0.7053%, acc.: 51.95%][Generator loss: 0.8577%]\n",
      "983 [Discriminator loss: 0.7485%, acc.: 33.59%][Generator loss: 0.7839%]\n",
      "984 [Discriminator loss: 0.7199%, acc.: 38.67%][Generator loss: 0.7626%]\n",
      "985 [Discriminator loss: 0.7205%, acc.: 41.02%][Generator loss: 0.7613%]\n",
      "986 [Discriminator loss: 0.6963%, acc.: 47.66%][Generator loss: 0.7754%]\n",
      "987 [Discriminator loss: 0.7223%, acc.: 37.89%][Generator loss: 0.7576%]\n",
      "988 [Discriminator loss: 0.7205%, acc.: 35.16%][Generator loss: 0.7545%]\n",
      "989 [Discriminator loss: 0.7277%, acc.: 35.94%][Generator loss: 0.7821%]\n",
      "990 [Discriminator loss: 0.7205%, acc.: 44.92%][Generator loss: 0.8376%]\n",
      "991 [Discriminator loss: 0.7356%, acc.: 31.64%][Generator loss: 0.7836%]\n",
      "992 [Discriminator loss: 0.7385%, acc.: 32.03%][Generator loss: 0.7667%]\n",
      "993 [Discriminator loss: 0.7233%, acc.: 39.06%][Generator loss: 0.7424%]\n",
      "994 [Discriminator loss: 0.7066%, acc.: 45.31%][Generator loss: 0.7815%]\n",
      "995 [Discriminator loss: 0.7170%, acc.: 43.36%][Generator loss: 0.8111%]\n",
      "996 [Discriminator loss: 0.7222%, acc.: 32.42%][Generator loss: 0.7687%]\n",
      "997 [Discriminator loss: 0.7190%, acc.: 38.67%][Generator loss: 0.7692%]\n",
      "998 [Discriminator loss: 0.7247%, acc.: 41.02%][Generator loss: 0.7943%]\n",
      "999 [Discriminator loss: 0.7184%, acc.: 39.45%][Generator loss: 0.7386%]\n",
      "1000 [Discriminator loss: 0.6973%, acc.: 51.17%][Generator loss: 0.7741%]\n",
      "1001 [Discriminator loss: 0.7180%, acc.: 37.11%][Generator loss: 0.7807%]\n",
      "1002 [Discriminator loss: 0.7135%, acc.: 41.80%][Generator loss: 0.7659%]\n",
      "1003 [Discriminator loss: 0.7386%, acc.: 35.55%][Generator loss: 0.8128%]\n",
      "1004 [Discriminator loss: 0.7102%, acc.: 54.30%][Generator loss: 0.8771%]\n",
      "1005 [Discriminator loss: 0.7492%, acc.: 38.28%][Generator loss: 0.7984%]\n",
      "1006 [Discriminator loss: 0.7257%, acc.: 41.02%][Generator loss: 0.7799%]\n",
      "1007 [Discriminator loss: 0.7142%, acc.: 39.84%][Generator loss: 0.7692%]\n",
      "1008 [Discriminator loss: 0.7189%, acc.: 42.19%][Generator loss: 0.7627%]\n",
      "1009 [Discriminator loss: 0.7149%, acc.: 44.14%][Generator loss: 0.7524%]\n",
      "1010 [Discriminator loss: 0.6917%, acc.: 51.95%][Generator loss: 0.7655%]\n",
      "1011 [Discriminator loss: 0.7100%, acc.: 40.62%][Generator loss: 0.7855%]\n",
      "1012 [Discriminator loss: 0.7319%, acc.: 37.11%][Generator loss: 0.8129%]\n",
      "1013 [Discriminator loss: 0.7375%, acc.: 33.98%][Generator loss: 0.7416%]\n",
      "1014 [Discriminator loss: 0.7279%, acc.: 32.81%][Generator loss: 0.7781%]\n",
      "1015 [Discriminator loss: 0.7079%, acc.: 47.66%][Generator loss: 0.8222%]\n",
      "1016 [Discriminator loss: 0.7616%, acc.: 28.91%][Generator loss: 0.7780%]\n",
      "1017 [Discriminator loss: 0.7319%, acc.: 29.69%][Generator loss: 0.7711%]\n",
      "1018 [Discriminator loss: 0.7203%, acc.: 36.72%][Generator loss: 0.7442%]\n",
      "1019 [Discriminator loss: 0.7320%, acc.: 39.06%][Generator loss: 0.7444%]\n",
      "1020 [Discriminator loss: 0.7224%, acc.: 32.03%][Generator loss: 0.7353%]\n",
      "1021 [Discriminator loss: 0.7276%, acc.: 36.72%][Generator loss: 0.7721%]\n",
      "1022 [Discriminator loss: 0.7249%, acc.: 36.33%][Generator loss: 0.7500%]\n",
      "1023 [Discriminator loss: 0.7091%, acc.: 45.31%][Generator loss: 0.7782%]\n",
      "1024 [Discriminator loss: 0.7238%, acc.: 32.03%][Generator loss: 0.7852%]\n",
      "1025 [Discriminator loss: 0.7034%, acc.: 47.27%][Generator loss: 0.7743%]\n",
      "1026 [Discriminator loss: 0.7148%, acc.: 34.38%][Generator loss: 0.7537%]\n",
      "1027 [Discriminator loss: 0.7095%, acc.: 45.70%][Generator loss: 0.7745%]\n",
      "1028 [Discriminator loss: 0.7481%, acc.: 37.89%][Generator loss: 0.7873%]\n",
      "1029 [Discriminator loss: 0.7079%, acc.: 41.80%][Generator loss: 0.7826%]\n",
      "1030 [Discriminator loss: 0.7391%, acc.: 27.34%][Generator loss: 0.7662%]\n",
      "1031 [Discriminator loss: 0.7149%, acc.: 37.50%][Generator loss: 0.7705%]\n",
      "1032 [Discriminator loss: 0.7115%, acc.: 38.67%][Generator loss: 0.7405%]\n",
      "1033 [Discriminator loss: 0.7233%, acc.: 39.06%][Generator loss: 0.7483%]\n",
      "1034 [Discriminator loss: 0.7271%, acc.: 36.33%][Generator loss: 0.8718%]\n",
      "1035 [Discriminator loss: 0.7369%, acc.: 46.09%][Generator loss: 0.8782%]\n",
      "1036 [Discriminator loss: 0.7578%, acc.: 33.59%][Generator loss: 0.8172%]\n",
      "1037 [Discriminator loss: 0.7260%, acc.: 34.77%][Generator loss: 0.7743%]\n",
      "1038 [Discriminator loss: 0.7174%, acc.: 38.67%][Generator loss: 0.7599%]\n",
      "1039 [Discriminator loss: 0.7146%, acc.: 40.23%][Generator loss: 0.7413%]\n",
      "1040 [Discriminator loss: 0.7161%, acc.: 40.23%][Generator loss: 0.7484%]\n",
      "1041 [Discriminator loss: 0.7248%, acc.: 39.06%][Generator loss: 0.7503%]\n",
      "1042 [Discriminator loss: 0.7073%, acc.: 44.53%][Generator loss: 0.7420%]\n",
      "1043 [Discriminator loss: 0.7230%, acc.: 41.80%][Generator loss: 0.7650%]\n",
      "1044 [Discriminator loss: 0.7052%, acc.: 39.06%][Generator loss: 0.7529%]\n",
      "1045 [Discriminator loss: 0.7142%, acc.: 35.94%][Generator loss: 0.7751%]\n",
      "1046 [Discriminator loss: 0.7116%, acc.: 48.44%][Generator loss: 0.8129%]\n",
      "1047 [Discriminator loss: 0.7543%, acc.: 31.64%][Generator loss: 0.7621%]\n",
      "1048 [Discriminator loss: 0.7236%, acc.: 35.16%][Generator loss: 0.7411%]\n",
      "1049 [Discriminator loss: 0.7100%, acc.: 42.19%][Generator loss: 0.7594%]\n",
      "1050 [Discriminator loss: 0.7122%, acc.: 45.31%][Generator loss: 0.7534%]\n",
      "1051 [Discriminator loss: 0.7053%, acc.: 50.00%][Generator loss: 0.7824%]\n",
      "1052 [Discriminator loss: 0.7470%, acc.: 30.47%][Generator loss: 0.7332%]\n",
      "1053 [Discriminator loss: 0.7281%, acc.: 34.77%][Generator loss: 0.7653%]\n",
      "1054 [Discriminator loss: 0.7189%, acc.: 41.80%][Generator loss: 0.7740%]\n",
      "1055 [Discriminator loss: 0.7240%, acc.: 31.25%][Generator loss: 0.8130%]\n",
      "1056 [Discriminator loss: 0.7088%, acc.: 44.14%][Generator loss: 0.8334%]\n",
      "1057 [Discriminator loss: 0.7439%, acc.: 35.16%][Generator loss: 0.7657%]\n",
      "1058 [Discriminator loss: 0.7226%, acc.: 35.16%][Generator loss: 0.7704%]\n",
      "1059 [Discriminator loss: 0.7157%, acc.: 37.11%][Generator loss: 0.7475%]\n",
      "1060 [Discriminator loss: 0.7153%, acc.: 42.58%][Generator loss: 0.7891%]\n",
      "1061 [Discriminator loss: 0.7069%, acc.: 49.22%][Generator loss: 0.7841%]\n",
      "1062 [Discriminator loss: 0.7242%, acc.: 34.38%][Generator loss: 0.7487%]\n",
      "1063 [Discriminator loss: 0.7247%, acc.: 37.11%][Generator loss: 0.7425%]\n",
      "1064 [Discriminator loss: 0.7216%, acc.: 34.77%][Generator loss: 0.7450%]\n",
      "1065 [Discriminator loss: 0.7044%, acc.: 40.23%][Generator loss: 0.7848%]\n",
      "1066 [Discriminator loss: 0.7091%, acc.: 48.83%][Generator loss: 0.8164%]\n",
      "1067 [Discriminator loss: 0.7598%, acc.: 24.22%][Generator loss: 0.7565%]\n",
      "1068 [Discriminator loss: 0.7234%, acc.: 28.12%][Generator loss: 0.7287%]\n",
      "1069 [Discriminator loss: 0.7157%, acc.: 39.45%][Generator loss: 0.7652%]\n",
      "1070 [Discriminator loss: 0.7086%, acc.: 52.73%][Generator loss: 0.7861%]\n",
      "1071 [Discriminator loss: 0.7427%, acc.: 29.69%][Generator loss: 0.7420%]\n",
      "1072 [Discriminator loss: 0.7124%, acc.: 43.36%][Generator loss: 0.7350%]\n",
      "1073 [Discriminator loss: 0.7159%, acc.: 41.80%][Generator loss: 0.8018%]\n",
      "1074 [Discriminator loss: 0.7102%, acc.: 53.91%][Generator loss: 0.8788%]\n",
      "1075 [Discriminator loss: 0.7572%, acc.: 37.11%][Generator loss: 0.8010%]\n",
      "1076 [Discriminator loss: 0.7361%, acc.: 34.38%][Generator loss: 0.7542%]\n",
      "1077 [Discriminator loss: 0.7156%, acc.: 44.14%][Generator loss: 0.7486%]\n",
      "1078 [Discriminator loss: 0.7266%, acc.: 36.72%][Generator loss: 0.7466%]\n",
      "1079 [Discriminator loss: 0.7312%, acc.: 33.98%][Generator loss: 0.7449%]\n",
      "1080 [Discriminator loss: 0.7043%, acc.: 44.53%][Generator loss: 0.7625%]\n",
      "1081 [Discriminator loss: 0.7104%, acc.: 45.70%][Generator loss: 0.7657%]\n",
      "1082 [Discriminator loss: 0.7291%, acc.: 39.45%][Generator loss: 0.7578%]\n",
      "1083 [Discriminator loss: 0.7142%, acc.: 37.50%][Generator loss: 0.7496%]\n",
      "1084 [Discriminator loss: 0.6987%, acc.: 50.00%][Generator loss: 0.7854%]\n",
      "1085 [Discriminator loss: 0.7331%, acc.: 34.38%][Generator loss: 0.7487%]\n",
      "1086 [Discriminator loss: 0.7154%, acc.: 37.11%][Generator loss: 0.7348%]\n",
      "1087 [Discriminator loss: 0.7222%, acc.: 40.23%][Generator loss: 0.8715%]\n",
      "1088 [Discriminator loss: 0.7286%, acc.: 49.22%][Generator loss: 0.8912%]\n",
      "1089 [Discriminator loss: 0.7582%, acc.: 36.33%][Generator loss: 0.8158%]\n",
      "1090 [Discriminator loss: 0.7400%, acc.: 34.38%][Generator loss: 0.7673%]\n",
      "1091 [Discriminator loss: 0.7176%, acc.: 39.84%][Generator loss: 0.7603%]\n",
      "1092 [Discriminator loss: 0.7145%, acc.: 35.94%][Generator loss: 0.7463%]\n",
      "1093 [Discriminator loss: 0.7153%, acc.: 39.84%][Generator loss: 0.7385%]\n",
      "1094 [Discriminator loss: 0.7010%, acc.: 40.23%][Generator loss: 0.7202%]\n",
      "1095 [Discriminator loss: 0.7198%, acc.: 44.53%][Generator loss: 0.7372%]\n",
      "1096 [Discriminator loss: 0.7285%, acc.: 38.28%][Generator loss: 0.7467%]\n",
      "1097 [Discriminator loss: 0.7045%, acc.: 47.27%][Generator loss: 0.7532%]\n",
      "1098 [Discriminator loss: 0.7332%, acc.: 33.20%][Generator loss: 0.7557%]\n",
      "1099 [Discriminator loss: 0.7011%, acc.: 45.31%][Generator loss: 0.7485%]\n",
      "1100 [Discriminator loss: 0.7231%, acc.: 33.59%][Generator loss: 0.7700%]\n",
      "1101 [Discriminator loss: 0.7005%, acc.: 53.12%][Generator loss: 0.8150%]\n",
      "1102 [Discriminator loss: 0.7540%, acc.: 32.81%][Generator loss: 0.7637%]\n",
      "1103 [Discriminator loss: 0.7294%, acc.: 34.38%][Generator loss: 0.7548%]\n",
      "1104 [Discriminator loss: 0.7134%, acc.: 41.41%][Generator loss: 0.7318%]\n",
      "1105 [Discriminator loss: 0.7065%, acc.: 43.75%][Generator loss: 0.7378%]\n",
      "1106 [Discriminator loss: 0.7016%, acc.: 49.61%][Generator loss: 0.7454%]\n",
      "1107 [Discriminator loss: 0.7144%, acc.: 40.62%][Generator loss: 0.7705%]\n",
      "1108 [Discriminator loss: 0.7219%, acc.: 36.33%][Generator loss: 0.8100%]\n",
      "1109 [Discriminator loss: 0.7066%, acc.: 46.09%][Generator loss: 0.8162%]\n",
      "1110 [Discriminator loss: 0.7580%, acc.: 34.38%][Generator loss: 0.7581%]\n",
      "1111 [Discriminator loss: 0.7273%, acc.: 27.73%][Generator loss: 0.7392%]\n",
      "1112 [Discriminator loss: 0.7096%, acc.: 42.19%][Generator loss: 0.7388%]\n",
      "1113 [Discriminator loss: 0.7197%, acc.: 37.11%][Generator loss: 0.7511%]\n",
      "1114 [Discriminator loss: 0.7145%, acc.: 37.11%][Generator loss: 0.7487%]\n",
      "1115 [Discriminator loss: 0.7249%, acc.: 36.72%][Generator loss: 0.7534%]\n",
      "1116 [Discriminator loss: 0.7198%, acc.: 38.28%][Generator loss: 0.7471%]\n",
      "1117 [Discriminator loss: 0.7171%, acc.: 32.03%][Generator loss: 0.8196%]\n",
      "1118 [Discriminator loss: 0.7160%, acc.: 39.84%][Generator loss: 0.8441%]\n",
      "1119 [Discriminator loss: 0.7481%, acc.: 27.34%][Generator loss: 0.7819%]\n",
      "1120 [Discriminator loss: 0.7274%, acc.: 37.11%][Generator loss: 0.7546%]\n",
      "1121 [Discriminator loss: 0.7359%, acc.: 32.03%][Generator loss: 0.7388%]\n",
      "1122 [Discriminator loss: 0.7126%, acc.: 36.33%][Generator loss: 0.7397%]\n",
      "1123 [Discriminator loss: 0.7098%, acc.: 40.23%][Generator loss: 0.7313%]\n",
      "1124 [Discriminator loss: 0.7158%, acc.: 38.67%][Generator loss: 0.7400%]\n",
      "1125 [Discriminator loss: 0.7046%, acc.: 46.88%][Generator loss: 0.7276%]\n",
      "1126 [Discriminator loss: 0.7217%, acc.: 31.25%][Generator loss: 0.7761%]\n",
      "1127 [Discriminator loss: 0.7074%, acc.: 49.61%][Generator loss: 0.8290%]\n",
      "1128 [Discriminator loss: 0.7561%, acc.: 31.25%][Generator loss: 0.7485%]\n",
      "1129 [Discriminator loss: 0.7226%, acc.: 32.03%][Generator loss: 0.7412%]\n",
      "1130 [Discriminator loss: 0.7205%, acc.: 38.67%][Generator loss: 0.7375%]\n",
      "1131 [Discriminator loss: 0.7159%, acc.: 32.03%][Generator loss: 0.7216%]\n",
      "1132 [Discriminator loss: 0.7074%, acc.: 43.75%][Generator loss: 0.7349%]\n",
      "1133 [Discriminator loss: 0.7170%, acc.: 33.59%][Generator loss: 0.7485%]\n",
      "1134 [Discriminator loss: 0.7051%, acc.: 44.92%][Generator loss: 0.7689%]\n",
      "1135 [Discriminator loss: 0.7253%, acc.: 35.94%][Generator loss: 0.7341%]\n",
      "1136 [Discriminator loss: 0.7224%, acc.: 35.94%][Generator loss: 0.7352%]\n",
      "1137 [Discriminator loss: 0.7237%, acc.: 37.11%][Generator loss: 0.7690%]\n",
      "1138 [Discriminator loss: 0.7078%, acc.: 46.48%][Generator loss: 0.7942%]\n",
      "1139 [Discriminator loss: 0.7483%, acc.: 29.30%][Generator loss: 0.7564%]\n",
      "1140 [Discriminator loss: 0.7182%, acc.: 35.94%][Generator loss: 0.7338%]\n",
      "1141 [Discriminator loss: 0.7061%, acc.: 41.80%][Generator loss: 0.9176%]\n",
      "1142 [Discriminator loss: 0.7614%, acc.: 42.97%][Generator loss: 0.8868%]\n",
      "1143 [Discriminator loss: 0.7428%, acc.: 40.62%][Generator loss: 0.8219%]\n",
      "1144 [Discriminator loss: 0.7415%, acc.: 35.94%][Generator loss: 0.7783%]\n",
      "1145 [Discriminator loss: 0.7180%, acc.: 34.38%][Generator loss: 0.7600%]\n",
      "1146 [Discriminator loss: 0.7270%, acc.: 33.98%][Generator loss: 0.7709%]\n",
      "1147 [Discriminator loss: 0.7169%, acc.: 35.16%][Generator loss: 0.7307%]\n",
      "1148 [Discriminator loss: 0.7161%, acc.: 33.20%][Generator loss: 0.7300%]\n",
      "1149 [Discriminator loss: 0.7228%, acc.: 39.45%][Generator loss: 0.7329%]\n",
      "1150 [Discriminator loss: 0.7096%, acc.: 42.19%][Generator loss: 0.7326%]\n",
      "1151 [Discriminator loss: 0.7094%, acc.: 44.14%][Generator loss: 0.7393%]\n",
      "1152 [Discriminator loss: 0.7000%, acc.: 48.44%][Generator loss: 0.7518%]\n",
      "1153 [Discriminator loss: 0.7217%, acc.: 35.55%][Generator loss: 0.7354%]\n",
      "1154 [Discriminator loss: 0.7112%, acc.: 39.84%][Generator loss: 0.7306%]\n",
      "1155 [Discriminator loss: 0.7002%, acc.: 50.00%][Generator loss: 0.7291%]\n",
      "1156 [Discriminator loss: 0.7042%, acc.: 44.53%][Generator loss: 0.7246%]\n",
      "1157 [Discriminator loss: 0.7192%, acc.: 39.45%][Generator loss: 0.7193%]\n",
      "1158 [Discriminator loss: 0.7086%, acc.: 41.02%][Generator loss: 0.7831%]\n",
      "1159 [Discriminator loss: 0.7202%, acc.: 39.84%][Generator loss: 0.7748%]\n",
      "1160 [Discriminator loss: 0.7215%, acc.: 37.11%][Generator loss: 0.7630%]\n",
      "1161 [Discriminator loss: 0.7088%, acc.: 43.75%][Generator loss: 0.8475%]\n",
      "1162 [Discriminator loss: 0.7697%, acc.: 24.61%][Generator loss: 0.7624%]\n",
      "1163 [Discriminator loss: 0.7254%, acc.: 30.08%][Generator loss: 0.7326%]\n",
      "1164 [Discriminator loss: 0.7063%, acc.: 41.80%][Generator loss: 0.7390%]\n",
      "1165 [Discriminator loss: 0.7105%, acc.: 37.89%][Generator loss: 0.7339%]\n",
      "1166 [Discriminator loss: 0.7116%, acc.: 40.62%][Generator loss: 0.7336%]\n",
      "1167 [Discriminator loss: 0.7195%, acc.: 38.67%][Generator loss: 0.7330%]\n",
      "1168 [Discriminator loss: 0.7145%, acc.: 37.11%][Generator loss: 0.8001%]\n",
      "1169 [Discriminator loss: 0.7137%, acc.: 47.27%][Generator loss: 0.8459%]\n",
      "1170 [Discriminator loss: 0.7441%, acc.: 38.28%][Generator loss: 0.7655%]\n",
      "1171 [Discriminator loss: 0.7287%, acc.: 35.94%][Generator loss: 0.7446%]\n",
      "1172 [Discriminator loss: 0.7100%, acc.: 35.55%][Generator loss: 0.7433%]\n",
      "1173 [Discriminator loss: 0.7176%, acc.: 35.16%][Generator loss: 0.7279%]\n",
      "1174 [Discriminator loss: 0.7087%, acc.: 42.19%][Generator loss: 0.7677%]\n",
      "1175 [Discriminator loss: 0.7076%, acc.: 53.91%][Generator loss: 0.8199%]\n",
      "1176 [Discriminator loss: 0.7429%, acc.: 37.11%][Generator loss: 0.7499%]\n",
      "1177 [Discriminator loss: 0.7273%, acc.: 31.64%][Generator loss: 0.7277%]\n",
      "1178 [Discriminator loss: 0.7058%, acc.: 44.53%][Generator loss: 0.7590%]\n",
      "1179 [Discriminator loss: 0.7213%, acc.: 33.98%][Generator loss: 0.7447%]\n",
      "1180 [Discriminator loss: 0.7083%, acc.: 42.58%][Generator loss: 0.7481%]\n",
      "1181 [Discriminator loss: 0.7109%, acc.: 40.23%][Generator loss: 0.7415%]\n",
      "1182 [Discriminator loss: 0.7217%, acc.: 36.72%][Generator loss: 0.7929%]\n",
      "1183 [Discriminator loss: 0.7066%, acc.: 49.61%][Generator loss: 0.8608%]\n",
      "1184 [Discriminator loss: 0.7544%, acc.: 36.33%][Generator loss: 0.7739%]\n",
      "1185 [Discriminator loss: 0.7278%, acc.: 36.33%][Generator loss: 0.7535%]\n",
      "1186 [Discriminator loss: 0.7326%, acc.: 31.25%][Generator loss: 0.7267%]\n",
      "1187 [Discriminator loss: 0.7089%, acc.: 45.70%][Generator loss: 0.7354%]\n",
      "1188 [Discriminator loss: 0.7093%, acc.: 45.70%][Generator loss: 0.7276%]\n",
      "1189 [Discriminator loss: 0.7139%, acc.: 42.97%][Generator loss: 0.7467%]\n",
      "1190 [Discriminator loss: 0.7144%, acc.: 44.14%][Generator loss: 0.7912%]\n",
      "1191 [Discriminator loss: 0.7417%, acc.: 28.52%][Generator loss: 0.7500%]\n",
      "1192 [Discriminator loss: 0.7194%, acc.: 34.77%][Generator loss: 0.7536%]\n",
      "1193 [Discriminator loss: 0.7116%, acc.: 40.62%][Generator loss: 0.7578%]\n",
      "1194 [Discriminator loss: 0.7242%, acc.: 35.55%][Generator loss: 0.7371%]\n",
      "1195 [Discriminator loss: 0.7195%, acc.: 32.81%][Generator loss: 0.7355%]\n",
      "1196 [Discriminator loss: 0.7077%, acc.: 39.45%][Generator loss: 0.7843%]\n",
      "1197 [Discriminator loss: 0.7337%, acc.: 31.64%][Generator loss: 0.7520%]\n",
      "1198 [Discriminator loss: 0.7132%, acc.: 44.14%][Generator loss: 0.7546%]\n",
      "1199 [Discriminator loss: 0.7159%, acc.: 31.64%][Generator loss: 0.7289%]\n",
      "1200 [Discriminator loss: 0.7232%, acc.: 32.03%][Generator loss: 0.7263%]\n",
      "1201 [Discriminator loss: 0.7102%, acc.: 42.19%][Generator loss: 0.7450%]\n",
      "1202 [Discriminator loss: 0.7216%, acc.: 32.03%][Generator loss: 0.9106%]\n",
      "1203 [Discriminator loss: 0.7383%, acc.: 44.14%][Generator loss: 0.8721%]\n",
      "1204 [Discriminator loss: 0.7507%, acc.: 40.62%][Generator loss: 0.8095%]\n",
      "1205 [Discriminator loss: 0.7306%, acc.: 32.42%][Generator loss: 0.7676%]\n",
      "1206 [Discriminator loss: 0.7222%, acc.: 33.98%][Generator loss: 0.7541%]\n",
      "1207 [Discriminator loss: 0.7161%, acc.: 36.72%][Generator loss: 0.7352%]\n",
      "1208 [Discriminator loss: 0.7142%, acc.: 39.06%][Generator loss: 0.7327%]\n",
      "1209 [Discriminator loss: 0.7137%, acc.: 42.19%][Generator loss: 0.7365%]\n",
      "1210 [Discriminator loss: 0.7068%, acc.: 40.62%][Generator loss: 0.7385%]\n",
      "1211 [Discriminator loss: 0.7101%, acc.: 44.92%][Generator loss: 0.7377%]\n",
      "1212 [Discriminator loss: 0.7126%, acc.: 39.84%][Generator loss: 0.7389%]\n",
      "1213 [Discriminator loss: 0.7246%, acc.: 43.75%][Generator loss: 0.7439%]\n",
      "1214 [Discriminator loss: 0.7281%, acc.: 26.17%][Generator loss: 0.7472%]\n",
      "1215 [Discriminator loss: 0.7073%, acc.: 44.92%][Generator loss: 0.7586%]\n",
      "1216 [Discriminator loss: 0.7325%, acc.: 32.03%][Generator loss: 0.7506%]\n",
      "1217 [Discriminator loss: 0.7212%, acc.: 30.47%][Generator loss: 0.7324%]\n",
      "1218 [Discriminator loss: 0.7167%, acc.: 29.69%][Generator loss: 0.7495%]\n",
      "1219 [Discriminator loss: 0.7014%, acc.: 49.61%][Generator loss: 0.8253%]\n",
      "1220 [Discriminator loss: 0.7556%, acc.: 30.08%][Generator loss: 0.7441%]\n",
      "1221 [Discriminator loss: 0.7223%, acc.: 30.86%][Generator loss: 0.7450%]\n",
      "1222 [Discriminator loss: 0.7103%, acc.: 36.72%][Generator loss: 0.7401%]\n",
      "1223 [Discriminator loss: 0.7097%, acc.: 40.62%][Generator loss: 0.7627%]\n",
      "1224 [Discriminator loss: 0.7138%, acc.: 40.23%][Generator loss: 0.7734%]\n",
      "1225 [Discriminator loss: 0.7300%, acc.: 32.42%][Generator loss: 0.7239%]\n",
      "1226 [Discriminator loss: 0.7221%, acc.: 30.86%][Generator loss: 0.7462%]\n",
      "1227 [Discriminator loss: 0.7065%, acc.: 42.58%][Generator loss: 0.7908%]\n",
      "1228 [Discriminator loss: 0.7423%, acc.: 29.30%][Generator loss: 0.7383%]\n",
      "1229 [Discriminator loss: 0.7157%, acc.: 32.81%][Generator loss: 0.7188%]\n",
      "1230 [Discriminator loss: 0.7116%, acc.: 35.94%][Generator loss: 0.7310%]\n",
      "1231 [Discriminator loss: 0.7138%, acc.: 38.28%][Generator loss: 0.7385%]\n",
      "1232 [Discriminator loss: 0.7240%, acc.: 28.52%][Generator loss: 0.7398%]\n",
      "1233 [Discriminator loss: 0.7047%, acc.: 41.41%][Generator loss: 0.7674%]\n",
      "1234 [Discriminator loss: 0.7370%, acc.: 33.20%][Generator loss: 0.7524%]\n",
      "1235 [Discriminator loss: 0.7146%, acc.: 39.06%][Generator loss: 0.7472%]\n",
      "1236 [Discriminator loss: 0.7177%, acc.: 31.64%][Generator loss: 0.7316%]\n",
      "1237 [Discriminator loss: 0.7007%, acc.: 46.88%][Generator loss: 0.7362%]\n",
      "1238 [Discriminator loss: 0.7331%, acc.: 34.38%][Generator loss: 0.8292%]\n",
      "1239 [Discriminator loss: 0.7418%, acc.: 44.14%][Generator loss: 0.8734%]\n",
      "1240 [Discriminator loss: 0.7604%, acc.: 33.59%][Generator loss: 0.8067%]\n",
      "1241 [Discriminator loss: 0.7363%, acc.: 35.16%][Generator loss: 0.7737%]\n",
      "1242 [Discriminator loss: 0.7298%, acc.: 33.20%][Generator loss: 0.7458%]\n",
      "1243 [Discriminator loss: 0.7227%, acc.: 24.22%][Generator loss: 0.7374%]\n",
      "1244 [Discriminator loss: 0.7196%, acc.: 29.30%][Generator loss: 0.7376%]\n",
      "1245 [Discriminator loss: 0.7087%, acc.: 35.55%][Generator loss: 0.7254%]\n",
      "1246 [Discriminator loss: 0.7126%, acc.: 42.58%][Generator loss: 0.7350%]\n",
      "1247 [Discriminator loss: 0.7100%, acc.: 35.55%][Generator loss: 0.7268%]\n",
      "1248 [Discriminator loss: 0.7122%, acc.: 33.98%][Generator loss: 0.7509%]\n",
      "1249 [Discriminator loss: 0.7090%, acc.: 46.48%][Generator loss: 0.7773%]\n",
      "1250 [Discriminator loss: 0.7339%, acc.: 30.08%][Generator loss: 0.7466%]\n",
      "1251 [Discriminator loss: 0.7149%, acc.: 37.89%][Generator loss: 0.7424%]\n",
      "1252 [Discriminator loss: 0.7195%, acc.: 30.86%][Generator loss: 0.7361%]\n",
      "1253 [Discriminator loss: 0.7163%, acc.: 31.25%][Generator loss: 0.7534%]\n",
      "1254 [Discriminator loss: 0.7174%, acc.: 29.30%][Generator loss: 0.7621%]\n",
      "1255 [Discriminator loss: 0.7048%, acc.: 46.88%][Generator loss: 0.8102%]\n",
      "1256 [Discriminator loss: 0.7418%, acc.: 30.47%][Generator loss: 0.7470%]\n",
      "1257 [Discriminator loss: 0.7197%, acc.: 33.59%][Generator loss: 0.7346%]\n",
      "1258 [Discriminator loss: 0.7071%, acc.: 40.62%][Generator loss: 0.7442%]\n",
      "1259 [Discriminator loss: 0.7220%, acc.: 41.80%][Generator loss: 0.7687%]\n",
      "1260 [Discriminator loss: 0.7276%, acc.: 36.33%][Generator loss: 0.7551%]\n",
      "1261 [Discriminator loss: 0.7114%, acc.: 33.98%][Generator loss: 0.7616%]\n",
      "1262 [Discriminator loss: 0.7189%, acc.: 40.23%][Generator loss: 0.7606%]\n",
      "1263 [Discriminator loss: 0.7182%, acc.: 37.89%][Generator loss: 0.7434%]\n",
      "1264 [Discriminator loss: 0.7063%, acc.: 47.27%][Generator loss: 0.7335%]\n",
      "1265 [Discriminator loss: 0.7234%, acc.: 41.41%][Generator loss: 0.7478%]\n",
      "1266 [Discriminator loss: 0.7198%, acc.: 28.91%][Generator loss: 0.7325%]\n",
      "1267 [Discriminator loss: 0.7125%, acc.: 39.84%][Generator loss: 0.7387%]\n",
      "1268 [Discriminator loss: 0.7200%, acc.: 28.12%][Generator loss: 0.7740%]\n",
      "1269 [Discriminator loss: 0.7120%, acc.: 44.14%][Generator loss: 0.8119%]\n",
      "1270 [Discriminator loss: 0.7555%, acc.: 26.95%][Generator loss: 0.7612%]\n",
      "1271 [Discriminator loss: 0.7252%, acc.: 20.31%][Generator loss: 0.7385%]\n",
      "1272 [Discriminator loss: 0.7162%, acc.: 27.34%][Generator loss: 0.7353%]\n",
      "1273 [Discriminator loss: 0.7154%, acc.: 28.91%][Generator loss: 0.7321%]\n",
      "1274 [Discriminator loss: 0.7130%, acc.: 42.19%][Generator loss: 0.7356%]\n",
      "1275 [Discriminator loss: 0.7252%, acc.: 28.52%][Generator loss: 0.7375%]\n",
      "1276 [Discriminator loss: 0.7132%, acc.: 44.53%][Generator loss: 0.7294%]\n",
      "1277 [Discriminator loss: 0.7129%, acc.: 38.28%][Generator loss: 0.7272%]\n",
      "1278 [Discriminator loss: 0.7119%, acc.: 38.28%][Generator loss: 0.7478%]\n",
      "1279 [Discriminator loss: 0.7241%, acc.: 30.08%][Generator loss: 0.7516%]\n",
      "1280 [Discriminator loss: 0.7160%, acc.: 32.03%][Generator loss: 0.7606%]\n",
      "1281 [Discriminator loss: 0.7222%, acc.: 33.98%][Generator loss: 0.7426%]\n",
      "1282 [Discriminator loss: 0.7169%, acc.: 42.19%][Generator loss: 0.7555%]\n",
      "1283 [Discriminator loss: 0.7177%, acc.: 31.64%][Generator loss: 0.7293%]\n",
      "1284 [Discriminator loss: 0.7180%, acc.: 42.19%][Generator loss: 0.7391%]\n",
      "1285 [Discriminator loss: 0.7156%, acc.: 37.11%][Generator loss: 0.8361%]\n",
      "1286 [Discriminator loss: 0.7314%, acc.: 44.14%][Generator loss: 0.8734%]\n",
      "1287 [Discriminator loss: 0.7590%, acc.: 32.03%][Generator loss: 0.7930%]\n",
      "1288 [Discriminator loss: 0.7424%, acc.: 30.08%][Generator loss: 0.7595%]\n",
      "1289 [Discriminator loss: 0.7200%, acc.: 28.91%][Generator loss: 0.7443%]\n",
      "1290 [Discriminator loss: 0.7142%, acc.: 37.11%][Generator loss: 0.7320%]\n",
      "1291 [Discriminator loss: 0.7159%, acc.: 32.42%][Generator loss: 0.7660%]\n",
      "1292 [Discriminator loss: 0.7168%, acc.: 32.81%][Generator loss: 0.7324%]\n",
      "1293 [Discriminator loss: 0.7166%, acc.: 37.11%][Generator loss: 0.7260%]\n",
      "1294 [Discriminator loss: 0.7141%, acc.: 35.94%][Generator loss: 0.7257%]\n",
      "1295 [Discriminator loss: 0.7088%, acc.: 35.94%][Generator loss: 0.7327%]\n",
      "1296 [Discriminator loss: 0.7064%, acc.: 39.06%][Generator loss: 0.7540%]\n",
      "1297 [Discriminator loss: 0.7263%, acc.: 29.69%][Generator loss: 0.7344%]\n",
      "1298 [Discriminator loss: 0.7089%, acc.: 43.36%][Generator loss: 0.7382%]\n",
      "1299 [Discriminator loss: 0.7147%, acc.: 29.69%][Generator loss: 0.8283%]\n",
      "1300 [Discriminator loss: 0.7275%, acc.: 43.36%][Generator loss: 0.8441%]\n",
      "1301 [Discriminator loss: 0.7574%, acc.: 31.64%][Generator loss: 0.7884%]\n",
      "1302 [Discriminator loss: 0.7313%, acc.: 27.34%][Generator loss: 0.7444%]\n",
      "1303 [Discriminator loss: 0.7174%, acc.: 35.94%][Generator loss: 0.7533%]\n",
      "1304 [Discriminator loss: 0.7101%, acc.: 41.02%][Generator loss: 0.7423%]\n",
      "1305 [Discriminator loss: 0.7154%, acc.: 33.59%][Generator loss: 0.7287%]\n",
      "1306 [Discriminator loss: 0.7117%, acc.: 31.25%][Generator loss: 0.7290%]\n",
      "1307 [Discriminator loss: 0.7167%, acc.: 30.47%][Generator loss: 0.7517%]\n",
      "1308 [Discriminator loss: 0.7032%, acc.: 42.58%][Generator loss: 0.7810%]\n",
      "1309 [Discriminator loss: 0.7331%, acc.: 29.30%][Generator loss: 0.7345%]\n",
      "1310 [Discriminator loss: 0.7139%, acc.: 26.56%][Generator loss: 0.7299%]\n",
      "1311 [Discriminator loss: 0.7150%, acc.: 38.67%][Generator loss: 0.7242%]\n",
      "1312 [Discriminator loss: 0.7187%, acc.: 31.64%][Generator loss: 0.7130%]\n",
      "1313 [Discriminator loss: 0.7092%, acc.: 40.62%][Generator loss: 0.7173%]\n",
      "1314 [Discriminator loss: 0.7154%, acc.: 34.38%][Generator loss: 0.7256%]\n",
      "1315 [Discriminator loss: 0.6990%, acc.: 46.09%][Generator loss: 0.7767%]\n",
      "1316 [Discriminator loss: 0.7399%, acc.: 28.52%][Generator loss: 0.7290%]\n",
      "1317 [Discriminator loss: 0.7184%, acc.: 26.95%][Generator loss: 0.7210%]\n",
      "1318 [Discriminator loss: 0.7040%, acc.: 41.02%][Generator loss: 0.7306%]\n",
      "1319 [Discriminator loss: 0.7183%, acc.: 33.98%][Generator loss: 0.7564%]\n",
      "1320 [Discriminator loss: 0.7097%, acc.: 39.84%][Generator loss: 0.8040%]\n",
      "1321 [Discriminator loss: 0.7449%, acc.: 28.52%][Generator loss: 0.7498%]\n",
      "1322 [Discriminator loss: 0.7300%, acc.: 22.66%][Generator loss: 0.7364%]\n",
      "1323 [Discriminator loss: 0.7128%, acc.: 38.67%][Generator loss: 0.7328%]\n",
      "1324 [Discriminator loss: 0.7135%, acc.: 33.98%][Generator loss: 0.7317%]\n",
      "1325 [Discriminator loss: 0.7126%, acc.: 35.94%][Generator loss: 0.7220%]\n",
      "1326 [Discriminator loss: 0.7136%, acc.: 36.72%][Generator loss: 0.7387%]\n",
      "1327 [Discriminator loss: 0.7095%, acc.: 43.75%][Generator loss: 0.7494%]\n",
      "1328 [Discriminator loss: 0.7194%, acc.: 32.42%][Generator loss: 0.7437%]\n",
      "1329 [Discriminator loss: 0.7121%, acc.: 37.89%][Generator loss: 0.7285%]\n",
      "1330 [Discriminator loss: 0.7259%, acc.: 32.81%][Generator loss: 0.7602%]\n",
      "1331 [Discriminator loss: 0.7025%, acc.: 51.56%][Generator loss: 0.8175%]\n",
      "1332 [Discriminator loss: 0.7517%, acc.: 35.16%][Generator loss: 0.7552%]\n",
      "1333 [Discriminator loss: 0.7325%, acc.: 24.22%][Generator loss: 0.7359%]\n",
      "1334 [Discriminator loss: 0.7163%, acc.: 27.73%][Generator loss: 0.7421%]\n",
      "1335 [Discriminator loss: 0.7145%, acc.: 34.38%][Generator loss: 0.7172%]\n",
      "1336 [Discriminator loss: 0.7085%, acc.: 36.72%][Generator loss: 0.7352%]\n",
      "1337 [Discriminator loss: 0.7077%, acc.: 44.53%][Generator loss: 0.7556%]\n",
      "1338 [Discriminator loss: 0.7199%, acc.: 33.98%][Generator loss: 0.7326%]\n",
      "1339 [Discriminator loss: 0.7143%, acc.: 35.55%][Generator loss: 0.7185%]\n",
      "1340 [Discriminator loss: 0.7138%, acc.: 34.38%][Generator loss: 0.7302%]\n",
      "1341 [Discriminator loss: 0.7176%, acc.: 28.52%][Generator loss: 0.7347%]\n",
      "1342 [Discriminator loss: 0.7109%, acc.: 39.06%][Generator loss: 0.7351%]\n",
      "1343 [Discriminator loss: 0.7181%, acc.: 29.69%][Generator loss: 0.8116%]\n",
      "1344 [Discriminator loss: 0.7115%, acc.: 41.80%][Generator loss: 0.8131%]\n",
      "1345 [Discriminator loss: 0.7437%, acc.: 32.42%][Generator loss: 0.7559%]\n",
      "1346 [Discriminator loss: 0.7328%, acc.: 18.75%][Generator loss: 0.7460%]\n",
      "1347 [Discriminator loss: 0.7189%, acc.: 32.03%][Generator loss: 0.7208%]\n",
      "1348 [Discriminator loss: 0.7101%, acc.: 32.81%][Generator loss: 0.7549%]\n",
      "1349 [Discriminator loss: 0.7193%, acc.: 32.03%][Generator loss: 0.7349%]\n",
      "1350 [Discriminator loss: 0.7200%, acc.: 31.25%][Generator loss: 0.7281%]\n",
      "1351 [Discriminator loss: 0.7184%, acc.: 40.62%][Generator loss: 0.7273%]\n",
      "1352 [Discriminator loss: 0.7090%, acc.: 32.03%][Generator loss: 0.7194%]\n",
      "1353 [Discriminator loss: 0.7030%, acc.: 42.58%][Generator loss: 0.7322%]\n",
      "1354 [Discriminator loss: 0.7241%, acc.: 29.30%][Generator loss: 0.7346%]\n",
      "1355 [Discriminator loss: 0.7100%, acc.: 39.84%][Generator loss: 0.7381%]\n",
      "1356 [Discriminator loss: 0.7147%, acc.: 32.42%][Generator loss: 0.7476%]\n",
      "1357 [Discriminator loss: 0.7200%, acc.: 28.12%][Generator loss: 0.7474%]\n",
      "1358 [Discriminator loss: 0.7118%, acc.: 33.59%][Generator loss: 0.7623%]\n",
      "1359 [Discriminator loss: 0.7344%, acc.: 23.44%][Generator loss: 0.7334%]\n",
      "1360 [Discriminator loss: 0.7088%, acc.: 30.86%][Generator loss: 0.7421%]\n",
      "1361 [Discriminator loss: 0.7055%, acc.: 41.80%][Generator loss: 0.7449%]\n",
      "1362 [Discriminator loss: 0.7206%, acc.: 27.34%][Generator loss: 0.7483%]\n",
      "1363 [Discriminator loss: 0.7037%, acc.: 45.70%][Generator loss: 0.7927%]\n",
      "1364 [Discriminator loss: 0.7399%, acc.: 24.22%][Generator loss: 0.7528%]\n",
      "1365 [Discriminator loss: 0.7189%, acc.: 31.64%][Generator loss: 0.7264%]\n",
      "1366 [Discriminator loss: 0.7062%, acc.: 36.72%][Generator loss: 0.7708%]\n",
      "1367 [Discriminator loss: 0.7132%, acc.: 48.44%][Generator loss: 0.7916%]\n",
      "1368 [Discriminator loss: 0.7362%, acc.: 34.38%][Generator loss: 0.7439%]\n",
      "1369 [Discriminator loss: 0.7163%, acc.: 31.64%][Generator loss: 0.7341%]\n",
      "1370 [Discriminator loss: 0.7098%, acc.: 39.45%][Generator loss: 0.7435%]\n",
      "1371 [Discriminator loss: 0.7139%, acc.: 39.45%][Generator loss: 0.7407%]\n",
      "1372 [Discriminator loss: 0.7135%, acc.: 29.30%][Generator loss: 0.7282%]\n",
      "1373 [Discriminator loss: 0.7059%, acc.: 40.62%][Generator loss: 0.7345%]\n",
      "1374 [Discriminator loss: 0.7102%, acc.: 30.47%][Generator loss: 0.7641%]\n",
      "1375 [Discriminator loss: 0.7071%, acc.: 43.75%][Generator loss: 0.8178%]\n",
      "1376 [Discriminator loss: 0.7451%, acc.: 27.73%][Generator loss: 0.7515%]\n",
      "1377 [Discriminator loss: 0.7148%, acc.: 29.69%][Generator loss: 0.7400%]\n",
      "1378 [Discriminator loss: 0.7215%, acc.: 30.08%][Generator loss: 0.7214%]\n",
      "1379 [Discriminator loss: 0.7104%, acc.: 41.02%][Generator loss: 0.7254%]\n",
      "1380 [Discriminator loss: 0.7180%, acc.: 29.69%][Generator loss: 0.7252%]\n",
      "1381 [Discriminator loss: 0.7162%, acc.: 32.42%][Generator loss: 0.7274%]\n",
      "1382 [Discriminator loss: 0.7125%, acc.: 31.64%][Generator loss: 0.7392%]\n",
      "1383 [Discriminator loss: 0.7081%, acc.: 39.45%][Generator loss: 0.7575%]\n",
      "1384 [Discriminator loss: 0.7218%, acc.: 25.78%][Generator loss: 0.7224%]\n",
      "1385 [Discriminator loss: 0.7147%, acc.: 33.98%][Generator loss: 0.7330%]\n",
      "1386 [Discriminator loss: 0.7147%, acc.: 30.86%][Generator loss: 0.7215%]\n",
      "1387 [Discriminator loss: 0.7125%, acc.: 28.91%][Generator loss: 0.7220%]\n",
      "1388 [Discriminator loss: 0.7125%, acc.: 36.33%][Generator loss: 0.7286%]\n",
      "1389 [Discriminator loss: 0.7125%, acc.: 30.86%][Generator loss: 0.7377%]\n",
      "1390 [Discriminator loss: 0.7061%, acc.: 45.31%][Generator loss: 0.7579%]\n",
      "1391 [Discriminator loss: 0.7258%, acc.: 31.25%][Generator loss: 0.7265%]\n",
      "1392 [Discriminator loss: 0.7094%, acc.: 28.12%][Generator loss: 0.7273%]\n",
      "1393 [Discriminator loss: 0.7086%, acc.: 42.58%][Generator loss: 0.7235%]\n",
      "1394 [Discriminator loss: 0.7078%, acc.: 34.38%][Generator loss: 0.7414%]\n",
      "1395 [Discriminator loss: 0.7107%, acc.: 34.77%][Generator loss: 0.7480%]\n",
      "1396 [Discriminator loss: 0.7204%, acc.: 32.03%][Generator loss: 0.7273%]\n",
      "1397 [Discriminator loss: 0.7135%, acc.: 32.81%][Generator loss: 0.7450%]\n",
      "1398 [Discriminator loss: 0.7255%, acc.: 32.42%][Generator loss: 0.7240%]\n",
      "1399 [Discriminator loss: 0.7202%, acc.: 26.95%][Generator loss: 0.7426%]\n",
      "1400 [Discriminator loss: 0.7163%, acc.: 23.44%][Generator loss: 0.7598%]\n",
      "1401 [Discriminator loss: 0.7108%, acc.: 37.11%][Generator loss: 0.7629%]\n",
      "1402 [Discriminator loss: 0.7161%, acc.: 35.94%][Generator loss: 0.7318%]\n",
      "1403 [Discriminator loss: 0.7065%, acc.: 41.02%][Generator loss: 0.7288%]\n",
      "1404 [Discriminator loss: 0.7096%, acc.: 35.16%][Generator loss: 0.7444%]\n",
      "1405 [Discriminator loss: 0.7076%, acc.: 37.11%][Generator loss: 0.7635%]\n",
      "1406 [Discriminator loss: 0.7312%, acc.: 30.08%][Generator loss: 0.7335%]\n",
      "1407 [Discriminator loss: 0.7110%, acc.: 31.25%][Generator loss: 0.7324%]\n",
      "1408 [Discriminator loss: 0.7086%, acc.: 39.84%][Generator loss: 0.7563%]\n",
      "1409 [Discriminator loss: 0.7295%, acc.: 29.30%][Generator loss: 0.7338%]\n",
      "1410 [Discriminator loss: 0.7096%, acc.: 35.55%][Generator loss: 0.7219%]\n",
      "1411 [Discriminator loss: 0.7143%, acc.: 29.69%][Generator loss: 0.8743%]\n",
      "1412 [Discriminator loss: 0.7437%, acc.: 41.41%][Generator loss: 0.8376%]\n",
      "1413 [Discriminator loss: 0.7478%, acc.: 37.11%][Generator loss: 0.7844%]\n",
      "1414 [Discriminator loss: 0.7247%, acc.: 39.06%][Generator loss: 0.7689%]\n",
      "1415 [Discriminator loss: 0.7184%, acc.: 23.44%][Generator loss: 0.7513%]\n",
      "1416 [Discriminator loss: 0.7128%, acc.: 33.59%][Generator loss: 0.7472%]\n",
      "1417 [Discriminator loss: 0.7144%, acc.: 35.55%][Generator loss: 0.7355%]\n",
      "1418 [Discriminator loss: 0.7131%, acc.: 37.50%][Generator loss: 0.7307%]\n",
      "1419 [Discriminator loss: 0.7092%, acc.: 35.55%][Generator loss: 0.7415%]\n",
      "1420 [Discriminator loss: 0.7166%, acc.: 24.22%][Generator loss: 0.7419%]\n",
      "1421 [Discriminator loss: 0.7091%, acc.: 30.08%][Generator loss: 0.7312%]\n",
      "1422 [Discriminator loss: 0.7083%, acc.: 37.89%][Generator loss: 0.7275%]\n",
      "1423 [Discriminator loss: 0.7030%, acc.: 42.19%][Generator loss: 0.7309%]\n",
      "1424 [Discriminator loss: 0.7028%, acc.: 40.23%][Generator loss: 0.7392%]\n",
      "1425 [Discriminator loss: 0.7154%, acc.: 35.16%][Generator loss: 0.7420%]\n",
      "1426 [Discriminator loss: 0.7111%, acc.: 32.03%][Generator loss: 0.7443%]\n",
      "1427 [Discriminator loss: 0.7165%, acc.: 32.03%][Generator loss: 0.7371%]\n",
      "1428 [Discriminator loss: 0.7130%, acc.: 37.11%][Generator loss: 0.7406%]\n",
      "1429 [Discriminator loss: 0.7171%, acc.: 23.05%][Generator loss: 0.7633%]\n",
      "1430 [Discriminator loss: 0.7101%, acc.: 41.41%][Generator loss: 0.8091%]\n",
      "1431 [Discriminator loss: 0.7405%, acc.: 32.81%][Generator loss: 0.7633%]\n",
      "1432 [Discriminator loss: 0.7186%, acc.: 37.89%][Generator loss: 0.7406%]\n",
      "1433 [Discriminator loss: 0.7166%, acc.: 28.52%][Generator loss: 0.7324%]\n",
      "1434 [Discriminator loss: 0.7147%, acc.: 26.17%][Generator loss: 0.7359%]\n",
      "1435 [Discriminator loss: 0.7085%, acc.: 34.77%][Generator loss: 0.7332%]\n",
      "1436 [Discriminator loss: 0.7073%, acc.: 41.41%][Generator loss: 0.7256%]\n",
      "1437 [Discriminator loss: 0.7109%, acc.: 33.20%][Generator loss: 0.7271%]\n",
      "1438 [Discriminator loss: 0.7099%, acc.: 33.59%][Generator loss: 0.7373%]\n",
      "1439 [Discriminator loss: 0.7100%, acc.: 35.16%][Generator loss: 0.9435%]\n",
      "1440 [Discriminator loss: 0.7728%, acc.: 48.05%][Generator loss: 0.8617%]\n",
      "1441 [Discriminator loss: 0.7347%, acc.: 47.27%][Generator loss: 0.8121%]\n",
      "1442 [Discriminator loss: 0.7250%, acc.: 42.19%][Generator loss: 0.7855%]\n",
      "1443 [Discriminator loss: 0.7188%, acc.: 42.19%][Generator loss: 0.7649%]\n",
      "1444 [Discriminator loss: 0.7168%, acc.: 41.02%][Generator loss: 0.7492%]\n",
      "1445 [Discriminator loss: 0.7152%, acc.: 32.03%][Generator loss: 0.7429%]\n",
      "1446 [Discriminator loss: 0.7155%, acc.: 33.20%][Generator loss: 0.7315%]\n",
      "1447 [Discriminator loss: 0.7095%, acc.: 43.36%][Generator loss: 0.7302%]\n",
      "1448 [Discriminator loss: 0.7052%, acc.: 41.41%][Generator loss: 0.7302%]\n",
      "1449 [Discriminator loss: 0.7128%, acc.: 41.02%][Generator loss: 0.7305%]\n",
      "1450 [Discriminator loss: 0.7111%, acc.: 36.33%][Generator loss: 0.7369%]\n",
      "1451 [Discriminator loss: 0.7076%, acc.: 30.47%][Generator loss: 0.7307%]\n",
      "1452 [Discriminator loss: 0.7122%, acc.: 35.55%][Generator loss: 0.7434%]\n",
      "1453 [Discriminator loss: 0.7209%, acc.: 28.91%][Generator loss: 0.7161%]\n",
      "1454 [Discriminator loss: 0.7052%, acc.: 37.50%][Generator loss: 0.7276%]\n",
      "1455 [Discriminator loss: 0.7143%, acc.: 32.42%][Generator loss: 0.7226%]\n",
      "1456 [Discriminator loss: 0.7134%, acc.: 27.34%][Generator loss: 0.7323%]\n",
      "1457 [Discriminator loss: 0.7037%, acc.: 42.58%][Generator loss: 0.7463%]\n",
      "1458 [Discriminator loss: 0.7206%, acc.: 35.94%][Generator loss: 0.7401%]\n",
      "1459 [Discriminator loss: 0.7096%, acc.: 34.77%][Generator loss: 0.7379%]\n",
      "1460 [Discriminator loss: 0.7101%, acc.: 37.11%][Generator loss: 0.7450%]\n",
      "1461 [Discriminator loss: 0.7068%, acc.: 41.02%][Generator loss: 0.7688%]\n",
      "1462 [Discriminator loss: 0.7288%, acc.: 35.16%][Generator loss: 0.7277%]\n",
      "1463 [Discriminator loss: 0.7118%, acc.: 35.16%][Generator loss: 0.7375%]\n",
      "1464 [Discriminator loss: 0.7041%, acc.: 38.28%][Generator loss: 0.7359%]\n",
      "1465 [Discriminator loss: 0.7155%, acc.: 33.59%][Generator loss: 0.7322%]\n",
      "1466 [Discriminator loss: 0.7085%, acc.: 37.89%][Generator loss: 0.7295%]\n",
      "1467 [Discriminator loss: 0.7169%, acc.: 33.98%][Generator loss: 0.7996%]\n",
      "1468 [Discriminator loss: 0.7146%, acc.: 49.22%][Generator loss: 0.8225%]\n",
      "1469 [Discriminator loss: 0.7440%, acc.: 35.55%][Generator loss: 0.7687%]\n",
      "1470 [Discriminator loss: 0.7194%, acc.: 35.16%][Generator loss: 0.7393%]\n",
      "1471 [Discriminator loss: 0.7174%, acc.: 32.42%][Generator loss: 0.7316%]\n",
      "1472 [Discriminator loss: 0.7237%, acc.: 34.38%][Generator loss: 0.7298%]\n",
      "1473 [Discriminator loss: 0.7130%, acc.: 27.73%][Generator loss: 0.7248%]\n",
      "1474 [Discriminator loss: 0.7120%, acc.: 26.17%][Generator loss: 0.7315%]\n",
      "1475 [Discriminator loss: 0.7012%, acc.: 40.23%][Generator loss: 0.7318%]\n",
      "1476 [Discriminator loss: 0.7080%, acc.: 42.58%][Generator loss: 0.7445%]\n",
      "1477 [Discriminator loss: 0.7269%, acc.: 31.25%][Generator loss: 0.7368%]\n",
      "1478 [Discriminator loss: 0.7053%, acc.: 39.45%][Generator loss: 0.7500%]\n",
      "1479 [Discriminator loss: 0.7216%, acc.: 19.53%][Generator loss: 0.7252%]\n",
      "1480 [Discriminator loss: 0.7115%, acc.: 30.86%][Generator loss: 0.7286%]\n",
      "1481 [Discriminator loss: 0.7112%, acc.: 34.38%][Generator loss: 0.7392%]\n",
      "1482 [Discriminator loss: 0.7064%, acc.: 38.28%][Generator loss: 0.7417%]\n",
      "1483 [Discriminator loss: 0.7100%, acc.: 34.38%][Generator loss: 0.7263%]\n",
      "1484 [Discriminator loss: 0.7145%, acc.: 31.64%][Generator loss: 0.8053%]\n",
      "1485 [Discriminator loss: 0.7236%, acc.: 42.97%][Generator loss: 0.8177%]\n",
      "1486 [Discriminator loss: 0.7380%, acc.: 36.33%][Generator loss: 0.7714%]\n",
      "1487 [Discriminator loss: 0.7236%, acc.: 37.11%][Generator loss: 0.7518%]\n",
      "1488 [Discriminator loss: 0.7121%, acc.: 31.25%][Generator loss: 0.7417%]\n",
      "1489 [Discriminator loss: 0.7111%, acc.: 32.42%][Generator loss: 0.7273%]\n",
      "1490 [Discriminator loss: 0.7109%, acc.: 28.91%][Generator loss: 0.7237%]\n",
      "1491 [Discriminator loss: 0.7068%, acc.: 35.94%][Generator loss: 0.7306%]\n",
      "1492 [Discriminator loss: 0.7117%, acc.: 31.64%][Generator loss: 0.7290%]\n",
      "1493 [Discriminator loss: 0.7072%, acc.: 36.72%][Generator loss: 0.7333%]\n",
      "1494 [Discriminator loss: 0.7105%, acc.: 37.11%][Generator loss: 0.7298%]\n",
      "1495 [Discriminator loss: 0.7095%, acc.: 32.42%][Generator loss: 0.7299%]\n",
      "1496 [Discriminator loss: 0.7093%, acc.: 33.59%][Generator loss: 0.7355%]\n",
      "1497 [Discriminator loss: 0.7088%, acc.: 35.55%][Generator loss: 0.7482%]\n",
      "1498 [Discriminator loss: 0.7179%, acc.: 23.44%][Generator loss: 0.7308%]\n",
      "1499 [Discriminator loss: 0.7072%, acc.: 38.28%][Generator loss: 0.7318%]\n",
      "1500 [Discriminator loss: 0.7179%, acc.: 32.81%][Generator loss: 0.7379%]\n",
      "1501 [Discriminator loss: 0.7141%, acc.: 24.61%][Generator loss: 0.7345%]\n",
      "1502 [Discriminator loss: 0.7093%, acc.: 39.84%][Generator loss: 0.7457%]\n",
      "1503 [Discriminator loss: 0.7199%, acc.: 27.73%][Generator loss: 0.7475%]\n",
      "1504 [Discriminator loss: 0.7177%, acc.: 31.64%][Generator loss: 0.7478%]\n",
      "1505 [Discriminator loss: 0.7190%, acc.: 33.98%][Generator loss: 0.7304%]\n",
      "1506 [Discriminator loss: 0.7071%, acc.: 30.86%][Generator loss: 0.7290%]\n",
      "1507 [Discriminator loss: 0.7107%, acc.: 30.08%][Generator loss: 0.7345%]\n",
      "1508 [Discriminator loss: 0.7093%, acc.: 37.89%][Generator loss: 0.7405%]\n",
      "1509 [Discriminator loss: 0.7101%, acc.: 35.94%][Generator loss: 0.7351%]\n",
      "1510 [Discriminator loss: 0.7082%, acc.: 33.98%][Generator loss: 0.7420%]\n",
      "1511 [Discriminator loss: 0.7241%, acc.: 22.66%][Generator loss: 0.7475%]\n",
      "1512 [Discriminator loss: 0.7102%, acc.: 39.06%][Generator loss: 0.7736%]\n",
      "1513 [Discriminator loss: 0.7260%, acc.: 32.42%][Generator loss: 0.7367%]\n",
      "1514 [Discriminator loss: 0.7141%, acc.: 29.69%][Generator loss: 0.7368%]\n",
      "1515 [Discriminator loss: 0.7120%, acc.: 36.72%][Generator loss: 0.7313%]\n",
      "1516 [Discriminator loss: 0.7130%, acc.: 20.70%][Generator loss: 0.7307%]\n",
      "1517 [Discriminator loss: 0.7071%, acc.: 39.84%][Generator loss: 0.7407%]\n",
      "1518 [Discriminator loss: 0.7202%, acc.: 31.64%][Generator loss: 0.7547%]\n",
      "1519 [Discriminator loss: 0.7109%, acc.: 33.20%][Generator loss: 0.7465%]\n",
      "1520 [Discriminator loss: 0.7105%, acc.: 35.94%][Generator loss: 0.7265%]\n",
      "1521 [Discriminator loss: 0.7048%, acc.: 29.69%][Generator loss: 0.7373%]\n",
      "1522 [Discriminator loss: 0.7024%, acc.: 42.58%][Generator loss: 0.7504%]\n",
      "1523 [Discriminator loss: 0.7140%, acc.: 33.20%][Generator loss: 0.7261%]\n",
      "1524 [Discriminator loss: 0.7150%, acc.: 33.59%][Generator loss: 0.7537%]\n",
      "1525 [Discriminator loss: 0.7086%, acc.: 49.22%][Generator loss: 0.7706%]\n",
      "1526 [Discriminator loss: 0.7338%, acc.: 31.25%][Generator loss: 0.7341%]\n",
      "1527 [Discriminator loss: 0.7188%, acc.: 20.70%][Generator loss: 0.7299%]\n",
      "1528 [Discriminator loss: 0.7107%, acc.: 33.20%][Generator loss: 0.7248%]\n",
      "1529 [Discriminator loss: 0.7075%, acc.: 26.56%][Generator loss: 0.7531%]\n",
      "1530 [Discriminator loss: 0.7053%, acc.: 44.53%][Generator loss: 0.7518%]\n",
      "1531 [Discriminator loss: 0.7190%, acc.: 34.38%][Generator loss: 0.7296%]\n",
      "1532 [Discriminator loss: 0.7082%, acc.: 33.59%][Generator loss: 0.7299%]\n",
      "1533 [Discriminator loss: 0.7050%, acc.: 38.28%][Generator loss: 0.7196%]\n",
      "1534 [Discriminator loss: 0.7163%, acc.: 37.11%][Generator loss: 0.7258%]\n",
      "1535 [Discriminator loss: 0.7165%, acc.: 27.34%][Generator loss: 0.7345%]\n",
      "1536 [Discriminator loss: 0.7132%, acc.: 25.39%][Generator loss: 0.7484%]\n",
      "1537 [Discriminator loss: 0.7051%, acc.: 42.97%][Generator loss: 0.7639%]\n",
      "1538 [Discriminator loss: 0.7246%, acc.: 29.69%][Generator loss: 0.7366%]\n",
      "1539 [Discriminator loss: 0.7120%, acc.: 31.25%][Generator loss: 0.7309%]\n",
      "1540 [Discriminator loss: 0.7085%, acc.: 29.30%][Generator loss: 0.7272%]\n",
      "1541 [Discriminator loss: 0.7056%, acc.: 36.72%][Generator loss: 0.7338%]\n",
      "1542 [Discriminator loss: 0.7073%, acc.: 38.28%][Generator loss: 0.7342%]\n",
      "1543 [Discriminator loss: 0.7107%, acc.: 34.38%][Generator loss: 0.7369%]\n",
      "1544 [Discriminator loss: 0.7165%, acc.: 30.47%][Generator loss: 0.7452%]\n",
      "1545 [Discriminator loss: 0.7187%, acc.: 19.53%][Generator loss: 0.7436%]\n",
      "1546 [Discriminator loss: 0.7113%, acc.: 26.95%][Generator loss: 0.7333%]\n",
      "1547 [Discriminator loss: 0.7031%, acc.: 42.19%][Generator loss: 0.7413%]\n",
      "1548 [Discriminator loss: 0.7122%, acc.: 35.16%][Generator loss: 0.7379%]\n",
      "1549 [Discriminator loss: 0.7100%, acc.: 39.45%][Generator loss: 0.7567%]\n",
      "1550 [Discriminator loss: 0.7240%, acc.: 29.30%][Generator loss: 0.7286%]\n",
      "1551 [Discriminator loss: 0.7141%, acc.: 26.56%][Generator loss: 0.7357%]\n",
      "1552 [Discriminator loss: 0.7135%, acc.: 30.08%][Generator loss: 0.7446%]\n",
      "1553 [Discriminator loss: 0.7129%, acc.: 33.20%][Generator loss: 0.7318%]\n",
      "1554 [Discriminator loss: 0.7012%, acc.: 42.58%][Generator loss: 0.7309%]\n",
      "1555 [Discriminator loss: 0.7100%, acc.: 36.33%][Generator loss: 0.7275%]\n",
      "1556 [Discriminator loss: 0.7131%, acc.: 30.47%][Generator loss: 0.7387%]\n",
      "1557 [Discriminator loss: 0.7018%, acc.: 45.31%][Generator loss: 0.7728%]\n",
      "1558 [Discriminator loss: 0.7291%, acc.: 23.44%][Generator loss: 0.7370%]\n",
      "1559 [Discriminator loss: 0.7130%, acc.: 23.44%][Generator loss: 0.7310%]\n",
      "1560 [Discriminator loss: 0.7063%, acc.: 35.16%][Generator loss: 0.7288%]\n",
      "1561 [Discriminator loss: 0.7143%, acc.: 26.17%][Generator loss: 0.7298%]\n",
      "1562 [Discriminator loss: 0.7085%, acc.: 25.39%][Generator loss: 0.7318%]\n",
      "1563 [Discriminator loss: 0.7047%, acc.: 44.92%][Generator loss: 0.7509%]\n",
      "1564 [Discriminator loss: 0.7199%, acc.: 38.67%][Generator loss: 0.7371%]\n",
      "1565 [Discriminator loss: 0.7146%, acc.: 30.86%][Generator loss: 0.7278%]\n",
      "1566 [Discriminator loss: 0.7111%, acc.: 30.47%][Generator loss: 0.7303%]\n",
      "1567 [Discriminator loss: 0.7072%, acc.: 37.89%][Generator loss: 0.7444%]\n",
      "1568 [Discriminator loss: 0.7145%, acc.: 23.44%][Generator loss: 0.7225%]\n",
      "1569 [Discriminator loss: 0.7111%, acc.: 33.98%][Generator loss: 0.7220%]\n",
      "1570 [Discriminator loss: 0.7114%, acc.: 34.77%][Generator loss: 0.7278%]\n",
      "1571 [Discriminator loss: 0.7078%, acc.: 34.77%][Generator loss: 0.7717%]\n",
      "1572 [Discriminator loss: 0.7155%, acc.: 48.05%][Generator loss: 0.7886%]\n",
      "1573 [Discriminator loss: 0.7292%, acc.: 35.94%][Generator loss: 0.7492%]\n",
      "1574 [Discriminator loss: 0.7122%, acc.: 35.55%][Generator loss: 0.7380%]\n",
      "1575 [Discriminator loss: 0.7085%, acc.: 33.59%][Generator loss: 0.7284%]\n",
      "1576 [Discriminator loss: 0.7115%, acc.: 24.22%][Generator loss: 0.7313%]\n",
      "1577 [Discriminator loss: 0.7067%, acc.: 36.33%][Generator loss: 0.7299%]\n",
      "1578 [Discriminator loss: 0.7055%, acc.: 33.59%][Generator loss: 0.7340%]\n",
      "1579 [Discriminator loss: 0.7124%, acc.: 23.05%][Generator loss: 0.7488%]\n",
      "1580 [Discriminator loss: 0.7105%, acc.: 33.59%][Generator loss: 0.7493%]\n",
      "1581 [Discriminator loss: 0.7152%, acc.: 28.12%][Generator loss: 0.7336%]\n",
      "1582 [Discriminator loss: 0.7063%, acc.: 34.77%][Generator loss: 0.7265%]\n",
      "1583 [Discriminator loss: 0.7102%, acc.: 36.72%][Generator loss: 0.7286%]\n",
      "1584 [Discriminator loss: 0.7082%, acc.: 25.78%][Generator loss: 0.7287%]\n",
      "1585 [Discriminator loss: 0.7066%, acc.: 37.11%][Generator loss: 0.7273%]\n",
      "1586 [Discriminator loss: 0.7041%, acc.: 39.06%][Generator loss: 0.7970%]\n",
      "1587 [Discriminator loss: 0.7153%, acc.: 47.66%][Generator loss: 0.8148%]\n",
      "1588 [Discriminator loss: 0.7331%, acc.: 36.72%][Generator loss: 0.7641%]\n",
      "1589 [Discriminator loss: 0.7171%, acc.: 39.45%][Generator loss: 0.7490%]\n",
      "1590 [Discriminator loss: 0.7110%, acc.: 39.06%][Generator loss: 0.7386%]\n",
      "1591 [Discriminator loss: 0.7114%, acc.: 38.67%][Generator loss: 0.7293%]\n",
      "1592 [Discriminator loss: 0.7185%, acc.: 25.00%][Generator loss: 0.7230%]\n",
      "1593 [Discriminator loss: 0.7071%, acc.: 30.86%][Generator loss: 0.7212%]\n",
      "1594 [Discriminator loss: 0.7129%, acc.: 32.03%][Generator loss: 0.7310%]\n",
      "1595 [Discriminator loss: 0.7138%, acc.: 31.64%][Generator loss: 0.7265%]\n",
      "1596 [Discriminator loss: 0.7077%, acc.: 32.42%][Generator loss: 0.7293%]\n",
      "1597 [Discriminator loss: 0.7039%, acc.: 39.45%][Generator loss: 0.7298%]\n",
      "1598 [Discriminator loss: 0.7158%, acc.: 32.42%][Generator loss: 0.7299%]\n",
      "1599 [Discriminator loss: 0.7099%, acc.: 25.78%][Generator loss: 0.7270%]\n",
      "1600 [Discriminator loss: 0.7122%, acc.: 37.50%][Generator loss: 0.7929%]\n",
      "1601 [Discriminator loss: 0.7185%, acc.: 40.23%][Generator loss: 0.7891%]\n",
      "1602 [Discriminator loss: 0.7243%, acc.: 35.94%][Generator loss: 0.7591%]\n",
      "1603 [Discriminator loss: 0.7204%, acc.: 29.69%][Generator loss: 0.7424%]\n",
      "1604 [Discriminator loss: 0.7076%, acc.: 41.02%][Generator loss: 0.7329%]\n",
      "1605 [Discriminator loss: 0.7101%, acc.: 32.03%][Generator loss: 0.7268%]\n",
      "1606 [Discriminator loss: 0.7053%, acc.: 32.42%][Generator loss: 0.7296%]\n",
      "1607 [Discriminator loss: 0.7085%, acc.: 33.98%][Generator loss: 0.7257%]\n",
      "1608 [Discriminator loss: 0.7094%, acc.: 25.39%][Generator loss: 0.7236%]\n",
      "1609 [Discriminator loss: 0.7065%, acc.: 30.47%][Generator loss: 0.7258%]\n",
      "1610 [Discriminator loss: 0.6990%, acc.: 35.55%][Generator loss: 0.7355%]\n",
      "1611 [Discriminator loss: 0.7043%, acc.: 37.11%][Generator loss: 0.7410%]\n",
      "1612 [Discriminator loss: 0.7174%, acc.: 27.34%][Generator loss: 0.7234%]\n",
      "1613 [Discriminator loss: 0.7032%, acc.: 40.62%][Generator loss: 0.7246%]\n",
      "1614 [Discriminator loss: 0.7053%, acc.: 39.06%][Generator loss: 0.7362%]\n",
      "1615 [Discriminator loss: 0.7103%, acc.: 29.69%][Generator loss: 0.7329%]\n",
      "1616 [Discriminator loss: 0.7111%, acc.: 25.39%][Generator loss: 0.7251%]\n",
      "1617 [Discriminator loss: 0.7041%, acc.: 30.08%][Generator loss: 0.7916%]\n",
      "1618 [Discriminator loss: 0.7181%, acc.: 42.97%][Generator loss: 0.7998%]\n",
      "1619 [Discriminator loss: 0.7360%, acc.: 31.25%][Generator loss: 0.7577%]\n",
      "1620 [Discriminator loss: 0.7188%, acc.: 28.12%][Generator loss: 0.7446%]\n",
      "1621 [Discriminator loss: 0.7106%, acc.: 26.56%][Generator loss: 0.7340%]\n",
      "1622 [Discriminator loss: 0.7136%, acc.: 35.94%][Generator loss: 0.7299%]\n",
      "1623 [Discriminator loss: 0.7057%, acc.: 37.11%][Generator loss: 0.7370%]\n",
      "1624 [Discriminator loss: 0.7036%, acc.: 39.84%][Generator loss: 0.7334%]\n",
      "1625 [Discriminator loss: 0.7160%, acc.: 28.52%][Generator loss: 0.7281%]\n",
      "1626 [Discriminator loss: 0.7041%, acc.: 34.77%][Generator loss: 0.7264%]\n",
      "1627 [Discriminator loss: 0.7079%, acc.: 37.50%][Generator loss: 0.7320%]\n",
      "1628 [Discriminator loss: 0.7104%, acc.: 34.38%][Generator loss: 0.7246%]\n",
      "1629 [Discriminator loss: 0.7061%, acc.: 30.47%][Generator loss: 0.7444%]\n",
      "1630 [Discriminator loss: 0.7032%, acc.: 41.02%][Generator loss: 0.7777%]\n",
      "1631 [Discriminator loss: 0.7199%, acc.: 38.67%][Generator loss: 0.7397%]\n",
      "1632 [Discriminator loss: 0.7105%, acc.: 29.30%][Generator loss: 0.7373%]\n",
      "1633 [Discriminator loss: 0.7119%, acc.: 31.64%][Generator loss: 0.7271%]\n",
      "1634 [Discriminator loss: 0.7085%, acc.: 27.34%][Generator loss: 0.7242%]\n",
      "1635 [Discriminator loss: 0.7043%, acc.: 39.06%][Generator loss: 0.7205%]\n",
      "1636 [Discriminator loss: 0.7163%, acc.: 30.08%][Generator loss: 0.7469%]\n",
      "1637 [Discriminator loss: 0.7092%, acc.: 37.50%][Generator loss: 0.7623%]\n",
      "1638 [Discriminator loss: 0.7223%, acc.: 31.25%][Generator loss: 0.7316%]\n",
      "1639 [Discriminator loss: 0.7046%, acc.: 37.50%][Generator loss: 0.7307%]\n",
      "1640 [Discriminator loss: 0.7110%, acc.: 34.38%][Generator loss: 0.7226%]\n",
      "1641 [Discriminator loss: 0.7051%, acc.: 26.56%][Generator loss: 0.7330%]\n",
      "1642 [Discriminator loss: 0.7044%, acc.: 39.84%][Generator loss: 0.7513%]\n",
      "1643 [Discriminator loss: 0.7199%, acc.: 27.73%][Generator loss: 0.7301%]\n",
      "1644 [Discriminator loss: 0.7083%, acc.: 29.30%][Generator loss: 0.7245%]\n",
      "1645 [Discriminator loss: 0.7090%, acc.: 31.25%][Generator loss: 0.7235%]\n",
      "1646 [Discriminator loss: 0.7093%, acc.: 30.08%][Generator loss: 0.7232%]\n",
      "1647 [Discriminator loss: 0.7083%, acc.: 35.16%][Generator loss: 0.7228%]\n",
      "1648 [Discriminator loss: 0.7052%, acc.: 35.94%][Generator loss: 0.7368%]\n",
      "1649 [Discriminator loss: 0.7117%, acc.: 41.41%][Generator loss: 0.7360%]\n",
      "1650 [Discriminator loss: 0.7065%, acc.: 37.11%][Generator loss: 0.7558%]\n",
      "1651 [Discriminator loss: 0.7230%, acc.: 16.02%][Generator loss: 0.7336%]\n",
      "1652 [Discriminator loss: 0.7125%, acc.: 34.38%][Generator loss: 0.7214%]\n",
      "1653 [Discriminator loss: 0.7094%, acc.: 25.39%][Generator loss: 0.7603%]\n",
      "1654 [Discriminator loss: 0.7089%, acc.: 42.97%][Generator loss: 0.7874%]\n",
      "1655 [Discriminator loss: 0.7269%, acc.: 39.45%][Generator loss: 0.7501%]\n",
      "1656 [Discriminator loss: 0.7238%, acc.: 35.55%][Generator loss: 0.7334%]\n",
      "1657 [Discriminator loss: 0.7155%, acc.: 19.53%][Generator loss: 0.7256%]\n",
      "1658 [Discriminator loss: 0.7131%, acc.: 36.33%][Generator loss: 0.7208%]\n",
      "1659 [Discriminator loss: 0.7109%, acc.: 30.86%][Generator loss: 0.7251%]\n",
      "1660 [Discriminator loss: 0.7059%, acc.: 33.59%][Generator loss: 0.7543%]\n",
      "1661 [Discriminator loss: 0.7091%, acc.: 38.67%][Generator loss: 0.7566%]\n",
      "1662 [Discriminator loss: 0.7144%, acc.: 40.23%][Generator loss: 0.7369%]\n",
      "1663 [Discriminator loss: 0.7068%, acc.: 35.55%][Generator loss: 0.7286%]\n",
      "1664 [Discriminator loss: 0.7165%, acc.: 36.33%][Generator loss: 0.7206%]\n",
      "1665 [Discriminator loss: 0.7082%, acc.: 27.73%][Generator loss: 0.7229%]\n",
      "1666 [Discriminator loss: 0.7085%, acc.: 26.17%][Generator loss: 0.7278%]\n",
      "1667 [Discriminator loss: 0.7071%, acc.: 27.34%][Generator loss: 0.7247%]\n",
      "1668 [Discriminator loss: 0.7077%, acc.: 26.95%][Generator loss: 0.7340%]\n",
      "1669 [Discriminator loss: 0.7051%, acc.: 40.62%][Generator loss: 0.7533%]\n",
      "1670 [Discriminator loss: 0.7204%, acc.: 37.11%][Generator loss: 0.7313%]\n",
      "1671 [Discriminator loss: 0.7087%, acc.: 40.23%][Generator loss: 0.7304%]\n",
      "1672 [Discriminator loss: 0.7074%, acc.: 33.98%][Generator loss: 0.7236%]\n",
      "1673 [Discriminator loss: 0.7114%, acc.: 36.33%][Generator loss: 0.7291%]\n",
      "1674 [Discriminator loss: 0.7065%, acc.: 23.05%][Generator loss: 0.7357%]\n",
      "1675 [Discriminator loss: 0.7133%, acc.: 22.27%][Generator loss: 0.7241%]\n",
      "1676 [Discriminator loss: 0.7047%, acc.: 34.38%][Generator loss: 0.7328%]\n",
      "1677 [Discriminator loss: 0.7010%, acc.: 47.27%][Generator loss: 0.7569%]\n",
      "1678 [Discriminator loss: 0.7246%, acc.: 28.91%][Generator loss: 0.7314%]\n",
      "1679 [Discriminator loss: 0.7131%, acc.: 19.53%][Generator loss: 0.7285%]\n",
      "1680 [Discriminator loss: 0.7041%, acc.: 35.94%][Generator loss: 0.7420%]\n",
      "1681 [Discriminator loss: 0.7103%, acc.: 24.22%][Generator loss: 0.7298%]\n",
      "1682 [Discriminator loss: 0.7043%, acc.: 38.67%][Generator loss: 0.7425%]\n",
      "1683 [Discriminator loss: 0.7055%, acc.: 37.89%][Generator loss: 0.7769%]\n",
      "1684 [Discriminator loss: 0.7262%, acc.: 30.08%][Generator loss: 0.7450%]\n",
      "1685 [Discriminator loss: 0.7090%, acc.: 33.98%][Generator loss: 0.7446%]\n",
      "1686 [Discriminator loss: 0.7160%, acc.: 22.66%][Generator loss: 0.7266%]\n",
      "1687 [Discriminator loss: 0.7087%, acc.: 32.42%][Generator loss: 0.7263%]\n",
      "1688 [Discriminator loss: 0.7093%, acc.: 26.56%][Generator loss: 0.7329%]\n",
      "1689 [Discriminator loss: 0.7077%, acc.: 36.33%][Generator loss: 0.7590%]\n",
      "1690 [Discriminator loss: 0.7052%, acc.: 45.70%][Generator loss: 0.7907%]\n",
      "1691 [Discriminator loss: 0.7282%, acc.: 42.19%][Generator loss: 0.7524%]\n",
      "1692 [Discriminator loss: 0.7208%, acc.: 35.94%][Generator loss: 0.7377%]\n",
      "1693 [Discriminator loss: 0.7151%, acc.: 17.58%][Generator loss: 0.7288%]\n",
      "1694 [Discriminator loss: 0.7132%, acc.: 31.64%][Generator loss: 0.7286%]\n",
      "1695 [Discriminator loss: 0.7076%, acc.: 26.56%][Generator loss: 0.7310%]\n",
      "1696 [Discriminator loss: 0.7033%, acc.: 39.45%][Generator loss: 0.7320%]\n",
      "1697 [Discriminator loss: 0.7060%, acc.: 33.98%][Generator loss: 0.7257%]\n",
      "1698 [Discriminator loss: 0.7097%, acc.: 35.94%][Generator loss: 0.7512%]\n",
      "1699 [Discriminator loss: 0.7050%, acc.: 35.94%][Generator loss: 0.7615%]\n",
      "1700 [Discriminator loss: 0.7168%, acc.: 32.42%][Generator loss: 0.7322%]\n",
      "1701 [Discriminator loss: 0.7142%, acc.: 24.61%][Generator loss: 0.7289%]\n",
      "1702 [Discriminator loss: 0.7050%, acc.: 41.41%][Generator loss: 0.7312%]\n",
      "1703 [Discriminator loss: 0.7052%, acc.: 34.77%][Generator loss: 0.7284%]\n",
      "1704 [Discriminator loss: 0.7046%, acc.: 39.45%][Generator loss: 0.7273%]\n",
      "1705 [Discriminator loss: 0.7118%, acc.: 37.11%][Generator loss: 0.7299%]\n",
      "1706 [Discriminator loss: 0.7082%, acc.: 26.56%][Generator loss: 0.7358%]\n",
      "1707 [Discriminator loss: 0.6997%, acc.: 48.83%][Generator loss: 0.7666%]\n",
      "1708 [Discriminator loss: 0.7219%, acc.: 39.06%][Generator loss: 0.7415%]\n",
      "1709 [Discriminator loss: 0.7156%, acc.: 25.00%][Generator loss: 0.7273%]\n",
      "1710 [Discriminator loss: 0.7061%, acc.: 32.81%][Generator loss: 0.7356%]\n",
      "1711 [Discriminator loss: 0.7087%, acc.: 23.05%][Generator loss: 0.7251%]\n",
      "1712 [Discriminator loss: 0.7040%, acc.: 33.59%][Generator loss: 0.7323%]\n",
      "1713 [Discriminator loss: 0.7090%, acc.: 29.69%][Generator loss: 0.7312%]\n",
      "1714 [Discriminator loss: 0.7081%, acc.: 32.03%][Generator loss: 0.7247%]\n",
      "1715 [Discriminator loss: 0.7078%, acc.: 22.66%][Generator loss: 0.7336%]\n",
      "1716 [Discriminator loss: 0.7067%, acc.: 31.64%][Generator loss: 0.7248%]\n",
      "1717 [Discriminator loss: 0.7070%, acc.: 27.73%][Generator loss: 0.7220%]\n",
      "1718 [Discriminator loss: 0.7088%, acc.: 35.16%][Generator loss: 0.7440%]\n",
      "1719 [Discriminator loss: 0.7077%, acc.: 37.50%][Generator loss: 0.7635%]\n",
      "1720 [Discriminator loss: 0.7229%, acc.: 29.69%][Generator loss: 0.7410%]\n",
      "1721 [Discriminator loss: 0.7080%, acc.: 37.11%][Generator loss: 0.7314%]\n",
      "1722 [Discriminator loss: 0.7059%, acc.: 33.20%][Generator loss: 0.7248%]\n",
      "1723 [Discriminator loss: 0.7096%, acc.: 29.69%][Generator loss: 0.7288%]\n",
      "1724 [Discriminator loss: 0.7050%, acc.: 33.98%][Generator loss: 0.7405%]\n",
      "1725 [Discriminator loss: 0.7101%, acc.: 41.41%][Generator loss: 0.7185%]\n",
      "1726 [Discriminator loss: 0.7257%, acc.: 29.30%][Generator loss: 0.7771%]\n",
      "1727 [Discriminator loss: 0.7313%, acc.: 28.91%][Generator loss: 0.7641%]\n",
      "1728 [Discriminator loss: 0.7224%, acc.: 33.98%][Generator loss: 0.7435%]\n",
      "1729 [Discriminator loss: 0.7186%, acc.: 24.22%][Generator loss: 0.7338%]\n",
      "1730 [Discriminator loss: 0.7095%, acc.: 28.52%][Generator loss: 0.7278%]\n",
      "1731 [Discriminator loss: 0.7049%, acc.: 39.84%][Generator loss: 0.7294%]\n",
      "1732 [Discriminator loss: 0.7038%, acc.: 36.72%][Generator loss: 0.7255%]\n",
      "1733 [Discriminator loss: 0.7040%, acc.: 27.73%][Generator loss: 0.7262%]\n",
      "1734 [Discriminator loss: 0.7045%, acc.: 35.16%][Generator loss: 0.7254%]\n",
      "1735 [Discriminator loss: 0.7039%, acc.: 34.77%][Generator loss: 0.7349%]\n",
      "1736 [Discriminator loss: 0.7038%, acc.: 32.03%][Generator loss: 0.7324%]\n",
      "1737 [Discriminator loss: 0.7082%, acc.: 37.89%][Generator loss: 0.7288%]\n",
      "1738 [Discriminator loss: 0.7095%, acc.: 27.73%][Generator loss: 0.7320%]\n",
      "1739 [Discriminator loss: 0.7050%, acc.: 38.28%][Generator loss: 0.7252%]\n",
      "1740 [Discriminator loss: 0.7089%, acc.: 33.20%][Generator loss: 0.7319%]\n",
      "1741 [Discriminator loss: 0.7103%, acc.: 29.30%][Generator loss: 0.7257%]\n",
      "1742 [Discriminator loss: 0.7019%, acc.: 38.28%][Generator loss: 0.7316%]\n",
      "1743 [Discriminator loss: 0.7132%, acc.: 32.81%][Generator loss: 0.7614%]\n",
      "1744 [Discriminator loss: 0.7066%, acc.: 44.92%][Generator loss: 0.7708%]\n",
      "1745 [Discriminator loss: 0.7241%, acc.: 32.81%][Generator loss: 0.7378%]\n",
      "1746 [Discriminator loss: 0.7139%, acc.: 21.48%][Generator loss: 0.7342%]\n",
      "1747 [Discriminator loss: 0.7087%, acc.: 33.20%][Generator loss: 0.7299%]\n",
      "1748 [Discriminator loss: 0.7054%, acc.: 36.33%][Generator loss: 0.7260%]\n",
      "1749 [Discriminator loss: 0.7042%, acc.: 38.28%][Generator loss: 0.7317%]\n",
      "1750 [Discriminator loss: 0.7100%, acc.: 23.05%][Generator loss: 0.7315%]\n",
      "1751 [Discriminator loss: 0.7062%, acc.: 32.42%][Generator loss: 0.7320%]\n",
      "1752 [Discriminator loss: 0.7078%, acc.: 27.73%][Generator loss: 0.7313%]\n",
      "1753 [Discriminator loss: 0.7071%, acc.: 38.28%][Generator loss: 0.7410%]\n",
      "1754 [Discriminator loss: 0.7057%, acc.: 36.72%][Generator loss: 0.7632%]\n",
      "1755 [Discriminator loss: 0.7227%, acc.: 40.62%][Generator loss: 0.7352%]\n",
      "1756 [Discriminator loss: 0.7113%, acc.: 25.78%][Generator loss: 0.7273%]\n",
      "1757 [Discriminator loss: 0.7070%, acc.: 33.98%][Generator loss: 0.7260%]\n",
      "1758 [Discriminator loss: 0.7104%, acc.: 27.34%][Generator loss: 0.7339%]\n",
      "1759 [Discriminator loss: 0.7060%, acc.: 35.55%][Generator loss: 0.7411%]\n",
      "1760 [Discriminator loss: 0.7113%, acc.: 32.03%][Generator loss: 0.7362%]\n",
      "1761 [Discriminator loss: 0.7103%, acc.: 26.56%][Generator loss: 0.7323%]\n",
      "1762 [Discriminator loss: 0.7061%, acc.: 35.55%][Generator loss: 0.7275%]\n",
      "1763 [Discriminator loss: 0.7056%, acc.: 31.25%][Generator loss: 0.7366%]\n",
      "1764 [Discriminator loss: 0.7074%, acc.: 35.55%][Generator loss: 0.7507%]\n",
      "1765 [Discriminator loss: 0.7093%, acc.: 46.48%][Generator loss: 0.7779%]\n",
      "1766 [Discriminator loss: 0.7231%, acc.: 35.16%][Generator loss: 0.7472%]\n",
      "1767 [Discriminator loss: 0.7127%, acc.: 29.69%][Generator loss: 0.7384%]\n",
      "1768 [Discriminator loss: 0.7087%, acc.: 38.28%][Generator loss: 0.7413%]\n",
      "1769 [Discriminator loss: 0.7082%, acc.: 34.38%][Generator loss: 0.7315%]\n",
      "1770 [Discriminator loss: 0.7104%, acc.: 29.69%][Generator loss: 0.7226%]\n",
      "1771 [Discriminator loss: 0.7066%, acc.: 27.34%][Generator loss: 0.7278%]\n",
      "1772 [Discriminator loss: 0.7023%, acc.: 43.75%][Generator loss: 0.7273%]\n",
      "1773 [Discriminator loss: 0.7084%, acc.: 35.16%][Generator loss: 0.7303%]\n",
      "1774 [Discriminator loss: 0.7073%, acc.: 25.78%][Generator loss: 0.7564%]\n",
      "1775 [Discriminator loss: 0.7066%, acc.: 39.84%][Generator loss: 0.7783%]\n",
      "1776 [Discriminator loss: 0.7232%, acc.: 39.06%][Generator loss: 0.7438%]\n",
      "1777 [Discriminator loss: 0.7127%, acc.: 37.89%][Generator loss: 0.7390%]\n",
      "1778 [Discriminator loss: 0.7096%, acc.: 37.11%][Generator loss: 0.7288%]\n",
      "1779 [Discriminator loss: 0.7058%, acc.: 30.47%][Generator loss: 0.7332%]\n",
      "1780 [Discriminator loss: 0.7069%, acc.: 32.03%][Generator loss: 0.7317%]\n",
      "1781 [Discriminator loss: 0.7085%, acc.: 33.98%][Generator loss: 0.7345%]\n",
      "1782 [Discriminator loss: 0.7056%, acc.: 38.28%][Generator loss: 0.7338%]\n",
      "1783 [Discriminator loss: 0.7042%, acc.: 42.19%][Generator loss: 0.7272%]\n",
      "1784 [Discriminator loss: 0.7056%, acc.: 36.33%][Generator loss: 0.7238%]\n",
      "1785 [Discriminator loss: 0.7047%, acc.: 23.83%][Generator loss: 0.8530%]\n",
      "1786 [Discriminator loss: 0.7531%, acc.: 44.53%][Generator loss: 0.7905%]\n",
      "1787 [Discriminator loss: 0.7222%, acc.: 37.89%][Generator loss: 0.7600%]\n",
      "1788 [Discriminator loss: 0.7124%, acc.: 39.84%][Generator loss: 0.7545%]\n",
      "1789 [Discriminator loss: 0.7101%, acc.: 39.84%][Generator loss: 0.7417%]\n",
      "1790 [Discriminator loss: 0.7055%, acc.: 40.62%][Generator loss: 0.7408%]\n",
      "1791 [Discriminator loss: 0.7058%, acc.: 35.94%][Generator loss: 0.7334%]\n",
      "1792 [Discriminator loss: 0.7062%, acc.: 37.11%][Generator loss: 0.7286%]\n",
      "1793 [Discriminator loss: 0.7049%, acc.: 41.02%][Generator loss: 0.7281%]\n",
      "1794 [Discriminator loss: 0.7061%, acc.: 30.86%][Generator loss: 0.7267%]\n",
      "1795 [Discriminator loss: 0.7074%, acc.: 39.45%][Generator loss: 0.7330%]\n",
      "1796 [Discriminator loss: 0.7056%, acc.: 33.59%][Generator loss: 0.7294%]\n",
      "1797 [Discriminator loss: 0.7040%, acc.: 42.19%][Generator loss: 0.7248%]\n",
      "1798 [Discriminator loss: 0.7085%, acc.: 35.16%][Generator loss: 0.7347%]\n",
      "1799 [Discriminator loss: 0.7104%, acc.: 21.88%][Generator loss: 0.7250%]\n",
      "1800 [Discriminator loss: 0.7047%, acc.: 32.81%][Generator loss: 0.7336%]\n",
      "1801 [Discriminator loss: 0.7044%, acc.: 35.94%][Generator loss: 0.7382%]\n",
      "1802 [Discriminator loss: 0.7093%, acc.: 30.47%][Generator loss: 0.7256%]\n",
      "1803 [Discriminator loss: 0.7105%, acc.: 22.27%][Generator loss: 0.7254%]\n",
      "1804 [Discriminator loss: 0.7063%, acc.: 28.12%][Generator loss: 0.7290%]\n",
      "1805 [Discriminator loss: 0.7065%, acc.: 34.77%][Generator loss: 0.7340%]\n",
      "1806 [Discriminator loss: 0.7078%, acc.: 35.55%][Generator loss: 0.7400%]\n",
      "1807 [Discriminator loss: 0.7112%, acc.: 36.33%][Generator loss: 0.7269%]\n",
      "1808 [Discriminator loss: 0.7071%, acc.: 26.17%][Generator loss: 0.7281%]\n",
      "1809 [Discriminator loss: 0.7054%, acc.: 35.55%][Generator loss: 0.7266%]\n",
      "1810 [Discriminator loss: 0.7013%, acc.: 41.41%][Generator loss: 0.7287%]\n",
      "1811 [Discriminator loss: 0.7096%, acc.: 35.94%][Generator loss: 0.7313%]\n",
      "1812 [Discriminator loss: 0.7132%, acc.: 14.84%][Generator loss: 0.7262%]\n",
      "1813 [Discriminator loss: 0.7086%, acc.: 30.86%][Generator loss: 0.7631%]\n",
      "1814 [Discriminator loss: 0.7096%, acc.: 44.14%][Generator loss: 0.7814%]\n",
      "1815 [Discriminator loss: 0.7208%, acc.: 40.62%][Generator loss: 0.7507%]\n",
      "1816 [Discriminator loss: 0.7128%, acc.: 35.55%][Generator loss: 0.7413%]\n",
      "1817 [Discriminator loss: 0.7106%, acc.: 34.38%][Generator loss: 0.7325%]\n",
      "1818 [Discriminator loss: 0.7084%, acc.: 21.88%][Generator loss: 0.7309%]\n",
      "1819 [Discriminator loss: 0.7009%, acc.: 42.19%][Generator loss: 0.7252%]\n",
      "1820 [Discriminator loss: 0.7048%, acc.: 36.33%][Generator loss: 0.7371%]\n",
      "1821 [Discriminator loss: 0.7056%, acc.: 35.55%][Generator loss: 0.7305%]\n",
      "1822 [Discriminator loss: 0.7047%, acc.: 34.77%][Generator loss: 0.7378%]\n",
      "1823 [Discriminator loss: 0.7112%, acc.: 20.70%][Generator loss: 0.7246%]\n",
      "1824 [Discriminator loss: 0.7036%, acc.: 36.72%][Generator loss: 0.7262%]\n",
      "1825 [Discriminator loss: 0.7069%, acc.: 34.38%][Generator loss: 0.7264%]\n",
      "1826 [Discriminator loss: 0.7052%, acc.: 25.78%][Generator loss: 0.7664%]\n",
      "1827 [Discriminator loss: 0.7053%, acc.: 46.09%][Generator loss: 0.7873%]\n",
      "1828 [Discriminator loss: 0.7241%, acc.: 38.67%][Generator loss: 0.7530%]\n",
      "1829 [Discriminator loss: 0.7109%, acc.: 41.41%][Generator loss: 0.7418%]\n",
      "1830 [Discriminator loss: 0.7142%, acc.: 28.52%][Generator loss: 0.7314%]\n",
      "1831 [Discriminator loss: 0.7059%, acc.: 36.72%][Generator loss: 0.7254%]\n",
      "1832 [Discriminator loss: 0.7082%, acc.: 36.33%][Generator loss: 0.7270%]\n",
      "1833 [Discriminator loss: 0.7057%, acc.: 33.20%][Generator loss: 0.7318%]\n",
      "1834 [Discriminator loss: 0.7047%, acc.: 40.23%][Generator loss: 0.7261%]\n",
      "1835 [Discriminator loss: 0.7081%, acc.: 30.86%][Generator loss: 0.7352%]\n",
      "1836 [Discriminator loss: 0.7132%, acc.: 26.56%][Generator loss: 0.7323%]\n",
      "1837 [Discriminator loss: 0.7056%, acc.: 38.28%][Generator loss: 0.7280%]\n",
      "1838 [Discriminator loss: 0.7055%, acc.: 44.14%][Generator loss: 0.7318%]\n",
      "1839 [Discriminator loss: 0.7128%, acc.: 33.98%][Generator loss: 0.7357%]\n",
      "1840 [Discriminator loss: 0.7064%, acc.: 23.83%][Generator loss: 0.7339%]\n",
      "1841 [Discriminator loss: 0.7062%, acc.: 27.73%][Generator loss: 0.7272%]\n",
      "1842 [Discriminator loss: 0.7029%, acc.: 39.06%][Generator loss: 0.7355%]\n",
      "1843 [Discriminator loss: 0.7116%, acc.: 33.20%][Generator loss: 0.7266%]\n",
      "1844 [Discriminator loss: 0.7064%, acc.: 30.86%][Generator loss: 0.7280%]\n",
      "1845 [Discriminator loss: 0.7077%, acc.: 39.84%][Generator loss: 0.7235%]\n",
      "1846 [Discriminator loss: 0.7092%, acc.: 21.88%][Generator loss: 0.7804%]\n",
      "1847 [Discriminator loss: 0.7176%, acc.: 43.75%][Generator loss: 0.7838%]\n",
      "1848 [Discriminator loss: 0.7254%, acc.: 38.67%][Generator loss: 0.7535%]\n",
      "1849 [Discriminator loss: 0.7095%, acc.: 43.75%][Generator loss: 0.7433%]\n",
      "1850 [Discriminator loss: 0.7134%, acc.: 37.89%][Generator loss: 0.7319%]\n",
      "1851 [Discriminator loss: 0.7094%, acc.: 19.14%][Generator loss: 0.7277%]\n",
      "1852 [Discriminator loss: 0.7042%, acc.: 32.03%][Generator loss: 0.7293%]\n",
      "1853 [Discriminator loss: 0.7040%, acc.: 30.47%][Generator loss: 0.7300%]\n",
      "1854 [Discriminator loss: 0.7045%, acc.: 33.98%][Generator loss: 0.7285%]\n",
      "1855 [Discriminator loss: 0.7050%, acc.: 36.33%][Generator loss: 0.7267%]\n",
      "1856 [Discriminator loss: 0.7030%, acc.: 37.89%][Generator loss: 0.7293%]\n",
      "1857 [Discriminator loss: 0.7041%, acc.: 35.16%][Generator loss: 0.7325%]\n",
      "1858 [Discriminator loss: 0.7061%, acc.: 33.20%][Generator loss: 0.7285%]\n",
      "1859 [Discriminator loss: 0.7072%, acc.: 30.86%][Generator loss: 0.7353%]\n",
      "1860 [Discriminator loss: 0.7109%, acc.: 27.34%][Generator loss: 0.7214%]\n",
      "1861 [Discriminator loss: 0.7053%, acc.: 31.64%][Generator loss: 0.7320%]\n",
      "1862 [Discriminator loss: 0.7053%, acc.: 38.67%][Generator loss: 0.7475%]\n",
      "1863 [Discriminator loss: 0.7137%, acc.: 38.67%][Generator loss: 0.7294%]\n",
      "1864 [Discriminator loss: 0.7052%, acc.: 34.38%][Generator loss: 0.7289%]\n",
      "1865 [Discriminator loss: 0.7035%, acc.: 38.67%][Generator loss: 0.7294%]\n",
      "1866 [Discriminator loss: 0.7061%, acc.: 35.55%][Generator loss: 0.7269%]\n",
      "1867 [Discriminator loss: 0.7046%, acc.: 37.11%][Generator loss: 0.7488%]\n",
      "1868 [Discriminator loss: 0.7001%, acc.: 46.09%][Generator loss: 0.7744%]\n",
      "1869 [Discriminator loss: 0.7244%, acc.: 39.06%][Generator loss: 0.7462%]\n",
      "1870 [Discriminator loss: 0.7118%, acc.: 30.08%][Generator loss: 0.7350%]\n",
      "1871 [Discriminator loss: 0.7099%, acc.: 30.08%][Generator loss: 0.7308%]\n",
      "1872 [Discriminator loss: 0.7059%, acc.: 37.89%][Generator loss: 0.7261%]\n",
      "1873 [Discriminator loss: 0.7069%, acc.: 24.22%][Generator loss: 0.7353%]\n",
      "1874 [Discriminator loss: 0.7066%, acc.: 36.33%][Generator loss: 0.7307%]\n",
      "1875 [Discriminator loss: 0.7093%, acc.: 23.05%][Generator loss: 0.7261%]\n",
      "1876 [Discriminator loss: 0.7058%, acc.: 36.72%][Generator loss: 0.7378%]\n",
      "1877 [Discriminator loss: 0.7072%, acc.: 26.56%][Generator loss: 0.7434%]\n",
      "1878 [Discriminator loss: 0.7166%, acc.: 34.38%][Generator loss: 0.7270%]\n",
      "1879 [Discriminator loss: 0.7084%, acc.: 23.83%][Generator loss: 0.7263%]\n",
      "1880 [Discriminator loss: 0.7087%, acc.: 33.98%][Generator loss: 0.7352%]\n",
      "1881 [Discriminator loss: 0.7060%, acc.: 40.23%][Generator loss: 0.7365%]\n",
      "1882 [Discriminator loss: 0.7093%, acc.: 33.98%][Generator loss: 0.7275%]\n",
      "1883 [Discriminator loss: 0.7069%, acc.: 40.23%][Generator loss: 0.7307%]\n",
      "1884 [Discriminator loss: 0.7032%, acc.: 33.20%][Generator loss: 0.7283%]\n",
      "1885 [Discriminator loss: 0.7036%, acc.: 37.11%][Generator loss: 0.7351%]\n",
      "1886 [Discriminator loss: 0.7095%, acc.: 30.08%][Generator loss: 0.7281%]\n",
      "1887 [Discriminator loss: 0.7036%, acc.: 38.28%][Generator loss: 0.7312%]\n",
      "1888 [Discriminator loss: 0.7037%, acc.: 44.92%][Generator loss: 0.7649%]\n",
      "1889 [Discriminator loss: 0.7190%, acc.: 41.02%][Generator loss: 0.7421%]\n",
      "1890 [Discriminator loss: 0.7111%, acc.: 39.45%][Generator loss: 0.7363%]\n",
      "1891 [Discriminator loss: 0.7049%, acc.: 35.16%][Generator loss: 0.7282%]\n",
      "1892 [Discriminator loss: 0.7056%, acc.: 37.89%][Generator loss: 0.7480%]\n",
      "1893 [Discriminator loss: 0.7089%, acc.: 32.03%][Generator loss: 0.7475%]\n",
      "1894 [Discriminator loss: 0.7139%, acc.: 39.84%][Generator loss: 0.7375%]\n",
      "1895 [Discriminator loss: 0.7074%, acc.: 34.77%][Generator loss: 0.7255%]\n",
      "1896 [Discriminator loss: 0.7045%, acc.: 35.16%][Generator loss: 0.7269%]\n",
      "1897 [Discriminator loss: 0.7034%, acc.: 36.72%][Generator loss: 0.7303%]\n",
      "1898 [Discriminator loss: 0.7022%, acc.: 44.14%][Generator loss: 0.7258%]\n",
      "1899 [Discriminator loss: 0.7067%, acc.: 31.25%][Generator loss: 0.7657%]\n",
      "1900 [Discriminator loss: 0.7105%, acc.: 40.23%][Generator loss: 0.7641%]\n",
      "1901 [Discriminator loss: 0.7167%, acc.: 42.19%][Generator loss: 0.7384%]\n",
      "1902 [Discriminator loss: 0.7034%, acc.: 44.92%][Generator loss: 0.7286%]\n",
      "1903 [Discriminator loss: 0.7087%, acc.: 42.58%][Generator loss: 0.7317%]\n",
      "1904 [Discriminator loss: 0.7056%, acc.: 36.72%][Generator loss: 0.7222%]\n",
      "1905 [Discriminator loss: 0.7037%, acc.: 34.38%][Generator loss: 0.7266%]\n",
      "1906 [Discriminator loss: 0.7043%, acc.: 31.64%][Generator loss: 0.7305%]\n",
      "1907 [Discriminator loss: 0.7077%, acc.: 36.33%][Generator loss: 0.7257%]\n",
      "1908 [Discriminator loss: 0.7081%, acc.: 35.55%][Generator loss: 0.7256%]\n",
      "1909 [Discriminator loss: 0.7113%, acc.: 20.31%][Generator loss: 0.7251%]\n",
      "1910 [Discriminator loss: 0.7045%, acc.: 32.81%][Generator loss: 0.7286%]\n",
      "1911 [Discriminator loss: 0.7042%, acc.: 34.77%][Generator loss: 0.7242%]\n",
      "1912 [Discriminator loss: 0.7055%, acc.: 32.03%][Generator loss: 0.7234%]\n",
      "1913 [Discriminator loss: 0.7032%, acc.: 41.80%][Generator loss: 0.7234%]\n",
      "1914 [Discriminator loss: 0.7078%, acc.: 26.95%][Generator loss: 0.7782%]\n",
      "1915 [Discriminator loss: 0.7128%, acc.: 46.09%][Generator loss: 0.7786%]\n",
      "1916 [Discriminator loss: 0.7217%, acc.: 37.89%][Generator loss: 0.7531%]\n",
      "1917 [Discriminator loss: 0.7121%, acc.: 31.64%][Generator loss: 0.7393%]\n",
      "1918 [Discriminator loss: 0.7075%, acc.: 30.47%][Generator loss: 0.7319%]\n",
      "1919 [Discriminator loss: 0.7081%, acc.: 35.94%][Generator loss: 0.7259%]\n",
      "1920 [Discriminator loss: 0.7083%, acc.: 23.44%][Generator loss: 0.7284%]\n",
      "1921 [Discriminator loss: 0.7063%, acc.: 31.64%][Generator loss: 0.7274%]\n",
      "1922 [Discriminator loss: 0.7062%, acc.: 24.61%][Generator loss: 0.7263%]\n",
      "1923 [Discriminator loss: 0.7012%, acc.: 37.11%][Generator loss: 0.7238%]\n",
      "1924 [Discriminator loss: 0.7074%, acc.: 27.34%][Generator loss: 0.7312%]\n",
      "1925 [Discriminator loss: 0.7065%, acc.: 32.81%][Generator loss: 0.7289%]\n",
      "1926 [Discriminator loss: 0.7074%, acc.: 38.28%][Generator loss: 0.7221%]\n",
      "1927 [Discriminator loss: 0.7045%, acc.: 36.72%][Generator loss: 0.7272%]\n",
      "1928 [Discriminator loss: 0.7022%, acc.: 37.50%][Generator loss: 0.7267%]\n",
      "1929 [Discriminator loss: 0.7091%, acc.: 22.66%][Generator loss: 0.7264%]\n",
      "1930 [Discriminator loss: 0.7040%, acc.: 37.50%][Generator loss: 0.7269%]\n",
      "1931 [Discriminator loss: 0.7029%, acc.: 38.28%][Generator loss: 0.7291%]\n",
      "1932 [Discriminator loss: 0.7051%, acc.: 37.11%][Generator loss: 0.7324%]\n",
      "1933 [Discriminator loss: 0.7099%, acc.: 37.11%][Generator loss: 0.7306%]\n",
      "1934 [Discriminator loss: 0.7044%, acc.: 39.45%][Generator loss: 0.7285%]\n",
      "1935 [Discriminator loss: 0.7062%, acc.: 37.89%][Generator loss: 0.7320%]\n",
      "1936 [Discriminator loss: 0.7038%, acc.: 37.89%][Generator loss: 0.7400%]\n",
      "1937 [Discriminator loss: 0.7116%, acc.: 40.23%][Generator loss: 0.7295%]\n",
      "1938 [Discriminator loss: 0.7044%, acc.: 37.89%][Generator loss: 0.7369%]\n",
      "1939 [Discriminator loss: 0.7104%, acc.: 40.62%][Generator loss: 0.7404%]\n",
      "1940 [Discriminator loss: 0.7083%, acc.: 35.16%][Generator loss: 0.7296%]\n",
      "1941 [Discriminator loss: 0.7045%, acc.: 41.41%][Generator loss: 0.7368%]\n",
      "1942 [Discriminator loss: 0.7072%, acc.: 37.89%][Generator loss: 0.7348%]\n",
      "1943 [Discriminator loss: 0.7093%, acc.: 42.58%][Generator loss: 0.7276%]\n",
      "1944 [Discriminator loss: 0.7083%, acc.: 26.56%][Generator loss: 0.7290%]\n",
      "1945 [Discriminator loss: 0.7055%, acc.: 32.42%][Generator loss: 0.7258%]\n",
      "1946 [Discriminator loss: 0.7042%, acc.: 34.77%][Generator loss: 0.7253%]\n",
      "1947 [Discriminator loss: 0.7041%, acc.: 31.25%][Generator loss: 0.7385%]\n",
      "1948 [Discriminator loss: 0.6986%, acc.: 46.09%][Generator loss: 0.7669%]\n",
      "1949 [Discriminator loss: 0.7185%, acc.: 39.45%][Generator loss: 0.7421%]\n",
      "1950 [Discriminator loss: 0.7096%, acc.: 36.33%][Generator loss: 0.7329%]\n",
      "1951 [Discriminator loss: 0.7098%, acc.: 37.11%][Generator loss: 0.7270%]\n",
      "1952 [Discriminator loss: 0.7082%, acc.: 19.53%][Generator loss: 0.7316%]\n",
      "1953 [Discriminator loss: 0.7037%, acc.: 37.89%][Generator loss: 0.7287%]\n",
      "1954 [Discriminator loss: 0.7046%, acc.: 35.94%][Generator loss: 0.7300%]\n",
      "1955 [Discriminator loss: 0.7063%, acc.: 32.03%][Generator loss: 0.7255%]\n",
      "1956 [Discriminator loss: 0.7043%, acc.: 38.67%][Generator loss: 0.7306%]\n",
      "1957 [Discriminator loss: 0.7051%, acc.: 33.59%][Generator loss: 0.7306%]\n",
      "1958 [Discriminator loss: 0.7057%, acc.: 37.11%][Generator loss: 0.7444%]\n",
      "1959 [Discriminator loss: 0.7102%, acc.: 40.23%][Generator loss: 0.7282%]\n",
      "1960 [Discriminator loss: 0.7113%, acc.: 20.70%][Generator loss: 0.7265%]\n",
      "1961 [Discriminator loss: 0.7022%, acc.: 39.06%][Generator loss: 0.7291%]\n",
      "1962 [Discriminator loss: 0.7042%, acc.: 31.25%][Generator loss: 0.7305%]\n",
      "1963 [Discriminator loss: 0.7080%, acc.: 35.94%][Generator loss: 0.7282%]\n",
      "1964 [Discriminator loss: 0.7065%, acc.: 24.61%][Generator loss: 0.7307%]\n",
      "1965 [Discriminator loss: 0.7029%, acc.: 35.94%][Generator loss: 0.7473%]\n",
      "1966 [Discriminator loss: 0.7119%, acc.: 39.45%][Generator loss: 0.7308%]\n",
      "1967 [Discriminator loss: 0.7039%, acc.: 35.94%][Generator loss: 0.7382%]\n",
      "1968 [Discriminator loss: 0.7085%, acc.: 25.78%][Generator loss: 0.7282%]\n",
      "1969 [Discriminator loss: 0.7033%, acc.: 35.94%][Generator loss: 0.7303%]\n",
      "1970 [Discriminator loss: 0.7027%, acc.: 39.06%][Generator loss: 0.7375%]\n",
      "1971 [Discriminator loss: 0.7063%, acc.: 40.62%][Generator loss: 0.7555%]\n",
      "1972 [Discriminator loss: 0.7137%, acc.: 38.28%][Generator loss: 0.7336%]\n",
      "1973 [Discriminator loss: 0.7079%, acc.: 41.80%][Generator loss: 0.7340%]\n",
      "1974 [Discriminator loss: 0.7086%, acc.: 32.03%][Generator loss: 0.7311%]\n",
      "1975 [Discriminator loss: 0.7049%, acc.: 36.33%][Generator loss: 0.7269%]\n",
      "1976 [Discriminator loss: 0.7016%, acc.: 39.84%][Generator loss: 0.7337%]\n",
      "1977 [Discriminator loss: 0.7080%, acc.: 36.33%][Generator loss: 0.7353%]\n",
      "1978 [Discriminator loss: 0.7090%, acc.: 34.77%][Generator loss: 0.7369%]\n",
      "1979 [Discriminator loss: 0.7073%, acc.: 39.84%][Generator loss: 0.7345%]\n",
      "1980 [Discriminator loss: 0.7066%, acc.: 36.72%][Generator loss: 0.7495%]\n",
      "1981 [Discriminator loss: 0.7157%, acc.: 37.11%][Generator loss: 0.7346%]\n",
      "1982 [Discriminator loss: 0.7057%, acc.: 43.36%][Generator loss: 0.7318%]\n",
      "1983 [Discriminator loss: 0.7059%, acc.: 35.55%][Generator loss: 0.7327%]\n",
      "1984 [Discriminator loss: 0.7023%, acc.: 37.50%][Generator loss: 0.7282%]\n",
      "1985 [Discriminator loss: 0.7071%, acc.: 44.14%][Generator loss: 0.7425%]\n",
      "1986 [Discriminator loss: 0.7045%, acc.: 41.41%][Generator loss: 0.7440%]\n",
      "1987 [Discriminator loss: 0.7115%, acc.: 39.45%][Generator loss: 0.7323%]\n",
      "1988 [Discriminator loss: 0.7045%, acc.: 38.28%][Generator loss: 0.7309%]\n",
      "1989 [Discriminator loss: 0.7036%, acc.: 38.67%][Generator loss: 0.7325%]\n",
      "1990 [Discriminator loss: 0.7055%, acc.: 41.02%][Generator loss: 0.7290%]\n",
      "1991 [Discriminator loss: 0.7058%, acc.: 30.47%][Generator loss: 0.7313%]\n",
      "1992 [Discriminator loss: 0.7082%, acc.: 30.08%][Generator loss: 0.7515%]\n",
      "1993 [Discriminator loss: 0.7091%, acc.: 41.41%][Generator loss: 0.7619%]\n",
      "1994 [Discriminator loss: 0.7145%, acc.: 44.92%][Generator loss: 0.7409%]\n",
      "1995 [Discriminator loss: 0.7092%, acc.: 38.67%][Generator loss: 0.7331%]\n",
      "1996 [Discriminator loss: 0.7087%, acc.: 34.38%][Generator loss: 0.7292%]\n",
      "1997 [Discriminator loss: 0.7051%, acc.: 36.33%][Generator loss: 0.7316%]\n",
      "1998 [Discriminator loss: 0.7029%, acc.: 40.23%][Generator loss: 0.7294%]\n",
      "1999 [Discriminator loss: 0.7077%, acc.: 34.38%][Generator loss: 0.7270%]\n",
      "2000 [Discriminator loss: 0.7065%, acc.: 32.42%][Generator loss: 0.7331%]\n",
      "2001 [Discriminator loss: 0.7018%, acc.: 41.80%][Generator loss: 0.7382%]\n",
      "2002 [Discriminator loss: 0.7097%, acc.: 43.36%][Generator loss: 0.7272%]\n",
      "2003 [Discriminator loss: 0.7054%, acc.: 37.11%][Generator loss: 0.7270%]\n",
      "2004 [Discriminator loss: 0.7031%, acc.: 41.41%][Generator loss: 0.7335%]\n",
      "2005 [Discriminator loss: 0.7020%, acc.: 41.02%][Generator loss: 0.7390%]\n",
      "2006 [Discriminator loss: 0.7128%, acc.: 41.02%][Generator loss: 0.7315%]\n",
      "2007 [Discriminator loss: 0.7065%, acc.: 26.56%][Generator loss: 0.7310%]\n",
      "2008 [Discriminator loss: 0.7067%, acc.: 39.06%][Generator loss: 0.7270%]\n",
      "2009 [Discriminator loss: 0.7072%, acc.: 32.03%][Generator loss: 0.7265%]\n",
      "2010 [Discriminator loss: 0.7042%, acc.: 39.45%][Generator loss: 0.7321%]\n",
      "2011 [Discriminator loss: 0.7078%, acc.: 35.94%][Generator loss: 0.7398%]\n",
      "2012 [Discriminator loss: 0.7029%, acc.: 47.66%][Generator loss: 0.7556%]\n",
      "2013 [Discriminator loss: 0.7169%, acc.: 39.45%][Generator loss: 0.7376%]\n",
      "2014 [Discriminator loss: 0.7112%, acc.: 24.61%][Generator loss: 0.7312%]\n",
      "2015 [Discriminator loss: 0.7041%, acc.: 42.97%][Generator loss: 0.7290%]\n",
      "2016 [Discriminator loss: 0.7037%, acc.: 42.19%][Generator loss: 0.7307%]\n",
      "2017 [Discriminator loss: 0.7056%, acc.: 32.03%][Generator loss: 0.7302%]\n",
      "2018 [Discriminator loss: 0.7030%, acc.: 38.28%][Generator loss: 0.7298%]\n",
      "2019 [Discriminator loss: 0.7059%, acc.: 38.67%][Generator loss: 0.7281%]\n",
      "2020 [Discriminator loss: 0.7035%, acc.: 40.62%][Generator loss: 0.7333%]\n",
      "2021 [Discriminator loss: 0.7065%, acc.: 41.80%][Generator loss: 0.7283%]\n",
      "2022 [Discriminator loss: 0.7077%, acc.: 21.09%][Generator loss: 0.7299%]\n",
      "2023 [Discriminator loss: 0.7023%, acc.: 37.11%][Generator loss: 0.7385%]\n",
      "2024 [Discriminator loss: 0.7100%, acc.: 25.78%][Generator loss: 0.7295%]\n",
      "2025 [Discriminator loss: 0.7053%, acc.: 36.33%][Generator loss: 0.7252%]\n",
      "2026 [Discriminator loss: 0.7046%, acc.: 32.03%][Generator loss: 0.7449%]\n",
      "2027 [Discriminator loss: 0.7016%, acc.: 48.44%][Generator loss: 0.7627%]\n",
      "2028 [Discriminator loss: 0.7130%, acc.: 44.92%][Generator loss: 0.7440%]\n",
      "2029 [Discriminator loss: 0.7094%, acc.: 42.19%][Generator loss: 0.7373%]\n",
      "2030 [Discriminator loss: 0.7069%, acc.: 41.80%][Generator loss: 0.7313%]\n",
      "2031 [Discriminator loss: 0.7058%, acc.: 41.41%][Generator loss: 0.7270%]\n",
      "2032 [Discriminator loss: 0.7036%, acc.: 35.55%][Generator loss: 0.7282%]\n",
      "2033 [Discriminator loss: 0.7028%, acc.: 44.92%][Generator loss: 0.7275%]\n",
      "2034 [Discriminator loss: 0.7053%, acc.: 39.84%][Generator loss: 0.7286%]\n",
      "2035 [Discriminator loss: 0.7085%, acc.: 26.56%][Generator loss: 0.7288%]\n",
      "2036 [Discriminator loss: 0.7024%, acc.: 44.14%][Generator loss: 0.7341%]\n",
      "2037 [Discriminator loss: 0.7033%, acc.: 41.02%][Generator loss: 0.7432%]\n",
      "2038 [Discriminator loss: 0.7114%, acc.: 37.50%][Generator loss: 0.7299%]\n",
      "2039 [Discriminator loss: 0.7079%, acc.: 29.69%][Generator loss: 0.7335%]\n",
      "2040 [Discriminator loss: 0.7041%, acc.: 41.80%][Generator loss: 0.7296%]\n",
      "2041 [Discriminator loss: 0.7042%, acc.: 38.67%][Generator loss: 0.7316%]\n",
      "2042 [Discriminator loss: 0.7051%, acc.: 38.67%][Generator loss: 0.7314%]\n",
      "2043 [Discriminator loss: 0.7031%, acc.: 36.33%][Generator loss: 0.7288%]\n",
      "2044 [Discriminator loss: 0.7059%, acc.: 33.20%][Generator loss: 0.7326%]\n",
      "2045 [Discriminator loss: 0.7091%, acc.: 37.50%][Generator loss: 0.7282%]\n",
      "2046 [Discriminator loss: 0.7010%, acc.: 40.23%][Generator loss: 0.7293%]\n",
      "2047 [Discriminator loss: 0.7009%, acc.: 38.67%][Generator loss: 0.7382%]\n",
      "2048 [Discriminator loss: 0.7079%, acc.: 32.03%][Generator loss: 0.7394%]\n",
      "2049 [Discriminator loss: 0.7102%, acc.: 37.11%][Generator loss: 0.7319%]\n",
      "2050 [Discriminator loss: 0.7033%, acc.: 39.06%][Generator loss: 0.7282%]\n",
      "2051 [Discriminator loss: 0.7089%, acc.: 33.59%][Generator loss: 0.7389%]\n",
      "2052 [Discriminator loss: 0.7089%, acc.: 25.39%][Generator loss: 0.7473%]\n",
      "2053 [Discriminator loss: 0.7124%, acc.: 34.38%][Generator loss: 0.7321%]\n",
      "2054 [Discriminator loss: 0.7071%, acc.: 34.77%][Generator loss: 0.7303%]\n",
      "2055 [Discriminator loss: 0.7032%, acc.: 34.77%][Generator loss: 0.7303%]\n",
      "2056 [Discriminator loss: 0.7039%, acc.: 39.45%][Generator loss: 0.7279%]\n",
      "2057 [Discriminator loss: 0.7030%, acc.: 40.62%][Generator loss: 0.7295%]\n",
      "2058 [Discriminator loss: 0.7057%, acc.: 39.45%][Generator loss: 0.7299%]\n",
      "2059 [Discriminator loss: 0.7057%, acc.: 27.34%][Generator loss: 0.7287%]\n",
      "2060 [Discriminator loss: 0.7065%, acc.: 32.81%][Generator loss: 0.7322%]\n",
      "2061 [Discriminator loss: 0.7065%, acc.: 26.56%][Generator loss: 0.7346%]\n",
      "2062 [Discriminator loss: 0.7063%, acc.: 35.94%][Generator loss: 0.7263%]\n",
      "2063 [Discriminator loss: 0.7048%, acc.: 38.67%][Generator loss: 0.7299%]\n",
      "2064 [Discriminator loss: 0.7016%, acc.: 39.06%][Generator loss: 0.7339%]\n",
      "2065 [Discriminator loss: 0.7066%, acc.: 41.41%][Generator loss: 0.7273%]\n",
      "2066 [Discriminator loss: 0.7046%, acc.: 31.64%][Generator loss: 0.7288%]\n",
      "2067 [Discriminator loss: 0.7053%, acc.: 37.50%][Generator loss: 0.7271%]\n",
      "2068 [Discriminator loss: 0.7067%, acc.: 34.77%][Generator loss: 0.7259%]\n",
      "2069 [Discriminator loss: 0.7053%, acc.: 30.86%][Generator loss: 0.7322%]\n",
      "2070 [Discriminator loss: 0.7028%, acc.: 39.84%][Generator loss: 0.7445%]\n",
      "2071 [Discriminator loss: 0.7097%, acc.: 40.62%][Generator loss: 0.7297%]\n",
      "2072 [Discriminator loss: 0.7093%, acc.: 36.72%][Generator loss: 0.7261%]\n",
      "2073 [Discriminator loss: 0.7085%, acc.: 26.17%][Generator loss: 0.7277%]\n",
      "2074 [Discriminator loss: 0.7001%, acc.: 43.75%][Generator loss: 0.7256%]\n",
      "2075 [Discriminator loss: 0.7029%, acc.: 39.06%][Generator loss: 0.7619%]\n",
      "2076 [Discriminator loss: 0.7120%, acc.: 42.19%][Generator loss: 0.7665%]\n",
      "2077 [Discriminator loss: 0.7180%, acc.: 44.14%][Generator loss: 0.7445%]\n",
      "2078 [Discriminator loss: 0.7083%, acc.: 42.58%][Generator loss: 0.7347%]\n",
      "2079 [Discriminator loss: 0.7066%, acc.: 39.45%][Generator loss: 0.7307%]\n",
      "2080 [Discriminator loss: 0.7067%, acc.: 32.03%][Generator loss: 0.7324%]\n",
      "2081 [Discriminator loss: 0.7070%, acc.: 25.00%][Generator loss: 0.7322%]\n",
      "2082 [Discriminator loss: 0.7023%, acc.: 38.28%][Generator loss: 0.7287%]\n",
      "2083 [Discriminator loss: 0.7016%, acc.: 44.14%][Generator loss: 0.7271%]\n",
      "2084 [Discriminator loss: 0.7034%, acc.: 40.62%][Generator loss: 0.7338%]\n",
      "2085 [Discriminator loss: 0.7036%, acc.: 41.02%][Generator loss: 0.7281%]\n",
      "2086 [Discriminator loss: 0.7036%, acc.: 41.80%][Generator loss: 0.7286%]\n",
      "2087 [Discriminator loss: 0.7035%, acc.: 37.11%][Generator loss: 0.7304%]\n",
      "2088 [Discriminator loss: 0.7023%, acc.: 38.67%][Generator loss: 0.7406%]\n",
      "2089 [Discriminator loss: 0.7081%, acc.: 34.38%][Generator loss: 0.7431%]\n",
      "2090 [Discriminator loss: 0.7110%, acc.: 39.45%][Generator loss: 0.7292%]\n",
      "2091 [Discriminator loss: 0.7056%, acc.: 27.34%][Generator loss: 0.7262%]\n",
      "2092 [Discriminator loss: 0.7033%, acc.: 26.95%][Generator loss: 0.7432%]\n",
      "2093 [Discriminator loss: 0.7020%, acc.: 45.31%][Generator loss: 0.7527%]\n",
      "2094 [Discriminator loss: 0.7096%, acc.: 44.14%][Generator loss: 0.7420%]\n",
      "2095 [Discriminator loss: 0.7070%, acc.: 42.97%][Generator loss: 0.7299%]\n",
      "2096 [Discriminator loss: 0.7064%, acc.: 30.86%][Generator loss: 0.7300%]\n",
      "2097 [Discriminator loss: 0.7021%, acc.: 35.94%][Generator loss: 0.7334%]\n",
      "2098 [Discriminator loss: 0.7034%, acc.: 40.62%][Generator loss: 0.7261%]\n",
      "2099 [Discriminator loss: 0.7014%, acc.: 39.06%][Generator loss: 0.7330%]\n",
      "2100 [Discriminator loss: 0.7024%, acc.: 42.97%][Generator loss: 0.7364%]\n",
      "2101 [Discriminator loss: 0.7048%, acc.: 45.70%][Generator loss: 0.7314%]\n",
      "2102 [Discriminator loss: 0.7063%, acc.: 41.80%][Generator loss: 0.7364%]\n",
      "2103 [Discriminator loss: 0.7058%, acc.: 40.23%][Generator loss: 0.7366%]\n",
      "2104 [Discriminator loss: 0.7059%, acc.: 43.36%][Generator loss: 0.7268%]\n",
      "2105 [Discriminator loss: 0.7024%, acc.: 39.06%][Generator loss: 0.7296%]\n",
      "2106 [Discriminator loss: 0.7059%, acc.: 39.06%][Generator loss: 0.7278%]\n",
      "2107 [Discriminator loss: 0.7057%, acc.: 37.50%][Generator loss: 0.7326%]\n",
      "2108 [Discriminator loss: 0.7077%, acc.: 22.27%][Generator loss: 0.7259%]\n",
      "2109 [Discriminator loss: 0.6989%, acc.: 43.75%][Generator loss: 0.7879%]\n",
      "2110 [Discriminator loss: 0.7147%, acc.: 48.44%][Generator loss: 0.7723%]\n",
      "2111 [Discriminator loss: 0.7168%, acc.: 49.22%][Generator loss: 0.7500%]\n",
      "2112 [Discriminator loss: 0.7080%, acc.: 46.88%][Generator loss: 0.7415%]\n",
      "2113 [Discriminator loss: 0.7031%, acc.: 42.19%][Generator loss: 0.7370%]\n",
      "2114 [Discriminator loss: 0.7064%, acc.: 36.33%][Generator loss: 0.7312%]\n",
      "2115 [Discriminator loss: 0.7047%, acc.: 41.41%][Generator loss: 0.7288%]\n",
      "2116 [Discriminator loss: 0.7060%, acc.: 32.42%][Generator loss: 0.7253%]\n",
      "2117 [Discriminator loss: 0.7032%, acc.: 38.28%][Generator loss: 0.7267%]\n",
      "2118 [Discriminator loss: 0.7027%, acc.: 38.28%][Generator loss: 0.7272%]\n",
      "2119 [Discriminator loss: 0.7033%, acc.: 38.67%][Generator loss: 0.7275%]\n",
      "2120 [Discriminator loss: 0.7028%, acc.: 38.28%][Generator loss: 0.7318%]\n",
      "2121 [Discriminator loss: 0.7023%, acc.: 43.75%][Generator loss: 0.7326%]\n",
      "2122 [Discriminator loss: 0.7049%, acc.: 42.97%][Generator loss: 0.7262%]\n",
      "2123 [Discriminator loss: 0.7019%, acc.: 36.72%][Generator loss: 0.7314%]\n",
      "2124 [Discriminator loss: 0.7073%, acc.: 28.91%][Generator loss: 0.7268%]\n",
      "2125 [Discriminator loss: 0.7089%, acc.: 22.66%][Generator loss: 0.7278%]\n",
      "2126 [Discriminator loss: 0.7031%, acc.: 39.45%][Generator loss: 0.7315%]\n",
      "2127 [Discriminator loss: 0.7042%, acc.: 39.45%][Generator loss: 0.7258%]\n",
      "2128 [Discriminator loss: 0.7047%, acc.: 33.98%][Generator loss: 0.7423%]\n",
      "2129 [Discriminator loss: 0.7008%, acc.: 44.53%][Generator loss: 0.7499%]\n",
      "2130 [Discriminator loss: 0.7119%, acc.: 37.50%][Generator loss: 0.7372%]\n",
      "2131 [Discriminator loss: 0.7059%, acc.: 40.62%][Generator loss: 0.7302%]\n",
      "2132 [Discriminator loss: 0.7070%, acc.: 37.11%][Generator loss: 0.7264%]\n",
      "2133 [Discriminator loss: 0.7054%, acc.: 37.11%][Generator loss: 0.7228%]\n",
      "2134 [Discriminator loss: 0.7073%, acc.: 24.61%][Generator loss: 0.7280%]\n",
      "2135 [Discriminator loss: 0.7001%, acc.: 43.36%][Generator loss: 0.7336%]\n",
      "2136 [Discriminator loss: 0.7021%, acc.: 35.55%][Generator loss: 0.7327%]\n",
      "2137 [Discriminator loss: 0.7028%, acc.: 41.41%][Generator loss: 0.7270%]\n",
      "2138 [Discriminator loss: 0.7027%, acc.: 39.45%][Generator loss: 0.7271%]\n",
      "2139 [Discriminator loss: 0.7049%, acc.: 34.77%][Generator loss: 0.7321%]\n",
      "2140 [Discriminator loss: 0.7022%, acc.: 40.23%][Generator loss: 0.7363%]\n",
      "2141 [Discriminator loss: 0.7102%, acc.: 36.33%][Generator loss: 0.7263%]\n",
      "2142 [Discriminator loss: 0.7037%, acc.: 39.06%][Generator loss: 0.7249%]\n",
      "2143 [Discriminator loss: 0.7049%, acc.: 28.12%][Generator loss: 0.7275%]\n",
      "2144 [Discriminator loss: 0.7024%, acc.: 35.94%][Generator loss: 0.7289%]\n",
      "2145 [Discriminator loss: 0.7098%, acc.: 23.44%][Generator loss: 0.7252%]\n",
      "2146 [Discriminator loss: 0.7052%, acc.: 27.73%][Generator loss: 0.7463%]\n",
      "2147 [Discriminator loss: 0.7071%, acc.: 46.09%][Generator loss: 0.7543%]\n",
      "2148 [Discriminator loss: 0.7122%, acc.: 46.09%][Generator loss: 0.7402%]\n",
      "2149 [Discriminator loss: 0.7065%, acc.: 41.80%][Generator loss: 0.7314%]\n",
      "2150 [Discriminator loss: 0.7036%, acc.: 44.92%][Generator loss: 0.7300%]\n",
      "2151 [Discriminator loss: 0.7031%, acc.: 42.97%][Generator loss: 0.7306%]\n",
      "2152 [Discriminator loss: 0.7071%, acc.: 35.55%][Generator loss: 0.7311%]\n",
      "2153 [Discriminator loss: 0.7040%, acc.: 42.19%][Generator loss: 0.7376%]\n",
      "2154 [Discriminator loss: 0.7050%, acc.: 39.06%][Generator loss: 0.7390%]\n",
      "2155 [Discriminator loss: 0.7052%, acc.: 44.14%][Generator loss: 0.7288%]\n",
      "2156 [Discriminator loss: 0.7048%, acc.: 41.80%][Generator loss: 0.7266%]\n",
      "2157 [Discriminator loss: 0.7110%, acc.: 30.08%][Generator loss: 0.7294%]\n",
      "2158 [Discriminator loss: 0.7076%, acc.: 19.14%][Generator loss: 0.7323%]\n",
      "2159 [Discriminator loss: 0.7049%, acc.: 38.28%][Generator loss: 0.7271%]\n",
      "2160 [Discriminator loss: 0.7037%, acc.: 38.28%][Generator loss: 0.7294%]\n",
      "2161 [Discriminator loss: 0.7055%, acc.: 36.33%][Generator loss: 0.7253%]\n",
      "2162 [Discriminator loss: 0.7048%, acc.: 36.33%][Generator loss: 0.7241%]\n",
      "2163 [Discriminator loss: 0.7044%, acc.: 32.81%][Generator loss: 0.7262%]\n",
      "2164 [Discriminator loss: 0.7032%, acc.: 43.36%][Generator loss: 0.7270%]\n",
      "2165 [Discriminator loss: 0.7049%, acc.: 33.59%][Generator loss: 0.7250%]\n",
      "2166 [Discriminator loss: 0.7023%, acc.: 38.28%][Generator loss: 0.7281%]\n",
      "2167 [Discriminator loss: 0.7074%, acc.: 30.86%][Generator loss: 0.7366%]\n",
      "2168 [Discriminator loss: 0.6993%, acc.: 46.88%][Generator loss: 0.7337%]\n",
      "2169 [Discriminator loss: 0.7090%, acc.: 31.64%][Generator loss: 0.7266%]\n",
      "2170 [Discriminator loss: 0.7043%, acc.: 34.77%][Generator loss: 0.7270%]\n",
      "2171 [Discriminator loss: 0.7048%, acc.: 38.67%][Generator loss: 0.7352%]\n",
      "2172 [Discriminator loss: 0.7051%, acc.: 42.19%][Generator loss: 0.7486%]\n",
      "2173 [Discriminator loss: 0.7084%, acc.: 41.80%][Generator loss: 0.7360%]\n",
      "2174 [Discriminator loss: 0.7069%, acc.: 41.80%][Generator loss: 0.7304%]\n",
      "2175 [Discriminator loss: 0.7022%, acc.: 46.88%][Generator loss: 0.7309%]\n",
      "2176 [Discriminator loss: 0.7028%, acc.: 39.06%][Generator loss: 0.7310%]\n",
      "2177 [Discriminator loss: 0.7013%, acc.: 37.50%][Generator loss: 0.7494%]\n",
      "2178 [Discriminator loss: 0.7115%, acc.: 37.11%][Generator loss: 0.7500%]\n",
      "2179 [Discriminator loss: 0.7122%, acc.: 35.55%][Generator loss: 0.7352%]\n",
      "2180 [Discriminator loss: 0.7064%, acc.: 37.89%][Generator loss: 0.7324%]\n",
      "2181 [Discriminator loss: 0.7038%, acc.: 41.41%][Generator loss: 0.7306%]\n",
      "2182 [Discriminator loss: 0.7031%, acc.: 39.84%][Generator loss: 0.7294%]\n",
      "2183 [Discriminator loss: 0.7031%, acc.: 42.97%][Generator loss: 0.7275%]\n",
      "2184 [Discriminator loss: 0.7003%, acc.: 42.97%][Generator loss: 0.7316%]\n",
      "2185 [Discriminator loss: 0.7002%, acc.: 44.53%][Generator loss: 0.7310%]\n",
      "2186 [Discriminator loss: 0.7063%, acc.: 35.94%][Generator loss: 0.7282%]\n",
      "2187 [Discriminator loss: 0.7020%, acc.: 41.41%][Generator loss: 0.7303%]\n",
      "2188 [Discriminator loss: 0.7072%, acc.: 39.45%][Generator loss: 0.7306%]\n",
      "2189 [Discriminator loss: 0.7029%, acc.: 39.06%][Generator loss: 0.7318%]\n",
      "2190 [Discriminator loss: 0.7048%, acc.: 41.02%][Generator loss: 0.7296%]\n",
      "2191 [Discriminator loss: 0.7047%, acc.: 35.55%][Generator loss: 0.7317%]\n",
      "2192 [Discriminator loss: 0.7055%, acc.: 27.73%][Generator loss: 0.7256%]\n",
      "2193 [Discriminator loss: 0.7010%, acc.: 38.67%][Generator loss: 0.7271%]\n",
      "2194 [Discriminator loss: 0.7024%, acc.: 37.50%][Generator loss: 0.7303%]\n",
      "2195 [Discriminator loss: 0.7026%, acc.: 40.23%][Generator loss: 0.7270%]\n",
      "2196 [Discriminator loss: 0.7024%, acc.: 33.59%][Generator loss: 0.7271%]\n",
      "2197 [Discriminator loss: 0.7054%, acc.: 30.86%][Generator loss: 0.7278%]\n",
      "2198 [Discriminator loss: 0.7076%, acc.: 32.42%][Generator loss: 0.7219%]\n",
      "2199 [Discriminator loss: 0.7034%, acc.: 32.42%][Generator loss: 0.7317%]\n",
      "2200 [Discriminator loss: 0.7041%, acc.: 42.58%][Generator loss: 0.7386%]\n",
      "2201 [Discriminator loss: 0.7087%, acc.: 38.28%][Generator loss: 0.7309%]\n",
      "2202 [Discriminator loss: 0.7057%, acc.: 40.62%][Generator loss: 0.7245%]\n",
      "2203 [Discriminator loss: 0.7021%, acc.: 38.28%][Generator loss: 0.7308%]\n",
      "2204 [Discriminator loss: 0.7025%, acc.: 40.23%][Generator loss: 0.7310%]\n",
      "2205 [Discriminator loss: 0.7061%, acc.: 36.72%][Generator loss: 0.7258%]\n",
      "2206 [Discriminator loss: 0.7013%, acc.: 41.41%][Generator loss: 0.7240%]\n",
      "2207 [Discriminator loss: 0.7038%, acc.: 35.94%][Generator loss: 0.7392%]\n",
      "2208 [Discriminator loss: 0.7025%, acc.: 41.80%][Generator loss: 0.7430%]\n",
      "2209 [Discriminator loss: 0.7072%, acc.: 43.75%][Generator loss: 0.7303%]\n",
      "2210 [Discriminator loss: 0.7054%, acc.: 43.36%][Generator loss: 0.7275%]\n",
      "2211 [Discriminator loss: 0.7047%, acc.: 36.33%][Generator loss: 0.7267%]\n",
      "2212 [Discriminator loss: 0.7072%, acc.: 16.80%][Generator loss: 0.7270%]\n",
      "2213 [Discriminator loss: 0.7032%, acc.: 39.84%][Generator loss: 0.7272%]\n",
      "2214 [Discriminator loss: 0.7060%, acc.: 26.17%][Generator loss: 0.7263%]\n",
      "2215 [Discriminator loss: 0.7020%, acc.: 42.97%][Generator loss: 0.7373%]\n",
      "2216 [Discriminator loss: 0.7050%, acc.: 37.50%][Generator loss: 0.7292%]\n",
      "2217 [Discriminator loss: 0.7069%, acc.: 28.52%][Generator loss: 0.7278%]\n",
      "2218 [Discriminator loss: 0.7031%, acc.: 38.28%][Generator loss: 0.7303%]\n",
      "2219 [Discriminator loss: 0.7033%, acc.: 42.97%][Generator loss: 0.7300%]\n",
      "2220 [Discriminator loss: 0.7028%, acc.: 44.53%][Generator loss: 0.7311%]\n",
      "2221 [Discriminator loss: 0.7023%, acc.: 40.62%][Generator loss: 0.7339%]\n",
      "2222 [Discriminator loss: 0.7045%, acc.: 39.84%][Generator loss: 0.7315%]\n",
      "2223 [Discriminator loss: 0.7058%, acc.: 40.23%][Generator loss: 0.7253%]\n",
      "2224 [Discriminator loss: 0.7011%, acc.: 33.59%][Generator loss: 0.7325%]\n",
      "2225 [Discriminator loss: 0.7093%, acc.: 30.47%][Generator loss: 0.7279%]\n",
      "2226 [Discriminator loss: 0.7040%, acc.: 37.89%][Generator loss: 0.7269%]\n",
      "2227 [Discriminator loss: 0.7021%, acc.: 42.58%][Generator loss: 0.7308%]\n",
      "2228 [Discriminator loss: 0.7074%, acc.: 32.03%][Generator loss: 0.7314%]\n",
      "2229 [Discriminator loss: 0.7085%, acc.: 27.73%][Generator loss: 0.7387%]\n",
      "2230 [Discriminator loss: 0.7075%, acc.: 40.62%][Generator loss: 0.7280%]\n",
      "2231 [Discriminator loss: 0.7072%, acc.: 30.08%][Generator loss: 0.7285%]\n",
      "2232 [Discriminator loss: 0.7009%, acc.: 42.19%][Generator loss: 0.7271%]\n",
      "2233 [Discriminator loss: 0.7011%, acc.: 46.48%][Generator loss: 0.7279%]\n",
      "2234 [Discriminator loss: 0.6996%, acc.: 46.09%][Generator loss: 0.7296%]\n",
      "2235 [Discriminator loss: 0.7064%, acc.: 37.50%][Generator loss: 0.7302%]\n",
      "2236 [Discriminator loss: 0.7089%, acc.: 20.70%][Generator loss: 0.7274%]\n",
      "2237 [Discriminator loss: 0.7027%, acc.: 42.19%][Generator loss: 0.7318%]\n",
      "2238 [Discriminator loss: 0.7015%, acc.: 42.97%][Generator loss: 0.7369%]\n",
      "2239 [Discriminator loss: 0.7099%, acc.: 40.23%][Generator loss: 0.7292%]\n",
      "2240 [Discriminator loss: 0.7056%, acc.: 35.16%][Generator loss: 0.7259%]\n",
      "2241 [Discriminator loss: 0.7012%, acc.: 42.19%][Generator loss: 0.7257%]\n",
      "2242 [Discriminator loss: 0.7041%, acc.: 35.94%][Generator loss: 0.7273%]\n",
      "2243 [Discriminator loss: 0.7057%, acc.: 28.12%][Generator loss: 0.7243%]\n",
      "2244 [Discriminator loss: 0.7037%, acc.: 39.84%][Generator loss: 0.7272%]\n",
      "2245 [Discriminator loss: 0.7040%, acc.: 32.81%][Generator loss: 0.7277%]\n",
      "2246 [Discriminator loss: 0.7029%, acc.: 38.67%][Generator loss: 0.7321%]\n",
      "2247 [Discriminator loss: 0.7035%, acc.: 40.23%][Generator loss: 0.7297%]\n",
      "2248 [Discriminator loss: 0.7046%, acc.: 38.67%][Generator loss: 0.7235%]\n",
      "2249 [Discriminator loss: 0.7021%, acc.: 36.72%][Generator loss: 0.7374%]\n",
      "2250 [Discriminator loss: 0.7012%, acc.: 43.75%][Generator loss: 0.7552%]\n",
      "2251 [Discriminator loss: 0.7136%, acc.: 40.62%][Generator loss: 0.7358%]\n",
      "2252 [Discriminator loss: 0.7097%, acc.: 30.47%][Generator loss: 0.7306%]\n",
      "2253 [Discriminator loss: 0.7037%, acc.: 41.02%][Generator loss: 0.7287%]\n",
      "2254 [Discriminator loss: 0.7026%, acc.: 40.62%][Generator loss: 0.7287%]\n",
      "2255 [Discriminator loss: 0.7041%, acc.: 34.77%][Generator loss: 0.7284%]\n",
      "2256 [Discriminator loss: 0.7034%, acc.: 41.80%][Generator loss: 0.7259%]\n",
      "2257 [Discriminator loss: 0.7035%, acc.: 41.41%][Generator loss: 0.7351%]\n",
      "2258 [Discriminator loss: 0.7049%, acc.: 37.50%][Generator loss: 0.7334%]\n",
      "2259 [Discriminator loss: 0.7046%, acc.: 39.45%][Generator loss: 0.7262%]\n",
      "2260 [Discriminator loss: 0.7077%, acc.: 35.94%][Generator loss: 0.7230%]\n",
      "2261 [Discriminator loss: 0.7024%, acc.: 36.33%][Generator loss: 0.7285%]\n",
      "2262 [Discriminator loss: 0.7036%, acc.: 30.47%][Generator loss: 0.7285%]\n",
      "2263 [Discriminator loss: 0.7004%, acc.: 46.88%][Generator loss: 0.7268%]\n",
      "2264 [Discriminator loss: 0.7065%, acc.: 34.77%][Generator loss: 0.7264%]\n",
      "2265 [Discriminator loss: 0.7023%, acc.: 34.38%][Generator loss: 0.7276%]\n",
      "2266 [Discriminator loss: 0.7029%, acc.: 35.55%][Generator loss: 0.7271%]\n",
      "2267 [Discriminator loss: 0.7020%, acc.: 44.92%][Generator loss: 0.7275%]\n",
      "2268 [Discriminator loss: 0.7002%, acc.: 44.14%][Generator loss: 0.7326%]\n",
      "2269 [Discriminator loss: 0.7051%, acc.: 39.06%][Generator loss: 0.7255%]\n",
      "2270 [Discriminator loss: 0.7016%, acc.: 40.62%][Generator loss: 0.7246%]\n",
      "2271 [Discriminator loss: 0.7035%, acc.: 34.77%][Generator loss: 0.7386%]\n",
      "2272 [Discriminator loss: 0.7052%, acc.: 39.84%][Generator loss: 0.7470%]\n",
      "2273 [Discriminator loss: 0.7104%, acc.: 39.45%][Generator loss: 0.7336%]\n",
      "2274 [Discriminator loss: 0.7042%, acc.: 44.53%][Generator loss: 0.7286%]\n",
      "2275 [Discriminator loss: 0.7047%, acc.: 28.52%][Generator loss: 0.7279%]\n",
      "2276 [Discriminator loss: 0.7060%, acc.: 30.47%][Generator loss: 0.7236%]\n",
      "2277 [Discriminator loss: 0.7051%, acc.: 30.47%][Generator loss: 0.7265%]\n",
      "2278 [Discriminator loss: 0.7003%, acc.: 46.88%][Generator loss: 0.7277%]\n",
      "2279 [Discriminator loss: 0.7032%, acc.: 42.19%][Generator loss: 0.7260%]\n",
      "2280 [Discriminator loss: 0.7057%, acc.: 36.72%][Generator loss: 0.7286%]\n",
      "2281 [Discriminator loss: 0.7032%, acc.: 39.84%][Generator loss: 0.7336%]\n",
      "2282 [Discriminator loss: 0.7049%, acc.: 39.06%][Generator loss: 0.7280%]\n",
      "2283 [Discriminator loss: 0.7066%, acc.: 23.83%][Generator loss: 0.7274%]\n",
      "2284 [Discriminator loss: 0.6992%, acc.: 44.53%][Generator loss: 0.7311%]\n",
      "2285 [Discriminator loss: 0.7058%, acc.: 32.03%][Generator loss: 0.7288%]\n",
      "2286 [Discriminator loss: 0.7028%, acc.: 39.45%][Generator loss: 0.7295%]\n",
      "2287 [Discriminator loss: 0.7008%, acc.: 44.92%][Generator loss: 0.7364%]\n",
      "2288 [Discriminator loss: 0.7041%, acc.: 46.48%][Generator loss: 0.7265%]\n",
      "2289 [Discriminator loss: 0.7041%, acc.: 38.67%][Generator loss: 0.7337%]\n",
      "2290 [Discriminator loss: 0.7035%, acc.: 42.19%][Generator loss: 0.7313%]\n",
      "2291 [Discriminator loss: 0.7053%, acc.: 37.11%][Generator loss: 0.7272%]\n",
      "2292 [Discriminator loss: 0.7049%, acc.: 39.84%][Generator loss: 0.7266%]\n",
      "2293 [Discriminator loss: 0.7049%, acc.: 29.69%][Generator loss: 0.7268%]\n",
      "2294 [Discriminator loss: 0.7025%, acc.: 41.02%][Generator loss: 0.7261%]\n",
      "2295 [Discriminator loss: 0.7046%, acc.: 35.16%][Generator loss: 0.7405%]\n",
      "2296 [Discriminator loss: 0.7034%, acc.: 47.27%][Generator loss: 0.7487%]\n",
      "2297 [Discriminator loss: 0.7119%, acc.: 40.23%][Generator loss: 0.7395%]\n",
      "2298 [Discriminator loss: 0.7062%, acc.: 44.14%][Generator loss: 0.7323%]\n",
      "2299 [Discriminator loss: 0.7046%, acc.: 45.70%][Generator loss: 0.7285%]\n",
      "2300 [Discriminator loss: 0.7009%, acc.: 43.36%][Generator loss: 0.7291%]\n",
      "2301 [Discriminator loss: 0.7021%, acc.: 37.89%][Generator loss: 0.7287%]\n",
      "2302 [Discriminator loss: 0.7009%, acc.: 41.02%][Generator loss: 0.7319%]\n",
      "2303 [Discriminator loss: 0.7047%, acc.: 41.80%][Generator loss: 0.7313%]\n",
      "2304 [Discriminator loss: 0.7034%, acc.: 42.19%][Generator loss: 0.7334%]\n",
      "2305 [Discriminator loss: 0.7044%, acc.: 36.72%][Generator loss: 0.7307%]\n",
      "2306 [Discriminator loss: 0.7026%, acc.: 37.89%][Generator loss: 0.7282%]\n",
      "2307 [Discriminator loss: 0.7028%, acc.: 41.80%][Generator loss: 0.7296%]\n",
      "2308 [Discriminator loss: 0.7043%, acc.: 45.70%][Generator loss: 0.7304%]\n",
      "2309 [Discriminator loss: 0.7005%, acc.: 44.14%][Generator loss: 0.7370%]\n",
      "2310 [Discriminator loss: 0.7060%, acc.: 47.27%][Generator loss: 0.7294%]\n",
      "2311 [Discriminator loss: 0.7020%, acc.: 44.14%][Generator loss: 0.7398%]\n",
      "2312 [Discriminator loss: 0.7023%, acc.: 45.70%][Generator loss: 0.7511%]\n",
      "2313 [Discriminator loss: 0.7096%, acc.: 46.09%][Generator loss: 0.7353%]\n",
      "2314 [Discriminator loss: 0.7030%, acc.: 46.88%][Generator loss: 0.7340%]\n",
      "2315 [Discriminator loss: 0.7042%, acc.: 46.09%][Generator loss: 0.7300%]\n",
      "2316 [Discriminator loss: 0.7020%, acc.: 44.53%][Generator loss: 0.7273%]\n",
      "2317 [Discriminator loss: 0.7045%, acc.: 33.20%][Generator loss: 0.7287%]\n",
      "2318 [Discriminator loss: 0.7033%, acc.: 41.41%][Generator loss: 0.7310%]\n",
      "2319 [Discriminator loss: 0.7025%, acc.: 42.58%][Generator loss: 0.7306%]\n",
      "2320 [Discriminator loss: 0.7034%, acc.: 35.16%][Generator loss: 0.7307%]\n",
      "2321 [Discriminator loss: 0.7053%, acc.: 36.72%][Generator loss: 0.7326%]\n",
      "2322 [Discriminator loss: 0.7101%, acc.: 26.17%][Generator loss: 0.7285%]\n",
      "2323 [Discriminator loss: 0.7034%, acc.: 37.50%][Generator loss: 0.7272%]\n",
      "2324 [Discriminator loss: 0.7019%, acc.: 39.06%][Generator loss: 0.7279%]\n",
      "2325 [Discriminator loss: 0.6999%, acc.: 45.70%][Generator loss: 0.7286%]\n",
      "2326 [Discriminator loss: 0.7036%, acc.: 39.45%][Generator loss: 0.7253%]\n",
      "2327 [Discriminator loss: 0.7015%, acc.: 41.41%][Generator loss: 0.7292%]\n",
      "2328 [Discriminator loss: 0.7020%, acc.: 44.14%][Generator loss: 0.7349%]\n",
      "2329 [Discriminator loss: 0.7072%, acc.: 37.50%][Generator loss: 0.7299%]\n",
      "2330 [Discriminator loss: 0.7052%, acc.: 29.30%][Generator loss: 0.7290%]\n",
      "2331 [Discriminator loss: 0.7034%, acc.: 39.06%][Generator loss: 0.7281%]\n",
      "2332 [Discriminator loss: 0.7024%, acc.: 40.23%][Generator loss: 0.7307%]\n",
      "2333 [Discriminator loss: 0.7017%, acc.: 43.36%][Generator loss: 0.7346%]\n",
      "2334 [Discriminator loss: 0.7020%, acc.: 44.14%][Generator loss: 0.7391%]\n",
      "2335 [Discriminator loss: 0.7098%, acc.: 35.16%][Generator loss: 0.7304%]\n",
      "2336 [Discriminator loss: 0.7040%, acc.: 34.77%][Generator loss: 0.7277%]\n",
      "2337 [Discriminator loss: 0.7016%, acc.: 37.89%][Generator loss: 0.7386%]\n",
      "2338 [Discriminator loss: 0.7039%, acc.: 48.05%][Generator loss: 0.7361%]\n",
      "2339 [Discriminator loss: 0.7030%, acc.: 44.53%][Generator loss: 0.7276%]\n",
      "2340 [Discriminator loss: 0.7041%, acc.: 43.36%][Generator loss: 0.7324%]\n",
      "2341 [Discriminator loss: 0.7021%, acc.: 43.75%][Generator loss: 0.7269%]\n",
      "2342 [Discriminator loss: 0.7052%, acc.: 39.84%][Generator loss: 0.7285%]\n",
      "2343 [Discriminator loss: 0.7045%, acc.: 39.06%][Generator loss: 0.7310%]\n",
      "2344 [Discriminator loss: 0.7011%, acc.: 44.14%][Generator loss: 0.7284%]\n",
      "2345 [Discriminator loss: 0.7003%, acc.: 40.62%][Generator loss: 0.7330%]\n",
      "2346 [Discriminator loss: 0.7017%, acc.: 43.36%][Generator loss: 0.7390%]\n",
      "2347 [Discriminator loss: 0.7074%, acc.: 38.28%][Generator loss: 0.7307%]\n",
      "2348 [Discriminator loss: 0.7038%, acc.: 40.23%][Generator loss: 0.7255%]\n",
      "2349 [Discriminator loss: 0.7020%, acc.: 45.31%][Generator loss: 0.7305%]\n",
      "2350 [Discriminator loss: 0.7013%, acc.: 41.41%][Generator loss: 0.7291%]\n",
      "2351 [Discriminator loss: 0.7019%, acc.: 41.80%][Generator loss: 0.7270%]\n",
      "2352 [Discriminator loss: 0.7044%, acc.: 40.23%][Generator loss: 0.7303%]\n",
      "2353 [Discriminator loss: 0.7038%, acc.: 39.45%][Generator loss: 0.7265%]\n",
      "2354 [Discriminator loss: 0.7055%, acc.: 32.42%][Generator loss: 0.7292%]\n",
      "2355 [Discriminator loss: 0.7036%, acc.: 45.70%][Generator loss: 0.7320%]\n",
      "2356 [Discriminator loss: 0.7028%, acc.: 45.31%][Generator loss: 0.7300%]\n",
      "2357 [Discriminator loss: 0.7047%, acc.: 43.36%][Generator loss: 0.7335%]\n",
      "2358 [Discriminator loss: 0.7016%, acc.: 47.66%][Generator loss: 0.7386%]\n",
      "2359 [Discriminator loss: 0.7072%, acc.: 42.19%][Generator loss: 0.7285%]\n",
      "2360 [Discriminator loss: 0.7047%, acc.: 36.33%][Generator loss: 0.7276%]\n",
      "2361 [Discriminator loss: 0.6992%, acc.: 44.92%][Generator loss: 0.7280%]\n",
      "2362 [Discriminator loss: 0.7015%, acc.: 44.14%][Generator loss: 0.7279%]\n",
      "2363 [Discriminator loss: 0.7008%, acc.: 41.80%][Generator loss: 0.7342%]\n",
      "2364 [Discriminator loss: 0.7063%, acc.: 47.27%][Generator loss: 0.7350%]\n",
      "2365 [Discriminator loss: 0.7054%, acc.: 33.98%][Generator loss: 0.7272%]\n",
      "2366 [Discriminator loss: 0.7011%, acc.: 41.80%][Generator loss: 0.7263%]\n",
      "2367 [Discriminator loss: 0.7031%, acc.: 43.36%][Generator loss: 0.7268%]\n",
      "2368 [Discriminator loss: 0.7025%, acc.: 41.41%][Generator loss: 0.7461%]\n",
      "2369 [Discriminator loss: 0.7060%, acc.: 45.70%][Generator loss: 0.7496%]\n",
      "2370 [Discriminator loss: 0.7083%, acc.: 45.31%][Generator loss: 0.7374%]\n",
      "2371 [Discriminator loss: 0.7047%, acc.: 42.19%][Generator loss: 0.7336%]\n",
      "2372 [Discriminator loss: 0.7040%, acc.: 44.53%][Generator loss: 0.7283%]\n",
      "2373 [Discriminator loss: 0.7013%, acc.: 46.09%][Generator loss: 0.7310%]\n",
      "2374 [Discriminator loss: 0.7034%, acc.: 36.33%][Generator loss: 0.7283%]\n",
      "2375 [Discriminator loss: 0.7017%, acc.: 40.23%][Generator loss: 0.7258%]\n",
      "2376 [Discriminator loss: 0.7014%, acc.: 41.02%][Generator loss: 0.7328%]\n",
      "2377 [Discriminator loss: 0.7022%, acc.: 44.14%][Generator loss: 0.7318%]\n",
      "2378 [Discriminator loss: 0.7039%, acc.: 42.97%][Generator loss: 0.7319%]\n",
      "2379 [Discriminator loss: 0.7040%, acc.: 42.19%][Generator loss: 0.7381%]\n",
      "2380 [Discriminator loss: 0.7066%, acc.: 40.62%][Generator loss: 0.7301%]\n",
      "2381 [Discriminator loss: 0.7048%, acc.: 37.11%][Generator loss: 0.7292%]\n",
      "2382 [Discriminator loss: 0.7013%, acc.: 39.45%][Generator loss: 0.7271%]\n",
      "2383 [Discriminator loss: 0.6995%, acc.: 44.14%][Generator loss: 0.7296%]\n",
      "2384 [Discriminator loss: 0.6999%, acc.: 46.09%][Generator loss: 0.7314%]\n",
      "2385 [Discriminator loss: 0.7033%, acc.: 41.41%][Generator loss: 0.7304%]\n",
      "2386 [Discriminator loss: 0.7057%, acc.: 33.98%][Generator loss: 0.7327%]\n",
      "2387 [Discriminator loss: 0.7064%, acc.: 37.50%][Generator loss: 0.7299%]\n",
      "2388 [Discriminator loss: 0.7053%, acc.: 36.72%][Generator loss: 0.7270%]\n",
      "2389 [Discriminator loss: 0.6995%, acc.: 43.75%][Generator loss: 0.7268%]\n",
      "2390 [Discriminator loss: 0.7006%, acc.: 46.09%][Generator loss: 0.7355%]\n",
      "2391 [Discriminator loss: 0.6998%, acc.: 48.05%][Generator loss: 0.7420%]\n",
      "2392 [Discriminator loss: 0.7066%, acc.: 47.66%][Generator loss: 0.7317%]\n",
      "2393 [Discriminator loss: 0.7054%, acc.: 41.80%][Generator loss: 0.7303%]\n",
      "2394 [Discriminator loss: 0.7034%, acc.: 40.62%][Generator loss: 0.7271%]\n",
      "2395 [Discriminator loss: 0.7025%, acc.: 41.41%][Generator loss: 0.7336%]\n",
      "2396 [Discriminator loss: 0.7012%, acc.: 43.36%][Generator loss: 0.7334%]\n",
      "2397 [Discriminator loss: 0.7071%, acc.: 32.81%][Generator loss: 0.7303%]\n",
      "2398 [Discriminator loss: 0.7042%, acc.: 38.67%][Generator loss: 0.7273%]\n",
      "2399 [Discriminator loss: 0.7007%, acc.: 48.05%][Generator loss: 0.7274%]\n",
      "2400 [Discriminator loss: 0.6999%, acc.: 46.48%][Generator loss: 0.7332%]\n",
      "2401 [Discriminator loss: 0.7044%, acc.: 35.94%][Generator loss: 0.7271%]\n",
      "2402 [Discriminator loss: 0.7054%, acc.: 33.59%][Generator loss: 0.7285%]\n",
      "2403 [Discriminator loss: 0.7019%, acc.: 44.53%][Generator loss: 0.7370%]\n",
      "2404 [Discriminator loss: 0.7053%, acc.: 46.09%][Generator loss: 0.7272%]\n",
      "2405 [Discriminator loss: 0.7023%, acc.: 40.62%][Generator loss: 0.7330%]\n",
      "2406 [Discriminator loss: 0.7018%, acc.: 43.36%][Generator loss: 0.7315%]\n",
      "2407 [Discriminator loss: 0.7038%, acc.: 36.72%][Generator loss: 0.7274%]\n",
      "2408 [Discriminator loss: 0.7038%, acc.: 40.23%][Generator loss: 0.7284%]\n",
      "2409 [Discriminator loss: 0.7021%, acc.: 43.75%][Generator loss: 0.7274%]\n",
      "2410 [Discriminator loss: 0.7018%, acc.: 41.02%][Generator loss: 0.7260%]\n",
      "2411 [Discriminator loss: 0.7019%, acc.: 42.97%][Generator loss: 0.7274%]\n",
      "2412 [Discriminator loss: 0.7042%, acc.: 39.06%][Generator loss: 0.7293%]\n",
      "2413 [Discriminator loss: 0.7007%, acc.: 41.80%][Generator loss: 0.7301%]\n",
      "2414 [Discriminator loss: 0.7058%, acc.: 39.45%][Generator loss: 0.7249%]\n",
      "2415 [Discriminator loss: 0.7030%, acc.: 39.06%][Generator loss: 0.7252%]\n",
      "2416 [Discriminator loss: 0.7048%, acc.: 35.94%][Generator loss: 0.7275%]\n",
      "2417 [Discriminator loss: 0.7031%, acc.: 34.77%][Generator loss: 0.7331%]\n",
      "2418 [Discriminator loss: 0.7024%, acc.: 44.92%][Generator loss: 0.7353%]\n",
      "2419 [Discriminator loss: 0.7057%, acc.: 42.19%][Generator loss: 0.7303%]\n",
      "2420 [Discriminator loss: 0.7041%, acc.: 38.28%][Generator loss: 0.7281%]\n",
      "2421 [Discriminator loss: 0.7010%, acc.: 45.70%][Generator loss: 0.7302%]\n",
      "2422 [Discriminator loss: 0.7017%, acc.: 40.23%][Generator loss: 0.7321%]\n",
      "2423 [Discriminator loss: 0.7040%, acc.: 40.62%][Generator loss: 0.7263%]\n",
      "2424 [Discriminator loss: 0.7022%, acc.: 48.05%][Generator loss: 0.7324%]\n",
      "2425 [Discriminator loss: 0.7016%, acc.: 41.02%][Generator loss: 0.7328%]\n",
      "2426 [Discriminator loss: 0.7030%, acc.: 48.83%][Generator loss: 0.7261%]\n",
      "2427 [Discriminator loss: 0.7026%, acc.: 37.11%][Generator loss: 0.7295%]\n",
      "2428 [Discriminator loss: 0.7066%, acc.: 35.16%][Generator loss: 0.7358%]\n",
      "2429 [Discriminator loss: 0.7055%, acc.: 41.80%][Generator loss: 0.7312%]\n",
      "2430 [Discriminator loss: 0.7023%, acc.: 43.36%][Generator loss: 0.7294%]\n",
      "2431 [Discriminator loss: 0.7034%, acc.: 42.19%][Generator loss: 0.7287%]\n",
      "2432 [Discriminator loss: 0.7045%, acc.: 37.50%][Generator loss: 0.7300%]\n",
      "2433 [Discriminator loss: 0.7013%, acc.: 41.02%][Generator loss: 0.7285%]\n",
      "2434 [Discriminator loss: 0.7003%, acc.: 46.09%][Generator loss: 0.7292%]\n",
      "2435 [Discriminator loss: 0.7007%, acc.: 46.88%][Generator loss: 0.7321%]\n",
      "2436 [Discriminator loss: 0.7021%, acc.: 42.19%][Generator loss: 0.7279%]\n",
      "2437 [Discriminator loss: 0.7027%, acc.: 44.14%][Generator loss: 0.7289%]\n",
      "2438 [Discriminator loss: 0.7015%, acc.: 39.06%][Generator loss: 0.7314%]\n",
      "2439 [Discriminator loss: 0.7037%, acc.: 44.53%][Generator loss: 0.7275%]\n",
      "2440 [Discriminator loss: 0.7007%, acc.: 42.97%][Generator loss: 0.7276%]\n",
      "2441 [Discriminator loss: 0.7014%, acc.: 42.97%][Generator loss: 0.7288%]\n",
      "2442 [Discriminator loss: 0.7007%, acc.: 40.23%][Generator loss: 0.7353%]\n",
      "2443 [Discriminator loss: 0.7041%, acc.: 40.23%][Generator loss: 0.7297%]\n",
      "2444 [Discriminator loss: 0.7046%, acc.: 35.55%][Generator loss: 0.7269%]\n",
      "2445 [Discriminator loss: 0.7013%, acc.: 43.75%][Generator loss: 0.7304%]\n",
      "2446 [Discriminator loss: 0.7022%, acc.: 44.14%][Generator loss: 0.7287%]\n",
      "2447 [Discriminator loss: 0.7011%, acc.: 45.31%][Generator loss: 0.7328%]\n",
      "2448 [Discriminator loss: 0.7044%, acc.: 41.41%][Generator loss: 0.7269%]\n",
      "2449 [Discriminator loss: 0.7018%, acc.: 41.41%][Generator loss: 0.7306%]\n",
      "2450 [Discriminator loss: 0.7021%, acc.: 40.62%][Generator loss: 0.7346%]\n",
      "2451 [Discriminator loss: 0.7059%, acc.: 39.84%][Generator loss: 0.7263%]\n",
      "2452 [Discriminator loss: 0.7026%, acc.: 38.28%][Generator loss: 0.7293%]\n",
      "2453 [Discriminator loss: 0.7026%, acc.: 43.75%][Generator loss: 0.7251%]\n",
      "2454 [Discriminator loss: 0.7017%, acc.: 40.23%][Generator loss: 0.7277%]\n",
      "2455 [Discriminator loss: 0.7028%, acc.: 36.33%][Generator loss: 0.7257%]\n",
      "2456 [Discriminator loss: 0.7042%, acc.: 40.23%][Generator loss: 0.7326%]\n",
      "2457 [Discriminator loss: 0.7008%, acc.: 42.58%][Generator loss: 0.7387%]\n",
      "2458 [Discriminator loss: 0.7066%, acc.: 44.14%][Generator loss: 0.7293%]\n",
      "2459 [Discriminator loss: 0.7027%, acc.: 40.62%][Generator loss: 0.7298%]\n",
      "2460 [Discriminator loss: 0.7037%, acc.: 42.58%][Generator loss: 0.7256%]\n",
      "2461 [Discriminator loss: 0.7010%, acc.: 44.92%][Generator loss: 0.7395%]\n",
      "2462 [Discriminator loss: 0.7043%, acc.: 42.19%][Generator loss: 0.7391%]\n",
      "2463 [Discriminator loss: 0.7053%, acc.: 46.48%][Generator loss: 0.7309%]\n",
      "2464 [Discriminator loss: 0.7020%, acc.: 44.53%][Generator loss: 0.7286%]\n",
      "2465 [Discriminator loss: 0.7003%, acc.: 45.31%][Generator loss: 0.7310%]\n",
      "2466 [Discriminator loss: 0.7045%, acc.: 42.58%][Generator loss: 0.7271%]\n",
      "2467 [Discriminator loss: 0.7018%, acc.: 47.27%][Generator loss: 0.7299%]\n",
      "2468 [Discriminator loss: 0.7032%, acc.: 42.97%][Generator loss: 0.7311%]\n",
      "2469 [Discriminator loss: 0.7029%, acc.: 43.75%][Generator loss: 0.7291%]\n",
      "2470 [Discriminator loss: 0.7018%, acc.: 42.19%][Generator loss: 0.7270%]\n",
      "2471 [Discriminator loss: 0.7011%, acc.: 44.14%][Generator loss: 0.7268%]\n",
      "2472 [Discriminator loss: 0.7009%, acc.: 44.92%][Generator loss: 0.7351%]\n",
      "2473 [Discriminator loss: 0.7013%, acc.: 41.02%][Generator loss: 0.7361%]\n",
      "2474 [Discriminator loss: 0.7070%, acc.: 37.50%][Generator loss: 0.7306%]\n",
      "2475 [Discriminator loss: 0.7012%, acc.: 45.70%][Generator loss: 0.7289%]\n",
      "2476 [Discriminator loss: 0.7034%, acc.: 39.45%][Generator loss: 0.7302%]\n",
      "2477 [Discriminator loss: 0.7036%, acc.: 45.31%][Generator loss: 0.7325%]\n",
      "2478 [Discriminator loss: 0.7031%, acc.: 43.36%][Generator loss: 0.7293%]\n",
      "2479 [Discriminator loss: 0.7025%, acc.: 39.84%][Generator loss: 0.7316%]\n",
      "2480 [Discriminator loss: 0.7020%, acc.: 45.70%][Generator loss: 0.7286%]\n",
      "2481 [Discriminator loss: 0.7028%, acc.: 39.45%][Generator loss: 0.7326%]\n",
      "2482 [Discriminator loss: 0.7005%, acc.: 42.19%][Generator loss: 0.7296%]\n",
      "2483 [Discriminator loss: 0.7005%, acc.: 46.48%][Generator loss: 0.7917%]\n",
      "2484 [Discriminator loss: 0.7212%, acc.: 45.70%][Generator loss: 0.7674%]\n",
      "2485 [Discriminator loss: 0.7151%, acc.: 45.70%][Generator loss: 0.7407%]\n",
      "2486 [Discriminator loss: 0.7028%, acc.: 48.83%][Generator loss: 0.7367%]\n",
      "2487 [Discriminator loss: 0.7014%, acc.: 44.14%][Generator loss: 0.7350%]\n",
      "2488 [Discriminator loss: 0.7030%, acc.: 42.58%][Generator loss: 0.7317%]\n",
      "2489 [Discriminator loss: 0.7003%, acc.: 46.09%][Generator loss: 0.7310%]\n",
      "2490 [Discriminator loss: 0.7014%, acc.: 43.75%][Generator loss: 0.7284%]\n",
      "2491 [Discriminator loss: 0.7008%, acc.: 48.44%][Generator loss: 0.7294%]\n",
      "2492 [Discriminator loss: 0.7007%, acc.: 44.53%][Generator loss: 0.7284%]\n",
      "2493 [Discriminator loss: 0.7019%, acc.: 43.36%][Generator loss: 0.7287%]\n",
      "2494 [Discriminator loss: 0.6999%, acc.: 44.53%][Generator loss: 0.7303%]\n",
      "2495 [Discriminator loss: 0.7014%, acc.: 40.62%][Generator loss: 0.7335%]\n",
      "2496 [Discriminator loss: 0.7016%, acc.: 46.88%][Generator loss: 0.7357%]\n",
      "2497 [Discriminator loss: 0.7035%, acc.: 48.05%][Generator loss: 0.7299%]\n",
      "2498 [Discriminator loss: 0.7021%, acc.: 42.97%][Generator loss: 0.7289%]\n",
      "2499 [Discriminator loss: 0.6990%, acc.: 46.09%][Generator loss: 0.7311%]\n",
      "2500 [Discriminator loss: 0.7028%, acc.: 41.41%][Generator loss: 0.7313%]\n",
      "2501 [Discriminator loss: 0.7007%, acc.: 45.31%][Generator loss: 0.7364%]\n",
      "2502 [Discriminator loss: 0.7052%, acc.: 40.23%][Generator loss: 0.7303%]\n",
      "2503 [Discriminator loss: 0.7032%, acc.: 46.88%][Generator loss: 0.7303%]\n",
      "2504 [Discriminator loss: 0.7002%, acc.: 48.44%][Generator loss: 0.7294%]\n",
      "2505 [Discriminator loss: 0.6997%, acc.: 46.88%][Generator loss: 0.7338%]\n",
      "2506 [Discriminator loss: 0.7028%, acc.: 45.31%][Generator loss: 0.7317%]\n",
      "2507 [Discriminator loss: 0.7021%, acc.: 44.53%][Generator loss: 0.7301%]\n",
      "2508 [Discriminator loss: 0.7018%, acc.: 41.41%][Generator loss: 0.7370%]\n",
      "2509 [Discriminator loss: 0.7074%, acc.: 44.53%][Generator loss: 0.7309%]\n",
      "2510 [Discriminator loss: 0.7011%, acc.: 44.53%][Generator loss: 0.7302%]\n",
      "2511 [Discriminator loss: 0.7022%, acc.: 44.53%][Generator loss: 0.7290%]\n",
      "2512 [Discriminator loss: 0.7026%, acc.: 39.45%][Generator loss: 0.7341%]\n",
      "2513 [Discriminator loss: 0.7016%, acc.: 48.05%][Generator loss: 0.7412%]\n",
      "2514 [Discriminator loss: 0.7055%, acc.: 47.27%][Generator loss: 0.7309%]\n",
      "2515 [Discriminator loss: 0.7038%, acc.: 41.80%][Generator loss: 0.7305%]\n",
      "2516 [Discriminator loss: 0.7036%, acc.: 44.92%][Generator loss: 0.7300%]\n",
      "2517 [Discriminator loss: 0.7014%, acc.: 42.58%][Generator loss: 0.7295%]\n",
      "2518 [Discriminator loss: 0.7021%, acc.: 41.41%][Generator loss: 0.7324%]\n",
      "2519 [Discriminator loss: 0.7026%, acc.: 46.09%][Generator loss: 0.7313%]\n",
      "2520 [Discriminator loss: 0.7001%, acc.: 42.97%][Generator loss: 0.7300%]\n",
      "2521 [Discriminator loss: 0.6997%, acc.: 46.88%][Generator loss: 0.7319%]\n",
      "2522 [Discriminator loss: 0.7004%, acc.: 45.70%][Generator loss: 0.7361%]\n",
      "2523 [Discriminator loss: 0.7049%, acc.: 41.80%][Generator loss: 0.7320%]\n",
      "2524 [Discriminator loss: 0.7022%, acc.: 46.09%][Generator loss: 0.7319%]\n",
      "2525 [Discriminator loss: 0.6994%, acc.: 48.83%][Generator loss: 0.7304%]\n",
      "2526 [Discriminator loss: 0.7025%, acc.: 42.19%][Generator loss: 0.7276%]\n",
      "2527 [Discriminator loss: 0.7001%, acc.: 45.70%][Generator loss: 0.7293%]\n",
      "2528 [Discriminator loss: 0.7072%, acc.: 39.06%][Generator loss: 0.7273%]\n",
      "2529 [Discriminator loss: 0.7053%, acc.: 33.98%][Generator loss: 0.7305%]\n",
      "2530 [Discriminator loss: 0.7019%, acc.: 48.05%][Generator loss: 0.7276%]\n",
      "2531 [Discriminator loss: 0.7001%, acc.: 41.41%][Generator loss: 0.7291%]\n",
      "2532 [Discriminator loss: 0.6991%, acc.: 47.27%][Generator loss: 0.7360%]\n",
      "2533 [Discriminator loss: 0.7015%, acc.: 46.09%][Generator loss: 0.7395%]\n",
      "2534 [Discriminator loss: 0.7041%, acc.: 44.92%][Generator loss: 0.7302%]\n",
      "2535 [Discriminator loss: 0.7026%, acc.: 48.44%][Generator loss: 0.7282%]\n",
      "2536 [Discriminator loss: 0.7031%, acc.: 43.75%][Generator loss: 0.7304%]\n",
      "2537 [Discriminator loss: 0.7019%, acc.: 44.53%][Generator loss: 0.7287%]\n",
      "2538 [Discriminator loss: 0.7005%, acc.: 47.66%][Generator loss: 0.7293%]\n",
      "2539 [Discriminator loss: 0.6974%, acc.: 45.31%][Generator loss: 0.7310%]\n",
      "2540 [Discriminator loss: 0.7063%, acc.: 40.23%][Generator loss: 0.7326%]\n",
      "2541 [Discriminator loss: 0.6993%, acc.: 48.05%][Generator loss: 0.7327%]\n",
      "2542 [Discriminator loss: 0.7048%, acc.: 39.45%][Generator loss: 0.7346%]\n",
      "2543 [Discriminator loss: 0.7021%, acc.: 47.27%][Generator loss: 0.7380%]\n",
      "2544 [Discriminator loss: 0.7029%, acc.: 43.75%][Generator loss: 0.7319%]\n",
      "2545 [Discriminator loss: 0.7008%, acc.: 46.88%][Generator loss: 0.7304%]\n",
      "2546 [Discriminator loss: 0.7000%, acc.: 50.00%][Generator loss: 0.7285%]\n",
      "2547 [Discriminator loss: 0.7012%, acc.: 43.75%][Generator loss: 0.7303%]\n",
      "2548 [Discriminator loss: 0.7022%, acc.: 47.66%][Generator loss: 0.7314%]\n",
      "2549 [Discriminator loss: 0.7003%, acc.: 48.44%][Generator loss: 0.7315%]\n",
      "2550 [Discriminator loss: 0.7038%, acc.: 41.80%][Generator loss: 0.7294%]\n",
      "2551 [Discriminator loss: 0.6993%, acc.: 46.88%][Generator loss: 0.7358%]\n",
      "2552 [Discriminator loss: 0.7045%, acc.: 44.92%][Generator loss: 0.7297%]\n",
      "2553 [Discriminator loss: 0.7009%, acc.: 46.88%][Generator loss: 0.7289%]\n",
      "2554 [Discriminator loss: 0.7003%, acc.: 43.36%][Generator loss: 0.7288%]\n",
      "2555 [Discriminator loss: 0.7019%, acc.: 43.75%][Generator loss: 0.7327%]\n",
      "2556 [Discriminator loss: 0.7000%, acc.: 48.83%][Generator loss: 0.7367%]\n",
      "2557 [Discriminator loss: 0.7060%, acc.: 38.28%][Generator loss: 0.7281%]\n",
      "2558 [Discriminator loss: 0.7020%, acc.: 42.19%][Generator loss: 0.7306%]\n",
      "2559 [Discriminator loss: 0.7026%, acc.: 41.41%][Generator loss: 0.7306%]\n",
      "2560 [Discriminator loss: 0.7022%, acc.: 46.48%][Generator loss: 0.7263%]\n",
      "2561 [Discriminator loss: 0.7037%, acc.: 37.89%][Generator loss: 0.7273%]\n",
      "2562 [Discriminator loss: 0.6999%, acc.: 47.27%][Generator loss: 0.7286%]\n",
      "2563 [Discriminator loss: 0.7011%, acc.: 47.27%][Generator loss: 0.7440%]\n",
      "2564 [Discriminator loss: 0.7054%, acc.: 45.70%][Generator loss: 0.7451%]\n",
      "2565 [Discriminator loss: 0.7074%, acc.: 45.31%][Generator loss: 0.7323%]\n",
      "2566 [Discriminator loss: 0.7032%, acc.: 46.88%][Generator loss: 0.7283%]\n",
      "2567 [Discriminator loss: 0.7040%, acc.: 38.28%][Generator loss: 0.7246%]\n",
      "2568 [Discriminator loss: 0.7032%, acc.: 41.41%][Generator loss: 0.7267%]\n",
      "2569 [Discriminator loss: 0.7003%, acc.: 48.44%][Generator loss: 0.7315%]\n",
      "2570 [Discriminator loss: 0.6999%, acc.: 46.09%][Generator loss: 0.7282%]\n",
      "2571 [Discriminator loss: 0.6972%, acc.: 49.22%][Generator loss: 0.7296%]\n",
      "2572 [Discriminator loss: 0.7028%, acc.: 39.06%][Generator loss: 0.7325%]\n",
      "2573 [Discriminator loss: 0.7031%, acc.: 46.09%][Generator loss: 0.7316%]\n",
      "2574 [Discriminator loss: 0.7018%, acc.: 44.14%][Generator loss: 0.7287%]\n",
      "2575 [Discriminator loss: 0.6996%, acc.: 47.66%][Generator loss: 0.7314%]\n",
      "2576 [Discriminator loss: 0.7020%, acc.: 45.31%][Generator loss: 0.7305%]\n",
      "2577 [Discriminator loss: 0.7019%, acc.: 48.05%][Generator loss: 0.7300%]\n",
      "2578 [Discriminator loss: 0.7010%, acc.: 46.09%][Generator loss: 0.7369%]\n",
      "2579 [Discriminator loss: 0.7017%, acc.: 46.88%][Generator loss: 0.7386%]\n",
      "2580 [Discriminator loss: 0.7037%, acc.: 48.05%][Generator loss: 0.7292%]\n",
      "2581 [Discriminator loss: 0.7017%, acc.: 43.36%][Generator loss: 0.7313%]\n",
      "2582 [Discriminator loss: 0.7014%, acc.: 45.70%][Generator loss: 0.7293%]\n",
      "2583 [Discriminator loss: 0.7012%, acc.: 46.48%][Generator loss: 0.7311%]\n",
      "2584 [Discriminator loss: 0.7004%, acc.: 46.48%][Generator loss: 0.7334%]\n",
      "2585 [Discriminator loss: 0.7035%, acc.: 44.53%][Generator loss: 0.7280%]\n",
      "2586 [Discriminator loss: 0.6994%, acc.: 46.48%][Generator loss: 0.7348%]\n",
      "2587 [Discriminator loss: 0.7006%, acc.: 49.22%][Generator loss: 0.7321%]\n",
      "2588 [Discriminator loss: 0.7051%, acc.: 39.84%][Generator loss: 0.7300%]\n",
      "2589 [Discriminator loss: 0.7025%, acc.: 46.88%][Generator loss: 0.7296%]\n",
      "2590 [Discriminator loss: 0.7012%, acc.: 47.27%][Generator loss: 0.7289%]\n",
      "2591 [Discriminator loss: 0.7024%, acc.: 45.70%][Generator loss: 0.7311%]\n",
      "2592 [Discriminator loss: 0.7001%, acc.: 48.05%][Generator loss: 0.7304%]\n",
      "2593 [Discriminator loss: 0.7018%, acc.: 41.02%][Generator loss: 0.7288%]\n",
      "2594 [Discriminator loss: 0.7015%, acc.: 47.66%][Generator loss: 0.7303%]\n",
      "2595 [Discriminator loss: 0.7061%, acc.: 35.16%][Generator loss: 0.7305%]\n",
      "2596 [Discriminator loss: 0.7021%, acc.: 42.97%][Generator loss: 0.7287%]\n",
      "2597 [Discriminator loss: 0.7028%, acc.: 42.97%][Generator loss: 0.7278%]\n",
      "2598 [Discriminator loss: 0.7003%, acc.: 46.88%][Generator loss: 0.7282%]\n",
      "2599 [Discriminator loss: 0.7003%, acc.: 48.83%][Generator loss: 0.7268%]\n",
      "2600 [Discriminator loss: 0.7008%, acc.: 41.02%][Generator loss: 0.7292%]\n",
      "2601 [Discriminator loss: 0.7063%, acc.: 39.84%][Generator loss: 0.7297%]\n",
      "2602 [Discriminator loss: 0.7016%, acc.: 44.14%][Generator loss: 0.7346%]\n",
      "2603 [Discriminator loss: 0.7032%, acc.: 46.09%][Generator loss: 0.7309%]\n",
      "2604 [Discriminator loss: 0.7005%, acc.: 49.61%][Generator loss: 0.7299%]\n",
      "2605 [Discriminator loss: 0.7000%, acc.: 46.09%][Generator loss: 0.7293%]\n",
      "2606 [Discriminator loss: 0.7021%, acc.: 44.14%][Generator loss: 0.7312%]\n",
      "2607 [Discriminator loss: 0.7026%, acc.: 47.66%][Generator loss: 0.7310%]\n",
      "2608 [Discriminator loss: 0.7021%, acc.: 42.58%][Generator loss: 0.7322%]\n",
      "2609 [Discriminator loss: 0.7032%, acc.: 46.09%][Generator loss: 0.7316%]\n",
      "2610 [Discriminator loss: 0.7020%, acc.: 48.44%][Generator loss: 0.7314%]\n",
      "2611 [Discriminator loss: 0.7023%, acc.: 44.53%][Generator loss: 0.7319%]\n",
      "2612 [Discriminator loss: 0.7013%, acc.: 45.31%][Generator loss: 0.7262%]\n",
      "2613 [Discriminator loss: 0.7021%, acc.: 44.53%][Generator loss: 0.7293%]\n",
      "2614 [Discriminator loss: 0.7010%, acc.: 44.53%][Generator loss: 0.7329%]\n",
      "2615 [Discriminator loss: 0.7002%, acc.: 50.00%][Generator loss: 0.7382%]\n",
      "2616 [Discriminator loss: 0.7039%, acc.: 49.22%][Generator loss: 0.7312%]\n",
      "2617 [Discriminator loss: 0.7010%, acc.: 46.88%][Generator loss: 0.7282%]\n",
      "2618 [Discriminator loss: 0.7015%, acc.: 42.97%][Generator loss: 0.7303%]\n",
      "2619 [Discriminator loss: 0.7017%, acc.: 44.14%][Generator loss: 0.7339%]\n",
      "2620 [Discriminator loss: 0.7032%, acc.: 44.92%][Generator loss: 0.7305%]\n",
      "2621 [Discriminator loss: 0.7002%, acc.: 44.92%][Generator loss: 0.7317%]\n",
      "2622 [Discriminator loss: 0.7012%, acc.: 45.31%][Generator loss: 0.7305%]\n",
      "2623 [Discriminator loss: 0.7015%, acc.: 45.70%][Generator loss: 0.7293%]\n",
      "2624 [Discriminator loss: 0.7013%, acc.: 44.92%][Generator loss: 0.7367%]\n",
      "2625 [Discriminator loss: 0.7040%, acc.: 49.61%][Generator loss: 0.7368%]\n",
      "2626 [Discriminator loss: 0.7024%, acc.: 48.44%][Generator loss: 0.7305%]\n",
      "2627 [Discriminator loss: 0.6988%, acc.: 48.44%][Generator loss: 0.7293%]\n",
      "2628 [Discriminator loss: 0.7016%, acc.: 44.53%][Generator loss: 0.7302%]\n",
      "2629 [Discriminator loss: 0.7037%, acc.: 38.67%][Generator loss: 0.7287%]\n",
      "2630 [Discriminator loss: 0.7002%, acc.: 46.48%][Generator loss: 0.7304%]\n",
      "2631 [Discriminator loss: 0.7009%, acc.: 46.09%][Generator loss: 0.7304%]\n",
      "2632 [Discriminator loss: 0.7037%, acc.: 36.72%][Generator loss: 0.7292%]\n",
      "2633 [Discriminator loss: 0.7001%, acc.: 42.97%][Generator loss: 0.7295%]\n",
      "2634 [Discriminator loss: 0.7002%, acc.: 47.66%][Generator loss: 0.7298%]\n",
      "2635 [Discriminator loss: 0.7014%, acc.: 46.09%][Generator loss: 0.7355%]\n",
      "2636 [Discriminator loss: 0.7023%, acc.: 46.09%][Generator loss: 0.7303%]\n",
      "2637 [Discriminator loss: 0.7023%, acc.: 40.23%][Generator loss: 0.7291%]\n",
      "2638 [Discriminator loss: 0.7002%, acc.: 49.22%][Generator loss: 0.7313%]\n",
      "2639 [Discriminator loss: 0.6993%, acc.: 47.66%][Generator loss: 0.7326%]\n",
      "2640 [Discriminator loss: 0.7017%, acc.: 48.44%][Generator loss: 0.7338%]\n",
      "2641 [Discriminator loss: 0.7010%, acc.: 46.88%][Generator loss: 0.7375%]\n",
      "2642 [Discriminator loss: 0.7021%, acc.: 47.27%][Generator loss: 0.7333%]\n",
      "2643 [Discriminator loss: 0.7011%, acc.: 46.88%][Generator loss: 0.7301%]\n",
      "2644 [Discriminator loss: 0.7025%, acc.: 46.09%][Generator loss: 0.7340%]\n",
      "2645 [Discriminator loss: 0.7030%, acc.: 44.14%][Generator loss: 0.7317%]\n",
      "2646 [Discriminator loss: 0.7004%, acc.: 48.44%][Generator loss: 0.7295%]\n",
      "2647 [Discriminator loss: 0.7003%, acc.: 48.83%][Generator loss: 0.7342%]\n",
      "2648 [Discriminator loss: 0.7000%, acc.: 45.70%][Generator loss: 0.7395%]\n",
      "2649 [Discriminator loss: 0.7066%, acc.: 40.23%][Generator loss: 0.7276%]\n",
      "2650 [Discriminator loss: 0.7015%, acc.: 44.14%][Generator loss: 0.7288%]\n",
      "2651 [Discriminator loss: 0.7010%, acc.: 48.44%][Generator loss: 0.7281%]\n",
      "2652 [Discriminator loss: 0.6986%, acc.: 49.22%][Generator loss: 0.7323%]\n",
      "2653 [Discriminator loss: 0.7019%, acc.: 45.70%][Generator loss: 0.7296%]\n",
      "2654 [Discriminator loss: 0.6994%, acc.: 45.31%][Generator loss: 0.7306%]\n",
      "2655 [Discriminator loss: 0.6991%, acc.: 48.44%][Generator loss: 0.7315%]\n",
      "2656 [Discriminator loss: 0.7012%, acc.: 45.31%][Generator loss: 0.7428%]\n",
      "2657 [Discriminator loss: 0.7036%, acc.: 47.66%][Generator loss: 0.7451%]\n",
      "2658 [Discriminator loss: 0.7046%, acc.: 48.05%][Generator loss: 0.7362%]\n",
      "2659 [Discriminator loss: 0.7016%, acc.: 49.61%][Generator loss: 0.7313%]\n",
      "2660 [Discriminator loss: 0.7014%, acc.: 48.05%][Generator loss: 0.7318%]\n",
      "2661 [Discriminator loss: 0.7001%, acc.: 49.61%][Generator loss: 0.7340%]\n",
      "2662 [Discriminator loss: 0.7029%, acc.: 42.58%][Generator loss: 0.7289%]\n",
      "2663 [Discriminator loss: 0.6996%, acc.: 47.66%][Generator loss: 0.7322%]\n",
      "2664 [Discriminator loss: 0.6995%, acc.: 50.00%][Generator loss: 0.7318%]\n",
      "2665 [Discriminator loss: 0.7005%, acc.: 46.88%][Generator loss: 0.7324%]\n",
      "2666 [Discriminator loss: 0.7043%, acc.: 46.88%][Generator loss: 0.7315%]\n",
      "2667 [Discriminator loss: 0.7021%, acc.: 42.19%][Generator loss: 0.7304%]\n",
      "2668 [Discriminator loss: 0.6995%, acc.: 50.00%][Generator loss: 0.7306%]\n",
      "2669 [Discriminator loss: 0.7027%, acc.: 40.23%][Generator loss: 0.7301%]\n",
      "2670 [Discriminator loss: 0.7027%, acc.: 48.44%][Generator loss: 0.7286%]\n",
      "2671 [Discriminator loss: 0.7013%, acc.: 43.75%][Generator loss: 0.7294%]\n",
      "2672 [Discriminator loss: 0.7017%, acc.: 38.67%][Generator loss: 0.7316%]\n",
      "2673 [Discriminator loss: 0.7014%, acc.: 45.70%][Generator loss: 0.7343%]\n",
      "2674 [Discriminator loss: 0.7021%, acc.: 46.88%][Generator loss: 0.7275%]\n",
      "2675 [Discriminator loss: 0.7009%, acc.: 45.31%][Generator loss: 0.7305%]\n",
      "2676 [Discriminator loss: 0.6984%, acc.: 46.48%][Generator loss: 0.7384%]\n",
      "2677 [Discriminator loss: 0.7046%, acc.: 48.05%][Generator loss: 0.7301%]\n",
      "2678 [Discriminator loss: 0.7002%, acc.: 48.83%][Generator loss: 0.7291%]\n",
      "2679 [Discriminator loss: 0.6992%, acc.: 48.83%][Generator loss: 0.7314%]\n",
      "2680 [Discriminator loss: 0.7019%, acc.: 44.92%][Generator loss: 0.7318%]\n",
      "2681 [Discriminator loss: 0.7020%, acc.: 47.66%][Generator loss: 0.7304%]\n",
      "2682 [Discriminator loss: 0.7006%, acc.: 47.66%][Generator loss: 0.7312%]\n",
      "2683 [Discriminator loss: 0.6996%, acc.: 49.61%][Generator loss: 0.7383%]\n",
      "2684 [Discriminator loss: 0.7045%, acc.: 46.09%][Generator loss: 0.7298%]\n",
      "2685 [Discriminator loss: 0.7017%, acc.: 42.58%][Generator loss: 0.7324%]\n",
      "2686 [Discriminator loss: 0.7035%, acc.: 47.27%][Generator loss: 0.7305%]\n",
      "2687 [Discriminator loss: 0.7013%, acc.: 43.36%][Generator loss: 0.7291%]\n",
      "2688 [Discriminator loss: 0.6998%, acc.: 47.27%][Generator loss: 0.7297%]\n",
      "2689 [Discriminator loss: 0.6994%, acc.: 50.39%][Generator loss: 0.7304%]\n",
      "2690 [Discriminator loss: 0.6995%, acc.: 48.05%][Generator loss: 0.7313%]\n",
      "2691 [Discriminator loss: 0.7001%, acc.: 47.66%][Generator loss: 0.7302%]\n",
      "2692 [Discriminator loss: 0.6999%, acc.: 50.00%][Generator loss: 0.7352%]\n",
      "2693 [Discriminator loss: 0.7014%, acc.: 46.09%][Generator loss: 0.7359%]\n",
      "2694 [Discriminator loss: 0.7041%, acc.: 46.48%][Generator loss: 0.7286%]\n",
      "2695 [Discriminator loss: 0.7002%, acc.: 49.61%][Generator loss: 0.7277%]\n",
      "2696 [Discriminator loss: 0.7019%, acc.: 46.48%][Generator loss: 0.7319%]\n",
      "2697 [Discriminator loss: 0.7016%, acc.: 48.05%][Generator loss: 0.7314%]\n",
      "2698 [Discriminator loss: 0.7008%, acc.: 46.48%][Generator loss: 0.7297%]\n",
      "2699 [Discriminator loss: 0.7006%, acc.: 46.88%][Generator loss: 0.7294%]\n",
      "2700 [Discriminator loss: 0.6999%, acc.: 46.09%][Generator loss: 0.7305%]\n",
      "2701 [Discriminator loss: 0.6996%, acc.: 45.70%][Generator loss: 0.7302%]\n",
      "2702 [Discriminator loss: 0.6984%, acc.: 49.61%][Generator loss: 0.7367%]\n",
      "2703 [Discriminator loss: 0.7027%, acc.: 48.44%][Generator loss: 0.7326%]\n",
      "2704 [Discriminator loss: 0.7015%, acc.: 49.22%][Generator loss: 0.7339%]\n",
      "2705 [Discriminator loss: 0.7038%, acc.: 47.27%][Generator loss: 0.7316%]\n",
      "2706 [Discriminator loss: 0.6990%, acc.: 48.83%][Generator loss: 0.7334%]\n",
      "2707 [Discriminator loss: 0.7029%, acc.: 46.48%][Generator loss: 0.7309%]\n",
      "2708 [Discriminator loss: 0.7005%, acc.: 48.83%][Generator loss: 0.7298%]\n",
      "2709 [Discriminator loss: 0.7003%, acc.: 47.27%][Generator loss: 0.7296%]\n",
      "2710 [Discriminator loss: 0.6999%, acc.: 48.83%][Generator loss: 0.7311%]\n",
      "2711 [Discriminator loss: 0.7011%, acc.: 47.66%][Generator loss: 0.7335%]\n",
      "2712 [Discriminator loss: 0.7007%, acc.: 47.27%][Generator loss: 0.7384%]\n",
      "2713 [Discriminator loss: 0.7011%, acc.: 50.39%][Generator loss: 0.7319%]\n",
      "2714 [Discriminator loss: 0.7015%, acc.: 45.31%][Generator loss: 0.7304%]\n",
      "2715 [Discriminator loss: 0.7032%, acc.: 43.75%][Generator loss: 0.7322%]\n",
      "2716 [Discriminator loss: 0.7003%, acc.: 46.09%][Generator loss: 0.7324%]\n",
      "2717 [Discriminator loss: 0.7006%, acc.: 50.00%][Generator loss: 0.7294%]\n",
      "2718 [Discriminator loss: 0.6997%, acc.: 44.92%][Generator loss: 0.7280%]\n",
      "2719 [Discriminator loss: 0.7036%, acc.: 38.67%][Generator loss: 0.7312%]\n",
      "2720 [Discriminator loss: 0.6998%, acc.: 45.31%][Generator loss: 0.7310%]\n",
      "2721 [Discriminator loss: 0.7040%, acc.: 48.05%][Generator loss: 0.7293%]\n",
      "2722 [Discriminator loss: 0.6997%, acc.: 46.88%][Generator loss: 0.7305%]\n",
      "2723 [Discriminator loss: 0.7005%, acc.: 45.31%][Generator loss: 0.7297%]\n",
      "2724 [Discriminator loss: 0.6998%, acc.: 44.14%][Generator loss: 0.7317%]\n",
      "2725 [Discriminator loss: 0.7020%, acc.: 47.27%][Generator loss: 0.7300%]\n",
      "2726 [Discriminator loss: 0.7002%, acc.: 48.05%][Generator loss: 0.7286%]\n",
      "2727 [Discriminator loss: 0.6999%, acc.: 48.44%][Generator loss: 0.7292%]\n",
      "2728 [Discriminator loss: 0.7022%, acc.: 48.83%][Generator loss: 0.7352%]\n",
      "2729 [Discriminator loss: 0.7017%, acc.: 49.61%][Generator loss: 0.7358%]\n",
      "2730 [Discriminator loss: 0.7028%, acc.: 50.39%][Generator loss: 0.7291%]\n",
      "2731 [Discriminator loss: 0.7000%, acc.: 46.88%][Generator loss: 0.7300%]\n",
      "2732 [Discriminator loss: 0.6998%, acc.: 47.66%][Generator loss: 0.7301%]\n",
      "2733 [Discriminator loss: 0.7010%, acc.: 48.05%][Generator loss: 0.7299%]\n",
      "2734 [Discriminator loss: 0.7022%, acc.: 44.53%][Generator loss: 0.7314%]\n",
      "2735 [Discriminator loss: 0.6991%, acc.: 46.09%][Generator loss: 0.7358%]\n",
      "2736 [Discriminator loss: 0.7032%, acc.: 45.31%][Generator loss: 0.7309%]\n",
      "2737 [Discriminator loss: 0.7001%, acc.: 46.09%][Generator loss: 0.7313%]\n",
      "2738 [Discriminator loss: 0.7009%, acc.: 49.22%][Generator loss: 0.7328%]\n",
      "2739 [Discriminator loss: 0.7028%, acc.: 48.44%][Generator loss: 0.7313%]\n",
      "2740 [Discriminator loss: 0.7008%, acc.: 47.27%][Generator loss: 0.7292%]\n",
      "2741 [Discriminator loss: 0.7020%, acc.: 38.67%][Generator loss: 0.7298%]\n",
      "2742 [Discriminator loss: 0.7014%, acc.: 45.31%][Generator loss: 0.7302%]\n",
      "2743 [Discriminator loss: 0.7012%, acc.: 47.27%][Generator loss: 0.7305%]\n",
      "2744 [Discriminator loss: 0.6986%, acc.: 49.61%][Generator loss: 0.7330%]\n",
      "2745 [Discriminator loss: 0.7013%, acc.: 47.27%][Generator loss: 0.7362%]\n",
      "2746 [Discriminator loss: 0.7035%, acc.: 45.70%][Generator loss: 0.7311%]\n",
      "2747 [Discriminator loss: 0.6996%, acc.: 48.05%][Generator loss: 0.7315%]\n",
      "2748 [Discriminator loss: 0.7003%, acc.: 48.44%][Generator loss: 0.7319%]\n",
      "2749 [Discriminator loss: 0.7003%, acc.: 48.44%][Generator loss: 0.7300%]\n",
      "2750 [Discriminator loss: 0.7024%, acc.: 44.92%][Generator loss: 0.7295%]\n",
      "2751 [Discriminator loss: 0.7005%, acc.: 48.05%][Generator loss: 0.7323%]\n",
      "2752 [Discriminator loss: 0.6998%, acc.: 46.88%][Generator loss: 0.7306%]\n",
      "2753 [Discriminator loss: 0.6995%, acc.: 47.27%][Generator loss: 0.7315%]\n",
      "2754 [Discriminator loss: 0.6998%, acc.: 48.83%][Generator loss: 0.7313%]\n",
      "2755 [Discriminator loss: 0.6991%, acc.: 48.05%][Generator loss: 0.7307%]\n",
      "2756 [Discriminator loss: 0.7007%, acc.: 47.27%][Generator loss: 0.7303%]\n",
      "2757 [Discriminator loss: 0.7017%, acc.: 46.09%][Generator loss: 0.7312%]\n",
      "2758 [Discriminator loss: 0.7000%, acc.: 48.44%][Generator loss: 0.7299%]\n",
      "2759 [Discriminator loss: 0.6990%, acc.: 46.88%][Generator loss: 0.7309%]\n",
      "2760 [Discriminator loss: 0.7018%, acc.: 43.75%][Generator loss: 0.7306%]\n",
      "2761 [Discriminator loss: 0.6995%, acc.: 46.09%][Generator loss: 0.7326%]\n",
      "2762 [Discriminator loss: 0.7007%, acc.: 47.66%][Generator loss: 0.7323%]\n",
      "2763 [Discriminator loss: 0.7011%, acc.: 47.27%][Generator loss: 0.7330%]\n",
      "2764 [Discriminator loss: 0.7010%, acc.: 49.61%][Generator loss: 0.7300%]\n",
      "2765 [Discriminator loss: 0.6990%, acc.: 44.14%][Generator loss: 0.7341%]\n",
      "2766 [Discriminator loss: 0.7015%, acc.: 46.48%][Generator loss: 0.7322%]\n",
      "2767 [Discriminator loss: 0.7006%, acc.: 47.66%][Generator loss: 0.7312%]\n",
      "2768 [Discriminator loss: 0.7007%, acc.: 45.31%][Generator loss: 0.7321%]\n",
      "2769 [Discriminator loss: 0.7016%, acc.: 48.44%][Generator loss: 0.7308%]\n",
      "2770 [Discriminator loss: 0.7001%, acc.: 46.48%][Generator loss: 0.7309%]\n",
      "2771 [Discriminator loss: 0.7024%, acc.: 47.66%][Generator loss: 0.7313%]\n",
      "2772 [Discriminator loss: 0.6987%, acc.: 47.27%][Generator loss: 0.7347%]\n",
      "2773 [Discriminator loss: 0.7004%, acc.: 47.66%][Generator loss: 0.7307%]\n",
      "2774 [Discriminator loss: 0.6995%, acc.: 47.27%][Generator loss: 0.7306%]\n",
      "2775 [Discriminator loss: 0.6988%, acc.: 48.44%][Generator loss: 0.7312%]\n",
      "2776 [Discriminator loss: 0.7017%, acc.: 47.66%][Generator loss: 0.7304%]\n",
      "2777 [Discriminator loss: 0.6995%, acc.: 50.00%][Generator loss: 0.7321%]\n",
      "2778 [Discriminator loss: 0.6993%, acc.: 45.70%][Generator loss: 0.7333%]\n",
      "2779 [Discriminator loss: 0.7010%, acc.: 49.61%][Generator loss: 0.7337%]\n",
      "2780 [Discriminator loss: 0.6994%, acc.: 47.27%][Generator loss: 0.7387%]\n",
      "2781 [Discriminator loss: 0.7040%, acc.: 50.00%][Generator loss: 0.7307%]\n",
      "2782 [Discriminator loss: 0.7014%, acc.: 47.66%][Generator loss: 0.7308%]\n",
      "2783 [Discriminator loss: 0.7008%, acc.: 48.05%][Generator loss: 0.7317%]\n",
      "2784 [Discriminator loss: 0.7005%, acc.: 49.22%][Generator loss: 0.7291%]\n",
      "2785 [Discriminator loss: 0.6991%, acc.: 48.05%][Generator loss: 0.7306%]\n",
      "2786 [Discriminator loss: 0.7007%, acc.: 46.88%][Generator loss: 0.7280%]\n",
      "2787 [Discriminator loss: 0.6996%, acc.: 44.92%][Generator loss: 0.7322%]\n",
      "2788 [Discriminator loss: 0.7008%, acc.: 48.44%][Generator loss: 0.7295%]\n",
      "2789 [Discriminator loss: 0.6998%, acc.: 48.83%][Generator loss: 0.7287%]\n",
      "2790 [Discriminator loss: 0.6997%, acc.: 50.00%][Generator loss: 0.7303%]\n",
      "2791 [Discriminator loss: 0.7001%, acc.: 46.09%][Generator loss: 0.7313%]\n",
      "2792 [Discriminator loss: 0.7025%, acc.: 48.44%][Generator loss: 0.7310%]\n",
      "2793 [Discriminator loss: 0.7010%, acc.: 48.83%][Generator loss: 0.7304%]\n",
      "2794 [Discriminator loss: 0.6991%, acc.: 44.53%][Generator loss: 0.7314%]\n",
      "2795 [Discriminator loss: 0.7008%, acc.: 48.83%][Generator loss: 0.7309%]\n",
      "2796 [Discriminator loss: 0.7000%, acc.: 46.09%][Generator loss: 0.7300%]\n",
      "2797 [Discriminator loss: 0.7013%, acc.: 49.61%][Generator loss: 0.7317%]\n",
      "2798 [Discriminator loss: 0.7004%, acc.: 50.00%][Generator loss: 0.7303%]\n",
      "2799 [Discriminator loss: 0.6997%, acc.: 46.09%][Generator loss: 0.7299%]\n",
      "2800 [Discriminator loss: 0.7010%, acc.: 48.83%][Generator loss: 0.7306%]\n",
      "2801 [Discriminator loss: 0.7009%, acc.: 48.83%][Generator loss: 0.7320%]\n",
      "2802 [Discriminator loss: 0.7012%, acc.: 46.09%][Generator loss: 0.7348%]\n",
      "2803 [Discriminator loss: 0.7012%, acc.: 50.00%][Generator loss: 0.7301%]\n",
      "2804 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7304%]\n",
      "2805 [Discriminator loss: 0.6995%, acc.: 44.53%][Generator loss: 0.7286%]\n",
      "2806 [Discriminator loss: 0.7001%, acc.: 45.31%][Generator loss: 0.7284%]\n",
      "2807 [Discriminator loss: 0.7005%, acc.: 43.36%][Generator loss: 0.7279%]\n",
      "2808 [Discriminator loss: 0.7018%, acc.: 43.36%][Generator loss: 0.7304%]\n",
      "2809 [Discriminator loss: 0.7008%, acc.: 49.61%][Generator loss: 0.7319%]\n",
      "2810 [Discriminator loss: 0.6999%, acc.: 47.27%][Generator loss: 0.7336%]\n",
      "2811 [Discriminator loss: 0.7012%, acc.: 49.22%][Generator loss: 0.7297%]\n",
      "2812 [Discriminator loss: 0.6987%, acc.: 47.27%][Generator loss: 0.7311%]\n",
      "2813 [Discriminator loss: 0.6995%, acc.: 48.05%][Generator loss: 0.7335%]\n",
      "2814 [Discriminator loss: 0.6993%, acc.: 47.27%][Generator loss: 0.7351%]\n",
      "2815 [Discriminator loss: 0.7037%, acc.: 41.80%][Generator loss: 0.7305%]\n",
      "2816 [Discriminator loss: 0.7000%, acc.: 49.61%][Generator loss: 0.7314%]\n",
      "2817 [Discriminator loss: 0.7005%, acc.: 48.44%][Generator loss: 0.7289%]\n",
      "2818 [Discriminator loss: 0.6981%, acc.: 49.22%][Generator loss: 0.7330%]\n",
      "2819 [Discriminator loss: 0.7021%, acc.: 42.19%][Generator loss: 0.7277%]\n",
      "2820 [Discriminator loss: 0.7009%, acc.: 42.19%][Generator loss: 0.7293%]\n",
      "2821 [Discriminator loss: 0.6986%, acc.: 49.22%][Generator loss: 0.7297%]\n",
      "2822 [Discriminator loss: 0.6999%, acc.: 44.92%][Generator loss: 0.7283%]\n",
      "2823 [Discriminator loss: 0.6989%, acc.: 48.44%][Generator loss: 0.7306%]\n",
      "2824 [Discriminator loss: 0.6989%, acc.: 46.09%][Generator loss: 0.7288%]\n",
      "2825 [Discriminator loss: 0.6998%, acc.: 47.66%][Generator loss: 0.7291%]\n",
      "2826 [Discriminator loss: 0.6997%, acc.: 50.00%][Generator loss: 0.7320%]\n",
      "2827 [Discriminator loss: 0.7004%, acc.: 47.27%][Generator loss: 0.7271%]\n",
      "2828 [Discriminator loss: 0.7009%, acc.: 48.05%][Generator loss: 0.7269%]\n",
      "2829 [Discriminator loss: 0.7007%, acc.: 42.19%][Generator loss: 0.7322%]\n",
      "2830 [Discriminator loss: 0.7032%, acc.: 48.44%][Generator loss: 0.7367%]\n",
      "2831 [Discriminator loss: 0.7015%, acc.: 50.00%][Generator loss: 0.7285%]\n",
      "2832 [Discriminator loss: 0.6992%, acc.: 46.88%][Generator loss: 0.7269%]\n",
      "2833 [Discriminator loss: 0.7002%, acc.: 44.92%][Generator loss: 0.7281%]\n",
      "2834 [Discriminator loss: 0.6993%, acc.: 46.09%][Generator loss: 0.7302%]\n",
      "2835 [Discriminator loss: 0.6991%, acc.: 48.44%][Generator loss: 0.7301%]\n",
      "2836 [Discriminator loss: 0.7011%, acc.: 42.97%][Generator loss: 0.7265%]\n",
      "2837 [Discriminator loss: 0.7006%, acc.: 46.48%][Generator loss: 0.7308%]\n",
      "2838 [Discriminator loss: 0.6994%, acc.: 49.22%][Generator loss: 0.7291%]\n",
      "2839 [Discriminator loss: 0.6991%, acc.: 49.61%][Generator loss: 0.7297%]\n",
      "2840 [Discriminator loss: 0.6982%, acc.: 49.61%][Generator loss: 0.7324%]\n",
      "2841 [Discriminator loss: 0.7000%, acc.: 48.83%][Generator loss: 0.7333%]\n",
      "2842 [Discriminator loss: 0.7017%, acc.: 44.92%][Generator loss: 0.7290%]\n",
      "2843 [Discriminator loss: 0.7003%, acc.: 50.39%][Generator loss: 0.7291%]\n",
      "2844 [Discriminator loss: 0.6994%, acc.: 46.88%][Generator loss: 0.7286%]\n",
      "2845 [Discriminator loss: 0.6999%, acc.: 45.31%][Generator loss: 0.7300%]\n",
      "2846 [Discriminator loss: 0.6998%, acc.: 46.09%][Generator loss: 0.7309%]\n",
      "2847 [Discriminator loss: 0.6998%, acc.: 48.05%][Generator loss: 0.7289%]\n",
      "2848 [Discriminator loss: 0.7008%, acc.: 47.66%][Generator loss: 0.7292%]\n",
      "2849 [Discriminator loss: 0.7004%, acc.: 48.05%][Generator loss: 0.7297%]\n",
      "2850 [Discriminator loss: 0.6983%, acc.: 49.61%][Generator loss: 0.7331%]\n",
      "2851 [Discriminator loss: 0.7018%, acc.: 47.27%][Generator loss: 0.7304%]\n",
      "2852 [Discriminator loss: 0.7020%, acc.: 39.84%][Generator loss: 0.7283%]\n",
      "2853 [Discriminator loss: 0.7023%, acc.: 45.31%][Generator loss: 0.7269%]\n",
      "2854 [Discriminator loss: 0.7001%, acc.: 44.92%][Generator loss: 0.7271%]\n",
      "2855 [Discriminator loss: 0.7008%, acc.: 46.48%][Generator loss: 0.7285%]\n",
      "2856 [Discriminator loss: 0.7010%, acc.: 46.09%][Generator loss: 0.7293%]\n",
      "2857 [Discriminator loss: 0.7005%, acc.: 48.05%][Generator loss: 0.7281%]\n",
      "2858 [Discriminator loss: 0.6985%, acc.: 48.44%][Generator loss: 0.7273%]\n",
      "2859 [Discriminator loss: 0.7002%, acc.: 49.61%][Generator loss: 0.7290%]\n",
      "2860 [Discriminator loss: 0.6994%, acc.: 47.66%][Generator loss: 0.7312%]\n",
      "2861 [Discriminator loss: 0.7017%, acc.: 50.00%][Generator loss: 0.7285%]\n",
      "2862 [Discriminator loss: 0.7016%, acc.: 44.14%][Generator loss: 0.7278%]\n",
      "2863 [Discriminator loss: 0.6997%, acc.: 50.00%][Generator loss: 0.7275%]\n",
      "2864 [Discriminator loss: 0.6994%, acc.: 46.09%][Generator loss: 0.7289%]\n",
      "2865 [Discriminator loss: 0.6996%, acc.: 50.00%][Generator loss: 0.7283%]\n",
      "2866 [Discriminator loss: 0.6993%, acc.: 45.31%][Generator loss: 0.7294%]\n",
      "2867 [Discriminator loss: 0.7028%, acc.: 47.66%][Generator loss: 0.7277%]\n",
      "2868 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7315%]\n",
      "2869 [Discriminator loss: 0.7020%, acc.: 49.22%][Generator loss: 0.7325%]\n",
      "2870 [Discriminator loss: 0.6999%, acc.: 49.61%][Generator loss: 0.7300%]\n",
      "2871 [Discriminator loss: 0.6996%, acc.: 46.09%][Generator loss: 0.7312%]\n",
      "2872 [Discriminator loss: 0.6991%, acc.: 49.61%][Generator loss: 0.7292%]\n",
      "2873 [Discriminator loss: 0.7001%, acc.: 47.66%][Generator loss: 0.7275%]\n",
      "2874 [Discriminator loss: 0.6995%, acc.: 43.36%][Generator loss: 0.7314%]\n",
      "2875 [Discriminator loss: 0.7011%, acc.: 49.61%][Generator loss: 0.7288%]\n",
      "2876 [Discriminator loss: 0.7008%, acc.: 44.14%][Generator loss: 0.7267%]\n",
      "2877 [Discriminator loss: 0.7004%, acc.: 49.61%][Generator loss: 0.7262%]\n",
      "2878 [Discriminator loss: 0.6989%, acc.: 47.66%][Generator loss: 0.7295%]\n",
      "2879 [Discriminator loss: 0.6989%, acc.: 47.66%][Generator loss: 0.7275%]\n",
      "2880 [Discriminator loss: 0.6995%, acc.: 50.39%][Generator loss: 0.7299%]\n",
      "2881 [Discriminator loss: 0.6995%, acc.: 43.75%][Generator loss: 0.7266%]\n",
      "2882 [Discriminator loss: 0.7007%, acc.: 48.83%][Generator loss: 0.7280%]\n",
      "2883 [Discriminator loss: 0.7020%, acc.: 47.27%][Generator loss: 0.7276%]\n",
      "2884 [Discriminator loss: 0.6996%, acc.: 49.61%][Generator loss: 0.7284%]\n",
      "2885 [Discriminator loss: 0.7000%, acc.: 46.88%][Generator loss: 0.7276%]\n",
      "2886 [Discriminator loss: 0.7009%, acc.: 48.05%][Generator loss: 0.7277%]\n",
      "2887 [Discriminator loss: 0.7004%, acc.: 46.48%][Generator loss: 0.7273%]\n",
      "2888 [Discriminator loss: 0.7008%, acc.: 44.14%][Generator loss: 0.7284%]\n",
      "2889 [Discriminator loss: 0.7020%, acc.: 45.70%][Generator loss: 0.7272%]\n",
      "2890 [Discriminator loss: 0.6992%, acc.: 47.27%][Generator loss: 0.7270%]\n",
      "2891 [Discriminator loss: 0.7002%, acc.: 50.39%][Generator loss: 0.7281%]\n",
      "2892 [Discriminator loss: 0.6998%, acc.: 45.70%][Generator loss: 0.7280%]\n",
      "2893 [Discriminator loss: 0.7006%, acc.: 44.14%][Generator loss: 0.7301%]\n",
      "2894 [Discriminator loss: 0.7011%, acc.: 48.83%][Generator loss: 0.7280%]\n",
      "2895 [Discriminator loss: 0.6979%, acc.: 49.22%][Generator loss: 0.7274%]\n",
      "2896 [Discriminator loss: 0.7011%, acc.: 44.92%][Generator loss: 0.7313%]\n",
      "2897 [Discriminator loss: 0.6991%, acc.: 50.00%][Generator loss: 0.7295%]\n",
      "2898 [Discriminator loss: 0.6988%, acc.: 47.66%][Generator loss: 0.7296%]\n",
      "2899 [Discriminator loss: 0.6998%, acc.: 50.00%][Generator loss: 0.7277%]\n",
      "2900 [Discriminator loss: 0.6984%, acc.: 47.27%][Generator loss: 0.7304%]\n",
      "2901 [Discriminator loss: 0.6997%, acc.: 47.27%][Generator loss: 0.7298%]\n",
      "2902 [Discriminator loss: 0.7000%, acc.: 48.44%][Generator loss: 0.7291%]\n",
      "2903 [Discriminator loss: 0.7010%, acc.: 44.53%][Generator loss: 0.7300%]\n",
      "2904 [Discriminator loss: 0.6996%, acc.: 48.44%][Generator loss: 0.7295%]\n",
      "2905 [Discriminator loss: 0.7013%, acc.: 43.75%][Generator loss: 0.7260%]\n",
      "2906 [Discriminator loss: 0.7007%, acc.: 47.66%][Generator loss: 0.7280%]\n",
      "2907 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7270%]\n",
      "2908 [Discriminator loss: 0.6985%, acc.: 47.27%][Generator loss: 0.7284%]\n",
      "2909 [Discriminator loss: 0.7007%, acc.: 48.44%][Generator loss: 0.7275%]\n",
      "2910 [Discriminator loss: 0.6987%, acc.: 50.00%][Generator loss: 0.7298%]\n",
      "2911 [Discriminator loss: 0.6998%, acc.: 48.44%][Generator loss: 0.7289%]\n",
      "2912 [Discriminator loss: 0.6998%, acc.: 50.00%][Generator loss: 0.7283%]\n",
      "2913 [Discriminator loss: 0.6994%, acc.: 48.83%][Generator loss: 0.7286%]\n",
      "2914 [Discriminator loss: 0.6995%, acc.: 49.61%][Generator loss: 0.7302%]\n",
      "2915 [Discriminator loss: 0.7004%, acc.: 46.48%][Generator loss: 0.7325%]\n",
      "2916 [Discriminator loss: 0.7016%, acc.: 50.00%][Generator loss: 0.7324%]\n",
      "2917 [Discriminator loss: 0.7019%, acc.: 47.27%][Generator loss: 0.7278%]\n",
      "2918 [Discriminator loss: 0.7005%, acc.: 44.14%][Generator loss: 0.7273%]\n",
      "2919 [Discriminator loss: 0.6991%, acc.: 47.66%][Generator loss: 0.7285%]\n",
      "2920 [Discriminator loss: 0.7000%, acc.: 42.58%][Generator loss: 0.7262%]\n",
      "2921 [Discriminator loss: 0.7000%, acc.: 48.83%][Generator loss: 0.7282%]\n",
      "2922 [Discriminator loss: 0.6995%, acc.: 48.44%][Generator loss: 0.7275%]\n",
      "2923 [Discriminator loss: 0.6998%, acc.: 50.39%][Generator loss: 0.7290%]\n",
      "2924 [Discriminator loss: 0.6989%, acc.: 48.83%][Generator loss: 0.7290%]\n",
      "2925 [Discriminator loss: 0.7007%, acc.: 49.61%][Generator loss: 0.7293%]\n",
      "2926 [Discriminator loss: 0.6987%, acc.: 49.61%][Generator loss: 0.7277%]\n",
      "2927 [Discriminator loss: 0.7016%, acc.: 41.02%][Generator loss: 0.7281%]\n",
      "2928 [Discriminator loss: 0.6999%, acc.: 49.61%][Generator loss: 0.7272%]\n",
      "2929 [Discriminator loss: 0.6983%, acc.: 47.27%][Generator loss: 0.7284%]\n",
      "2930 [Discriminator loss: 0.6985%, acc.: 47.66%][Generator loss: 0.7299%]\n",
      "2931 [Discriminator loss: 0.6996%, acc.: 48.44%][Generator loss: 0.7290%]\n",
      "2932 [Discriminator loss: 0.6996%, acc.: 48.83%][Generator loss: 0.7263%]\n",
      "2933 [Discriminator loss: 0.6998%, acc.: 50.00%][Generator loss: 0.7284%]\n",
      "2934 [Discriminator loss: 0.6995%, acc.: 48.44%][Generator loss: 0.7302%]\n",
      "2935 [Discriminator loss: 0.7021%, acc.: 44.53%][Generator loss: 0.7300%]\n",
      "2936 [Discriminator loss: 0.7018%, acc.: 49.61%][Generator loss: 0.7301%]\n",
      "2937 [Discriminator loss: 0.7008%, acc.: 46.48%][Generator loss: 0.7289%]\n",
      "2938 [Discriminator loss: 0.7004%, acc.: 48.83%][Generator loss: 0.7275%]\n",
      "2939 [Discriminator loss: 0.6984%, acc.: 46.48%][Generator loss: 0.7271%]\n",
      "2940 [Discriminator loss: 0.6989%, acc.: 49.61%][Generator loss: 0.7272%]\n",
      "2941 [Discriminator loss: 0.6981%, acc.: 48.83%][Generator loss: 0.7295%]\n",
      "2942 [Discriminator loss: 0.7001%, acc.: 47.27%][Generator loss: 0.7275%]\n",
      "2943 [Discriminator loss: 0.6992%, acc.: 48.83%][Generator loss: 0.7297%]\n",
      "2944 [Discriminator loss: 0.7001%, acc.: 48.05%][Generator loss: 0.7296%]\n",
      "2945 [Discriminator loss: 0.6996%, acc.: 46.09%][Generator loss: 0.7269%]\n",
      "2946 [Discriminator loss: 0.7009%, acc.: 47.66%][Generator loss: 0.7268%]\n",
      "2947 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7294%]\n",
      "2948 [Discriminator loss: 0.6993%, acc.: 47.66%][Generator loss: 0.7267%]\n",
      "2949 [Discriminator loss: 0.7031%, acc.: 41.41%][Generator loss: 0.7271%]\n",
      "2950 [Discriminator loss: 0.6992%, acc.: 48.44%][Generator loss: 0.7271%]\n",
      "2951 [Discriminator loss: 0.6990%, acc.: 49.22%][Generator loss: 0.7265%]\n",
      "2952 [Discriminator loss: 0.6989%, acc.: 45.70%][Generator loss: 0.7275%]\n",
      "2953 [Discriminator loss: 0.6998%, acc.: 47.66%][Generator loss: 0.7288%]\n",
      "2954 [Discriminator loss: 0.6993%, acc.: 49.61%][Generator loss: 0.7280%]\n",
      "2955 [Discriminator loss: 0.6986%, acc.: 49.22%][Generator loss: 0.7278%]\n",
      "2956 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7298%]\n",
      "2957 [Discriminator loss: 0.6990%, acc.: 48.83%][Generator loss: 0.7314%]\n",
      "2958 [Discriminator loss: 0.7021%, acc.: 49.22%][Generator loss: 0.7289%]\n",
      "2959 [Discriminator loss: 0.6987%, acc.: 44.14%][Generator loss: 0.7320%]\n",
      "2960 [Discriminator loss: 0.7008%, acc.: 48.44%][Generator loss: 0.7273%]\n",
      "2961 [Discriminator loss: 0.7000%, acc.: 48.05%][Generator loss: 0.7273%]\n",
      "2962 [Discriminator loss: 0.6993%, acc.: 48.44%][Generator loss: 0.7289%]\n",
      "2963 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7276%]\n",
      "2964 [Discriminator loss: 0.7030%, acc.: 39.45%][Generator loss: 0.7276%]\n",
      "2965 [Discriminator loss: 0.7023%, acc.: 48.44%][Generator loss: 0.7282%]\n",
      "2966 [Discriminator loss: 0.6987%, acc.: 48.83%][Generator loss: 0.7267%]\n",
      "2967 [Discriminator loss: 0.6986%, acc.: 49.22%][Generator loss: 0.7264%]\n",
      "2968 [Discriminator loss: 0.6996%, acc.: 41.80%][Generator loss: 0.7270%]\n",
      "2969 [Discriminator loss: 0.7001%, acc.: 50.39%][Generator loss: 0.7295%]\n",
      "2970 [Discriminator loss: 0.6993%, acc.: 50.00%][Generator loss: 0.7279%]\n",
      "2971 [Discriminator loss: 0.7002%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "2972 [Discriminator loss: 0.6999%, acc.: 48.83%][Generator loss: 0.7290%]\n",
      "2973 [Discriminator loss: 0.7014%, acc.: 48.83%][Generator loss: 0.7288%]\n",
      "2974 [Discriminator loss: 0.7002%, acc.: 48.05%][Generator loss: 0.7282%]\n",
      "2975 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7274%]\n",
      "2976 [Discriminator loss: 0.6983%, acc.: 49.61%][Generator loss: 0.7317%]\n",
      "2977 [Discriminator loss: 0.6995%, acc.: 43.75%][Generator loss: 0.7288%]\n",
      "2978 [Discriminator loss: 0.7000%, acc.: 48.83%][Generator loss: 0.7288%]\n",
      "2979 [Discriminator loss: 0.6995%, acc.: 46.88%][Generator loss: 0.7257%]\n",
      "2980 [Discriminator loss: 0.7000%, acc.: 48.05%][Generator loss: 0.7267%]\n",
      "2981 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7275%]\n",
      "2982 [Discriminator loss: 0.6982%, acc.: 49.22%][Generator loss: 0.7262%]\n",
      "2983 [Discriminator loss: 0.7006%, acc.: 46.09%][Generator loss: 0.7269%]\n",
      "2984 [Discriminator loss: 0.6990%, acc.: 46.88%][Generator loss: 0.7281%]\n",
      "2985 [Discriminator loss: 0.7008%, acc.: 49.61%][Generator loss: 0.7270%]\n",
      "2986 [Discriminator loss: 0.7005%, acc.: 42.19%][Generator loss: 0.7269%]\n",
      "2987 [Discriminator loss: 0.6991%, acc.: 46.09%][Generator loss: 0.7278%]\n",
      "2988 [Discriminator loss: 0.6988%, acc.: 46.48%][Generator loss: 0.7248%]\n",
      "2989 [Discriminator loss: 0.7005%, acc.: 43.75%][Generator loss: 0.7269%]\n",
      "2990 [Discriminator loss: 0.6993%, acc.: 48.05%][Generator loss: 0.7260%]\n",
      "2991 [Discriminator loss: 0.6999%, acc.: 50.00%][Generator loss: 0.7250%]\n",
      "2992 [Discriminator loss: 0.7015%, acc.: 41.80%][Generator loss: 0.7251%]\n",
      "2993 [Discriminator loss: 0.7012%, acc.: 45.31%][Generator loss: 0.7252%]\n",
      "2994 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7268%]\n",
      "2995 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7274%]\n",
      "2996 [Discriminator loss: 0.7002%, acc.: 47.27%][Generator loss: 0.7278%]\n",
      "2997 [Discriminator loss: 0.6995%, acc.: 49.22%][Generator loss: 0.7277%]\n",
      "2998 [Discriminator loss: 0.6985%, acc.: 48.44%][Generator loss: 0.7263%]\n",
      "2999 [Discriminator loss: 0.6993%, acc.: 48.05%][Generator loss: 0.7269%]\n",
      "3000 [Discriminator loss: 0.7004%, acc.: 46.48%][Generator loss: 0.7281%]\n",
      "3001 [Discriminator loss: 0.6999%, acc.: 49.61%][Generator loss: 0.7283%]\n",
      "3002 [Discriminator loss: 0.6990%, acc.: 49.61%][Generator loss: 0.7284%]\n",
      "3003 [Discriminator loss: 0.6983%, acc.: 47.66%][Generator loss: 0.7288%]\n",
      "3004 [Discriminator loss: 0.7010%, acc.: 48.83%][Generator loss: 0.7294%]\n",
      "3005 [Discriminator loss: 0.6995%, acc.: 50.00%][Generator loss: 0.7282%]\n",
      "3006 [Discriminator loss: 0.6993%, acc.: 49.22%][Generator loss: 0.7292%]\n",
      "3007 [Discriminator loss: 0.6987%, acc.: 50.00%][Generator loss: 0.7288%]\n",
      "3008 [Discriminator loss: 0.7004%, acc.: 50.00%][Generator loss: 0.7270%]\n",
      "3009 [Discriminator loss: 0.6997%, acc.: 45.70%][Generator loss: 0.7276%]\n",
      "3010 [Discriminator loss: 0.7001%, acc.: 46.48%][Generator loss: 0.7279%]\n",
      "3011 [Discriminator loss: 0.6984%, acc.: 46.88%][Generator loss: 0.7295%]\n",
      "3012 [Discriminator loss: 0.7008%, acc.: 48.05%][Generator loss: 0.7267%]\n",
      "3013 [Discriminator loss: 0.6985%, acc.: 49.22%][Generator loss: 0.7278%]\n",
      "3014 [Discriminator loss: 0.6998%, acc.: 48.05%][Generator loss: 0.7287%]\n",
      "3015 [Discriminator loss: 0.6999%, acc.: 49.61%][Generator loss: 0.7283%]\n",
      "3016 [Discriminator loss: 0.6981%, acc.: 48.83%][Generator loss: 0.7291%]\n",
      "3017 [Discriminator loss: 0.7006%, acc.: 47.66%][Generator loss: 0.7273%]\n",
      "3018 [Discriminator loss: 0.6994%, acc.: 47.66%][Generator loss: 0.7274%]\n",
      "3019 [Discriminator loss: 0.6979%, acc.: 48.44%][Generator loss: 0.7278%]\n",
      "3020 [Discriminator loss: 0.7014%, acc.: 44.14%][Generator loss: 0.7274%]\n",
      "3021 [Discriminator loss: 0.6997%, acc.: 47.27%][Generator loss: 0.7289%]\n",
      "3022 [Discriminator loss: 0.7000%, acc.: 50.39%][Generator loss: 0.7294%]\n",
      "3023 [Discriminator loss: 0.6993%, acc.: 46.09%][Generator loss: 0.7298%]\n",
      "3024 [Discriminator loss: 0.6994%, acc.: 49.61%][Generator loss: 0.7277%]\n",
      "3025 [Discriminator loss: 0.6993%, acc.: 48.44%][Generator loss: 0.7289%]\n",
      "3026 [Discriminator loss: 0.6998%, acc.: 49.61%][Generator loss: 0.7306%]\n",
      "3027 [Discriminator loss: 0.6997%, acc.: 47.27%][Generator loss: 0.7273%]\n",
      "3028 [Discriminator loss: 0.6993%, acc.: 47.27%][Generator loss: 0.7266%]\n",
      "3029 [Discriminator loss: 0.6980%, acc.: 49.61%][Generator loss: 0.7280%]\n",
      "3030 [Discriminator loss: 0.6986%, acc.: 50.00%][Generator loss: 0.7283%]\n",
      "3031 [Discriminator loss: 0.6995%, acc.: 47.66%][Generator loss: 0.7259%]\n",
      "3032 [Discriminator loss: 0.7021%, acc.: 45.70%][Generator loss: 0.7305%]\n",
      "3033 [Discriminator loss: 0.6987%, acc.: 50.00%][Generator loss: 0.7292%]\n",
      "3034 [Discriminator loss: 0.6996%, acc.: 48.83%][Generator loss: 0.7268%]\n",
      "3035 [Discriminator loss: 0.6979%, acc.: 46.88%][Generator loss: 0.7273%]\n",
      "3036 [Discriminator loss: 0.7000%, acc.: 48.83%][Generator loss: 0.7254%]\n",
      "3037 [Discriminator loss: 0.6988%, acc.: 48.05%][Generator loss: 0.7301%]\n",
      "3038 [Discriminator loss: 0.7016%, acc.: 41.41%][Generator loss: 0.7270%]\n",
      "3039 [Discriminator loss: 0.7000%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3040 [Discriminator loss: 0.6998%, acc.: 49.22%][Generator loss: 0.7263%]\n",
      "3041 [Discriminator loss: 0.7006%, acc.: 50.00%][Generator loss: 0.7273%]\n",
      "3042 [Discriminator loss: 0.6986%, acc.: 48.44%][Generator loss: 0.7264%]\n",
      "3043 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7298%]\n",
      "3044 [Discriminator loss: 0.6993%, acc.: 49.61%][Generator loss: 0.7280%]\n",
      "3045 [Discriminator loss: 0.6994%, acc.: 47.66%][Generator loss: 0.7297%]\n",
      "3046 [Discriminator loss: 0.6987%, acc.: 50.00%][Generator loss: 0.7297%]\n",
      "3047 [Discriminator loss: 0.6999%, acc.: 50.00%][Generator loss: 0.7277%]\n",
      "3048 [Discriminator loss: 0.6991%, acc.: 50.00%][Generator loss: 0.7285%]\n",
      "3049 [Discriminator loss: 0.6988%, acc.: 49.61%][Generator loss: 0.7285%]\n",
      "3050 [Discriminator loss: 0.7003%, acc.: 47.27%][Generator loss: 0.7267%]\n",
      "3051 [Discriminator loss: 0.6998%, acc.: 44.53%][Generator loss: 0.7270%]\n",
      "3052 [Discriminator loss: 0.6998%, acc.: 49.22%][Generator loss: 0.7261%]\n",
      "3053 [Discriminator loss: 0.6984%, acc.: 44.92%][Generator loss: 0.7265%]\n",
      "3054 [Discriminator loss: 0.6981%, acc.: 48.44%][Generator loss: 0.7270%]\n",
      "3055 [Discriminator loss: 0.7000%, acc.: 46.09%][Generator loss: 0.7269%]\n",
      "3056 [Discriminator loss: 0.6993%, acc.: 48.05%][Generator loss: 0.7265%]\n",
      "3057 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7278%]\n",
      "3058 [Discriminator loss: 0.6998%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3059 [Discriminator loss: 0.6993%, acc.: 46.88%][Generator loss: 0.7272%]\n",
      "3060 [Discriminator loss: 0.7003%, acc.: 50.00%][Generator loss: 0.7271%]\n",
      "3061 [Discriminator loss: 0.6998%, acc.: 49.61%][Generator loss: 0.7286%]\n",
      "3062 [Discriminator loss: 0.6998%, acc.: 48.05%][Generator loss: 0.7285%]\n",
      "3063 [Discriminator loss: 0.6999%, acc.: 45.70%][Generator loss: 0.7258%]\n",
      "3064 [Discriminator loss: 0.6991%, acc.: 49.22%][Generator loss: 0.7262%]\n",
      "3065 [Discriminator loss: 0.6982%, acc.: 45.70%][Generator loss: 0.7282%]\n",
      "3066 [Discriminator loss: 0.6991%, acc.: 48.44%][Generator loss: 0.7272%]\n",
      "3067 [Discriminator loss: 0.6987%, acc.: 49.22%][Generator loss: 0.7277%]\n",
      "3068 [Discriminator loss: 0.6995%, acc.: 50.00%][Generator loss: 0.7276%]\n",
      "3069 [Discriminator loss: 0.6992%, acc.: 44.14%][Generator loss: 0.7270%]\n",
      "3070 [Discriminator loss: 0.6997%, acc.: 50.00%][Generator loss: 0.7275%]\n",
      "3071 [Discriminator loss: 0.6984%, acc.: 48.05%][Generator loss: 0.7285%]\n",
      "3072 [Discriminator loss: 0.7019%, acc.: 46.09%][Generator loss: 0.7318%]\n",
      "3073 [Discriminator loss: 0.6999%, acc.: 48.05%][Generator loss: 0.7289%]\n",
      "3074 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7270%]\n",
      "3075 [Discriminator loss: 0.6986%, acc.: 49.22%][Generator loss: 0.7279%]\n",
      "3076 [Discriminator loss: 0.6988%, acc.: 50.39%][Generator loss: 0.7267%]\n",
      "3077 [Discriminator loss: 0.6996%, acc.: 48.83%][Generator loss: 0.7255%]\n",
      "3078 [Discriminator loss: 0.7000%, acc.: 49.22%][Generator loss: 0.7259%]\n",
      "3079 [Discriminator loss: 0.6993%, acc.: 47.66%][Generator loss: 0.7280%]\n",
      "3080 [Discriminator loss: 0.7009%, acc.: 48.83%][Generator loss: 0.7262%]\n",
      "3081 [Discriminator loss: 0.6989%, acc.: 47.27%][Generator loss: 0.7294%]\n",
      "3082 [Discriminator loss: 0.7011%, acc.: 45.31%][Generator loss: 0.7268%]\n",
      "3083 [Discriminator loss: 0.6997%, acc.: 50.00%][Generator loss: 0.7254%]\n",
      "3084 [Discriminator loss: 0.6976%, acc.: 48.44%][Generator loss: 0.7268%]\n",
      "3085 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7290%]\n",
      "3086 [Discriminator loss: 0.6997%, acc.: 50.00%][Generator loss: 0.7261%]\n",
      "3087 [Discriminator loss: 0.6997%, acc.: 50.00%][Generator loss: 0.7292%]\n",
      "3088 [Discriminator loss: 0.6983%, acc.: 47.66%][Generator loss: 0.7265%]\n",
      "3089 [Discriminator loss: 0.6988%, acc.: 48.44%][Generator loss: 0.7272%]\n",
      "3090 [Discriminator loss: 0.6987%, acc.: 50.39%][Generator loss: 0.7266%]\n",
      "3091 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7274%]\n",
      "3092 [Discriminator loss: 0.6994%, acc.: 50.00%][Generator loss: 0.7259%]\n",
      "3093 [Discriminator loss: 0.6985%, acc.: 48.44%][Generator loss: 0.7290%]\n",
      "3094 [Discriminator loss: 0.7020%, acc.: 46.09%][Generator loss: 0.7262%]\n",
      "3095 [Discriminator loss: 0.6993%, acc.: 50.00%][Generator loss: 0.7274%]\n",
      "3096 [Discriminator loss: 0.6998%, acc.: 41.41%][Generator loss: 0.7259%]\n",
      "3097 [Discriminator loss: 0.6999%, acc.: 46.88%][Generator loss: 0.7274%]\n",
      "3098 [Discriminator loss: 0.6988%, acc.: 50.39%][Generator loss: 0.7272%]\n",
      "3099 [Discriminator loss: 0.6987%, acc.: 50.00%][Generator loss: 0.7276%]\n",
      "3100 [Discriminator loss: 0.6976%, acc.: 49.61%][Generator loss: 0.7271%]\n",
      "3101 [Discriminator loss: 0.6986%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3102 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7279%]\n",
      "3103 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7299%]\n",
      "3104 [Discriminator loss: 0.7009%, acc.: 48.44%][Generator loss: 0.7297%]\n",
      "3105 [Discriminator loss: 0.6999%, acc.: 49.61%][Generator loss: 0.7265%]\n",
      "3106 [Discriminator loss: 0.6998%, acc.: 49.22%][Generator loss: 0.7288%]\n",
      "3107 [Discriminator loss: 0.6997%, acc.: 50.39%][Generator loss: 0.7276%]\n",
      "3108 [Discriminator loss: 0.6994%, acc.: 47.27%][Generator loss: 0.7281%]\n",
      "3109 [Discriminator loss: 0.6982%, acc.: 49.22%][Generator loss: 0.7282%]\n",
      "3110 [Discriminator loss: 0.7009%, acc.: 45.31%][Generator loss: 0.7271%]\n",
      "3111 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7262%]\n",
      "3112 [Discriminator loss: 0.6977%, acc.: 49.61%][Generator loss: 0.7254%]\n",
      "3113 [Discriminator loss: 0.6999%, acc.: 45.70%][Generator loss: 0.7249%]\n",
      "3114 [Discriminator loss: 0.7001%, acc.: 49.22%][Generator loss: 0.7271%]\n",
      "3115 [Discriminator loss: 0.6985%, acc.: 47.27%][Generator loss: 0.7284%]\n",
      "3116 [Discriminator loss: 0.6992%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3117 [Discriminator loss: 0.6999%, acc.: 47.27%][Generator loss: 0.7255%]\n",
      "3118 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7280%]\n",
      "3119 [Discriminator loss: 0.6994%, acc.: 43.75%][Generator loss: 0.7252%]\n",
      "3120 [Discriminator loss: 0.6996%, acc.: 46.09%][Generator loss: 0.7263%]\n",
      "3121 [Discriminator loss: 0.6977%, acc.: 47.66%][Generator loss: 0.7266%]\n",
      "3122 [Discriminator loss: 0.6995%, acc.: 46.09%][Generator loss: 0.7261%]\n",
      "3123 [Discriminator loss: 0.6996%, acc.: 50.00%][Generator loss: 0.7313%]\n",
      "3124 [Discriminator loss: 0.7000%, acc.: 50.00%][Generator loss: 0.7263%]\n",
      "3125 [Discriminator loss: 0.6989%, acc.: 48.83%][Generator loss: 0.7267%]\n",
      "3126 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7266%]\n",
      "3127 [Discriminator loss: 0.6992%, acc.: 48.44%][Generator loss: 0.7274%]\n",
      "3128 [Discriminator loss: 0.6993%, acc.: 48.83%][Generator loss: 0.7255%]\n",
      "3129 [Discriminator loss: 0.7006%, acc.: 48.05%][Generator loss: 0.7262%]\n",
      "3130 [Discriminator loss: 0.6971%, acc.: 49.61%][Generator loss: 0.7275%]\n",
      "3131 [Discriminator loss: 0.6993%, acc.: 46.88%][Generator loss: 0.7285%]\n",
      "3132 [Discriminator loss: 0.6993%, acc.: 44.14%][Generator loss: 0.7256%]\n",
      "3133 [Discriminator loss: 0.6996%, acc.: 46.09%][Generator loss: 0.7262%]\n",
      "3134 [Discriminator loss: 0.6986%, acc.: 48.44%][Generator loss: 0.7277%]\n",
      "3135 [Discriminator loss: 0.7004%, acc.: 48.44%][Generator loss: 0.7288%]\n",
      "3136 [Discriminator loss: 0.6993%, acc.: 49.61%][Generator loss: 0.7268%]\n",
      "3137 [Discriminator loss: 0.6993%, acc.: 50.00%][Generator loss: 0.7273%]\n",
      "3138 [Discriminator loss: 0.6983%, acc.: 48.83%][Generator loss: 0.7273%]\n",
      "3139 [Discriminator loss: 0.6970%, acc.: 49.22%][Generator loss: 0.7295%]\n",
      "3140 [Discriminator loss: 0.6998%, acc.: 50.00%][Generator loss: 0.7276%]\n",
      "3141 [Discriminator loss: 0.6995%, acc.: 46.48%][Generator loss: 0.7265%]\n",
      "3142 [Discriminator loss: 0.6995%, acc.: 44.14%][Generator loss: 0.7264%]\n",
      "3143 [Discriminator loss: 0.6982%, acc.: 48.05%][Generator loss: 0.7258%]\n",
      "3144 [Discriminator loss: 0.6979%, acc.: 47.66%][Generator loss: 0.7252%]\n",
      "3145 [Discriminator loss: 0.7001%, acc.: 46.48%][Generator loss: 0.7259%]\n",
      "3146 [Discriminator loss: 0.6992%, acc.: 48.83%][Generator loss: 0.7258%]\n",
      "3147 [Discriminator loss: 0.7008%, acc.: 40.62%][Generator loss: 0.7268%]\n",
      "3148 [Discriminator loss: 0.7005%, acc.: 48.44%][Generator loss: 0.7260%]\n",
      "3149 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7261%]\n",
      "3150 [Discriminator loss: 0.6979%, acc.: 48.44%][Generator loss: 0.7254%]\n",
      "3151 [Discriminator loss: 0.6980%, acc.: 49.22%][Generator loss: 0.7293%]\n",
      "3152 [Discriminator loss: 0.6990%, acc.: 49.22%][Generator loss: 0.7265%]\n",
      "3153 [Discriminator loss: 0.6993%, acc.: 50.00%][Generator loss: 0.7289%]\n",
      "3154 [Discriminator loss: 0.6997%, acc.: 48.83%][Generator loss: 0.7273%]\n",
      "3155 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7274%]\n",
      "3156 [Discriminator loss: 0.6991%, acc.: 50.00%][Generator loss: 0.7287%]\n",
      "3157 [Discriminator loss: 0.6999%, acc.: 48.05%][Generator loss: 0.7280%]\n",
      "3158 [Discriminator loss: 0.6996%, acc.: 49.22%][Generator loss: 0.7262%]\n",
      "3159 [Discriminator loss: 0.6976%, acc.: 49.22%][Generator loss: 0.7263%]\n",
      "3160 [Discriminator loss: 0.6998%, acc.: 48.83%][Generator loss: 0.7268%]\n",
      "3161 [Discriminator loss: 0.7006%, acc.: 44.14%][Generator loss: 0.7261%]\n",
      "3162 [Discriminator loss: 0.7006%, acc.: 49.61%][Generator loss: 0.7277%]\n",
      "3163 [Discriminator loss: 0.6993%, acc.: 47.27%][Generator loss: 0.7255%]\n",
      "3164 [Discriminator loss: 0.6983%, acc.: 49.22%][Generator loss: 0.7270%]\n",
      "3165 [Discriminator loss: 0.6984%, acc.: 48.44%][Generator loss: 0.7260%]\n",
      "3166 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7277%]\n",
      "3167 [Discriminator loss: 0.6994%, acc.: 46.88%][Generator loss: 0.7268%]\n",
      "3168 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7279%]\n",
      "3169 [Discriminator loss: 0.7011%, acc.: 46.48%][Generator loss: 0.7273%]\n",
      "3170 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3171 [Discriminator loss: 0.6990%, acc.: 49.61%][Generator loss: 0.7267%]\n",
      "3172 [Discriminator loss: 0.7003%, acc.: 46.48%][Generator loss: 0.7263%]\n",
      "3173 [Discriminator loss: 0.6986%, acc.: 49.61%][Generator loss: 0.7268%]\n",
      "3174 [Discriminator loss: 0.6974%, acc.: 47.27%][Generator loss: 0.7296%]\n",
      "3175 [Discriminator loss: 0.7001%, acc.: 46.88%][Generator loss: 0.7278%]\n",
      "3176 [Discriminator loss: 0.7000%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3177 [Discriminator loss: 0.6983%, acc.: 49.22%][Generator loss: 0.7292%]\n",
      "3178 [Discriminator loss: 0.6994%, acc.: 48.44%][Generator loss: 0.7276%]\n",
      "3179 [Discriminator loss: 0.6987%, acc.: 48.05%][Generator loss: 0.7269%]\n",
      "3180 [Discriminator loss: 0.6984%, acc.: 49.61%][Generator loss: 0.7283%]\n",
      "3181 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7288%]\n",
      "3182 [Discriminator loss: 0.6994%, acc.: 48.83%][Generator loss: 0.7290%]\n",
      "3183 [Discriminator loss: 0.6997%, acc.: 49.22%][Generator loss: 0.7271%]\n",
      "3184 [Discriminator loss: 0.6987%, acc.: 48.05%][Generator loss: 0.7266%]\n",
      "3185 [Discriminator loss: 0.7001%, acc.: 49.22%][Generator loss: 0.7276%]\n",
      "3186 [Discriminator loss: 0.6987%, acc.: 49.22%][Generator loss: 0.7276%]\n",
      "3187 [Discriminator loss: 0.7003%, acc.: 47.66%][Generator loss: 0.7264%]\n",
      "3188 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7260%]\n",
      "3189 [Discriminator loss: 0.6993%, acc.: 48.83%][Generator loss: 0.7275%]\n",
      "3190 [Discriminator loss: 0.6985%, acc.: 48.83%][Generator loss: 0.7281%]\n",
      "3191 [Discriminator loss: 0.6994%, acc.: 47.27%][Generator loss: 0.7272%]\n",
      "3192 [Discriminator loss: 0.6987%, acc.: 49.22%][Generator loss: 0.7284%]\n",
      "3193 [Discriminator loss: 0.6990%, acc.: 47.27%][Generator loss: 0.7259%]\n",
      "3194 [Discriminator loss: 0.6988%, acc.: 47.66%][Generator loss: 0.7260%]\n",
      "3195 [Discriminator loss: 0.6998%, acc.: 46.88%][Generator loss: 0.7265%]\n",
      "3196 [Discriminator loss: 0.6994%, acc.: 46.09%][Generator loss: 0.7248%]\n",
      "3197 [Discriminator loss: 0.6983%, acc.: 49.61%][Generator loss: 0.7278%]\n",
      "3198 [Discriminator loss: 0.6996%, acc.: 49.22%][Generator loss: 0.7261%]\n",
      "3199 [Discriminator loss: 0.6991%, acc.: 48.44%][Generator loss: 0.7262%]\n",
      "3200 [Discriminator loss: 0.6986%, acc.: 47.66%][Generator loss: 0.7286%]\n",
      "3201 [Discriminator loss: 0.7004%, acc.: 44.92%][Generator loss: 0.7274%]\n",
      "3202 [Discriminator loss: 0.6995%, acc.: 49.61%][Generator loss: 0.7273%]\n",
      "3203 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7281%]\n",
      "3204 [Discriminator loss: 0.6998%, acc.: 49.61%][Generator loss: 0.7318%]\n",
      "3205 [Discriminator loss: 0.7007%, acc.: 50.39%][Generator loss: 0.7270%]\n",
      "3206 [Discriminator loss: 0.6984%, acc.: 49.22%][Generator loss: 0.7281%]\n",
      "3207 [Discriminator loss: 0.6981%, acc.: 48.83%][Generator loss: 0.7269%]\n",
      "3208 [Discriminator loss: 0.6988%, acc.: 46.48%][Generator loss: 0.7266%]\n",
      "3209 [Discriminator loss: 0.7006%, acc.: 48.44%][Generator loss: 0.7279%]\n",
      "3210 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7286%]\n",
      "3211 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3212 [Discriminator loss: 0.7000%, acc.: 47.27%][Generator loss: 0.7285%]\n",
      "3213 [Discriminator loss: 0.7007%, acc.: 48.05%][Generator loss: 0.7263%]\n",
      "3214 [Discriminator loss: 0.6983%, acc.: 42.58%][Generator loss: 0.7269%]\n",
      "3215 [Discriminator loss: 0.6998%, acc.: 48.44%][Generator loss: 0.7260%]\n",
      "3216 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3217 [Discriminator loss: 0.6975%, acc.: 47.27%][Generator loss: 0.7262%]\n",
      "3218 [Discriminator loss: 0.6999%, acc.: 44.53%][Generator loss: 0.7258%]\n",
      "3219 [Discriminator loss: 0.6990%, acc.: 46.48%][Generator loss: 0.7277%]\n",
      "3220 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7262%]\n",
      "3221 [Discriminator loss: 0.7001%, acc.: 43.36%][Generator loss: 0.7319%]\n",
      "3222 [Discriminator loss: 0.7007%, acc.: 45.70%][Generator loss: 0.7296%]\n",
      "3223 [Discriminator loss: 0.6992%, acc.: 50.00%][Generator loss: 0.7264%]\n",
      "3224 [Discriminator loss: 0.6983%, acc.: 49.22%][Generator loss: 0.7262%]\n",
      "3225 [Discriminator loss: 0.6989%, acc.: 49.22%][Generator loss: 0.7257%]\n",
      "3226 [Discriminator loss: 0.6981%, acc.: 48.05%][Generator loss: 0.7279%]\n",
      "3227 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7274%]\n",
      "3228 [Discriminator loss: 0.6987%, acc.: 50.00%][Generator loss: 0.7268%]\n",
      "3229 [Discriminator loss: 0.6983%, acc.: 48.44%][Generator loss: 0.7278%]\n",
      "3230 [Discriminator loss: 0.6983%, acc.: 49.61%][Generator loss: 0.7275%]\n",
      "3231 [Discriminator loss: 0.6993%, acc.: 47.66%][Generator loss: 0.7265%]\n",
      "3232 [Discriminator loss: 0.6997%, acc.: 49.61%][Generator loss: 0.7264%]\n",
      "3233 [Discriminator loss: 0.6982%, acc.: 47.27%][Generator loss: 0.7268%]\n",
      "3234 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7271%]\n",
      "3235 [Discriminator loss: 0.6980%, acc.: 49.61%][Generator loss: 0.7275%]\n",
      "3236 [Discriminator loss: 0.6993%, acc.: 47.66%][Generator loss: 0.7254%]\n",
      "3237 [Discriminator loss: 0.6992%, acc.: 46.09%][Generator loss: 0.7266%]\n",
      "3238 [Discriminator loss: 0.6978%, acc.: 49.61%][Generator loss: 0.7274%]\n",
      "3239 [Discriminator loss: 0.6979%, acc.: 48.83%][Generator loss: 0.7270%]\n",
      "3240 [Discriminator loss: 0.7009%, acc.: 43.75%][Generator loss: 0.7253%]\n",
      "3241 [Discriminator loss: 0.6990%, acc.: 48.44%][Generator loss: 0.7261%]\n",
      "3242 [Discriminator loss: 0.6993%, acc.: 50.39%][Generator loss: 0.7265%]\n",
      "3243 [Discriminator loss: 0.6980%, acc.: 48.05%][Generator loss: 0.7271%]\n",
      "3244 [Discriminator loss: 0.6987%, acc.: 46.88%][Generator loss: 0.7266%]\n",
      "3245 [Discriminator loss: 0.7003%, acc.: 47.66%][Generator loss: 0.7264%]\n",
      "3246 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7263%]\n",
      "3247 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7280%]\n",
      "3248 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7278%]\n",
      "3249 [Discriminator loss: 0.6995%, acc.: 46.48%][Generator loss: 0.7277%]\n",
      "3250 [Discriminator loss: 0.6994%, acc.: 48.44%][Generator loss: 0.7277%]\n",
      "3251 [Discriminator loss: 0.6976%, acc.: 49.22%][Generator loss: 0.7286%]\n",
      "3252 [Discriminator loss: 0.6985%, acc.: 49.61%][Generator loss: 0.7262%]\n",
      "3253 [Discriminator loss: 0.6984%, acc.: 48.05%][Generator loss: 0.7265%]\n",
      "3254 [Discriminator loss: 0.6978%, acc.: 48.05%][Generator loss: 0.7259%]\n",
      "3255 [Discriminator loss: 0.7002%, acc.: 44.14%][Generator loss: 0.7238%]\n",
      "3256 [Discriminator loss: 0.7009%, acc.: 44.53%][Generator loss: 0.7255%]\n",
      "3257 [Discriminator loss: 0.6980%, acc.: 48.44%][Generator loss: 0.7251%]\n",
      "3258 [Discriminator loss: 0.6979%, acc.: 49.61%][Generator loss: 0.7267%]\n",
      "3259 [Discriminator loss: 0.6982%, acc.: 48.44%][Generator loss: 0.7262%]\n",
      "3260 [Discriminator loss: 0.6992%, acc.: 49.22%][Generator loss: 0.7266%]\n",
      "3261 [Discriminator loss: 0.6989%, acc.: 49.22%][Generator loss: 0.7267%]\n",
      "3262 [Discriminator loss: 0.6991%, acc.: 46.48%][Generator loss: 0.7268%]\n",
      "3263 [Discriminator loss: 0.6996%, acc.: 48.05%][Generator loss: 0.7276%]\n",
      "3264 [Discriminator loss: 0.6975%, acc.: 48.44%][Generator loss: 0.7265%]\n",
      "3265 [Discriminator loss: 0.6976%, acc.: 48.05%][Generator loss: 0.7280%]\n",
      "3266 [Discriminator loss: 0.6985%, acc.: 51.17%][Generator loss: 0.7267%]\n",
      "3267 [Discriminator loss: 0.6988%, acc.: 48.44%][Generator loss: 0.7276%]\n",
      "3268 [Discriminator loss: 0.6980%, acc.: 49.61%][Generator loss: 0.7264%]\n",
      "3269 [Discriminator loss: 0.6991%, acc.: 50.00%][Generator loss: 0.7306%]\n",
      "3270 [Discriminator loss: 0.7001%, acc.: 47.66%][Generator loss: 0.7294%]\n",
      "3271 [Discriminator loss: 0.7002%, acc.: 50.00%][Generator loss: 0.7260%]\n",
      "3272 [Discriminator loss: 0.7006%, acc.: 46.09%][Generator loss: 0.7264%]\n",
      "3273 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7252%]\n",
      "3274 [Discriminator loss: 0.6975%, acc.: 49.61%][Generator loss: 0.7262%]\n",
      "3275 [Discriminator loss: 0.6983%, acc.: 48.05%][Generator loss: 0.7268%]\n",
      "3276 [Discriminator loss: 0.6989%, acc.: 48.83%][Generator loss: 0.7264%]\n",
      "3277 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7258%]\n",
      "3278 [Discriminator loss: 0.7000%, acc.: 42.19%][Generator loss: 0.7267%]\n",
      "3279 [Discriminator loss: 0.6984%, acc.: 48.05%][Generator loss: 0.7255%]\n",
      "3280 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7260%]\n",
      "3281 [Discriminator loss: 0.6973%, acc.: 49.22%][Generator loss: 0.7280%]\n",
      "3282 [Discriminator loss: 0.7003%, acc.: 50.39%][Generator loss: 0.7257%]\n",
      "3283 [Discriminator loss: 0.6985%, acc.: 45.70%][Generator loss: 0.7265%]\n",
      "3284 [Discriminator loss: 0.6982%, acc.: 48.83%][Generator loss: 0.7272%]\n",
      "3285 [Discriminator loss: 0.6991%, acc.: 48.83%][Generator loss: 0.7266%]\n",
      "3286 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7268%]\n",
      "3287 [Discriminator loss: 0.6988%, acc.: 46.88%][Generator loss: 0.7281%]\n",
      "3288 [Discriminator loss: 0.6992%, acc.: 49.22%][Generator loss: 0.7279%]\n",
      "3289 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7254%]\n",
      "3290 [Discriminator loss: 0.6978%, acc.: 46.88%][Generator loss: 0.7269%]\n",
      "3291 [Discriminator loss: 0.6999%, acc.: 47.66%][Generator loss: 0.7268%]\n",
      "3292 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3293 [Discriminator loss: 0.6985%, acc.: 48.05%][Generator loss: 0.7256%]\n",
      "3294 [Discriminator loss: 0.6982%, acc.: 48.44%][Generator loss: 0.7289%]\n",
      "3295 [Discriminator loss: 0.7000%, acc.: 50.00%][Generator loss: 0.7273%]\n",
      "3296 [Discriminator loss: 0.6982%, acc.: 48.83%][Generator loss: 0.7276%]\n",
      "3297 [Discriminator loss: 0.6993%, acc.: 48.83%][Generator loss: 0.7259%]\n",
      "3298 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7277%]\n",
      "3299 [Discriminator loss: 0.6998%, acc.: 50.00%][Generator loss: 0.7278%]\n",
      "3300 [Discriminator loss: 0.6995%, acc.: 47.66%][Generator loss: 0.7276%]\n",
      "3301 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7257%]\n",
      "3302 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7278%]\n",
      "3303 [Discriminator loss: 0.6980%, acc.: 48.83%][Generator loss: 0.7277%]\n",
      "3304 [Discriminator loss: 0.6983%, acc.: 47.66%][Generator loss: 0.7255%]\n",
      "3305 [Discriminator loss: 0.6993%, acc.: 49.61%][Generator loss: 0.7252%]\n",
      "3306 [Discriminator loss: 0.6978%, acc.: 49.22%][Generator loss: 0.7273%]\n",
      "3307 [Discriminator loss: 0.6988%, acc.: 48.44%][Generator loss: 0.7261%]\n",
      "3308 [Discriminator loss: 0.6989%, acc.: 47.27%][Generator loss: 0.7256%]\n",
      "3309 [Discriminator loss: 0.6996%, acc.: 48.44%][Generator loss: 0.7265%]\n",
      "3310 [Discriminator loss: 0.6986%, acc.: 50.00%][Generator loss: 0.7258%]\n",
      "3311 [Discriminator loss: 0.6976%, acc.: 49.61%][Generator loss: 0.7255%]\n",
      "3312 [Discriminator loss: 0.6989%, acc.: 48.44%][Generator loss: 0.7269%]\n",
      "3313 [Discriminator loss: 0.6999%, acc.: 48.05%][Generator loss: 0.7254%]\n",
      "3314 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7272%]\n",
      "3315 [Discriminator loss: 0.7003%, acc.: 47.66%][Generator loss: 0.7279%]\n",
      "3316 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7294%]\n",
      "3317 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7273%]\n",
      "3318 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7263%]\n",
      "3319 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7270%]\n",
      "3320 [Discriminator loss: 0.6982%, acc.: 48.44%][Generator loss: 0.7267%]\n",
      "3321 [Discriminator loss: 0.6988%, acc.: 49.22%][Generator loss: 0.7273%]\n",
      "3322 [Discriminator loss: 0.6985%, acc.: 49.61%][Generator loss: 0.7277%]\n",
      "3323 [Discriminator loss: 0.6991%, acc.: 48.44%][Generator loss: 0.7258%]\n",
      "3324 [Discriminator loss: 0.7000%, acc.: 46.88%][Generator loss: 0.7275%]\n",
      "3325 [Discriminator loss: 0.6987%, acc.: 49.22%][Generator loss: 0.7255%]\n",
      "3326 [Discriminator loss: 0.6976%, acc.: 47.66%][Generator loss: 0.7270%]\n",
      "3327 [Discriminator loss: 0.6989%, acc.: 45.70%][Generator loss: 0.7279%]\n",
      "3328 [Discriminator loss: 0.7000%, acc.: 47.66%][Generator loss: 0.7265%]\n",
      "3329 [Discriminator loss: 0.6995%, acc.: 46.88%][Generator loss: 0.7259%]\n",
      "3330 [Discriminator loss: 0.6984%, acc.: 49.61%][Generator loss: 0.7258%]\n",
      "3331 [Discriminator loss: 0.6976%, acc.: 49.61%][Generator loss: 0.7264%]\n",
      "3332 [Discriminator loss: 0.6993%, acc.: 49.61%][Generator loss: 0.7263%]\n",
      "3333 [Discriminator loss: 0.7005%, acc.: 49.22%][Generator loss: 0.7256%]\n",
      "3334 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7282%]\n",
      "3335 [Discriminator loss: 0.6989%, acc.: 44.53%][Generator loss: 0.7261%]\n",
      "3336 [Discriminator loss: 0.6986%, acc.: 50.00%][Generator loss: 0.7248%]\n",
      "3337 [Discriminator loss: 0.6992%, acc.: 45.31%][Generator loss: 0.7259%]\n",
      "3338 [Discriminator loss: 0.7002%, acc.: 48.83%][Generator loss: 0.7255%]\n",
      "3339 [Discriminator loss: 0.6975%, acc.: 46.48%][Generator loss: 0.7260%]\n",
      "3340 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7260%]\n",
      "3341 [Discriminator loss: 0.6970%, acc.: 47.66%][Generator loss: 0.7276%]\n",
      "3342 [Discriminator loss: 0.7007%, acc.: 46.09%][Generator loss: 0.7252%]\n",
      "3343 [Discriminator loss: 0.6997%, acc.: 49.22%][Generator loss: 0.7261%]\n",
      "3344 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7263%]\n",
      "3345 [Discriminator loss: 0.6991%, acc.: 48.05%][Generator loss: 0.7284%]\n",
      "3346 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7272%]\n",
      "3347 [Discriminator loss: 0.6992%, acc.: 46.09%][Generator loss: 0.7253%]\n",
      "3348 [Discriminator loss: 0.7004%, acc.: 45.31%][Generator loss: 0.7253%]\n",
      "3349 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3350 [Discriminator loss: 0.6977%, acc.: 49.61%][Generator loss: 0.7250%]\n",
      "3351 [Discriminator loss: 0.6987%, acc.: 45.70%][Generator loss: 0.7273%]\n",
      "3352 [Discriminator loss: 0.6986%, acc.: 48.44%][Generator loss: 0.7262%]\n",
      "3353 [Discriminator loss: 0.6979%, acc.: 46.48%][Generator loss: 0.7264%]\n",
      "3354 [Discriminator loss: 0.6991%, acc.: 44.92%][Generator loss: 0.7274%]\n",
      "3355 [Discriminator loss: 0.6999%, acc.: 47.27%][Generator loss: 0.7260%]\n",
      "3356 [Discriminator loss: 0.7000%, acc.: 48.05%][Generator loss: 0.7276%]\n",
      "3357 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7285%]\n",
      "3358 [Discriminator loss: 0.6985%, acc.: 49.61%][Generator loss: 0.7268%]\n",
      "3359 [Discriminator loss: 0.6980%, acc.: 48.44%][Generator loss: 0.7267%]\n",
      "3360 [Discriminator loss: 0.6973%, acc.: 46.88%][Generator loss: 0.7271%]\n",
      "3361 [Discriminator loss: 0.6983%, acc.: 48.44%][Generator loss: 0.7254%]\n",
      "3362 [Discriminator loss: 0.6990%, acc.: 42.97%][Generator loss: 0.7260%]\n",
      "3363 [Discriminator loss: 0.6989%, acc.: 50.00%][Generator loss: 0.7273%]\n",
      "3364 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3365 [Discriminator loss: 0.6970%, acc.: 49.22%][Generator loss: 0.7271%]\n",
      "3366 [Discriminator loss: 0.6998%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3367 [Discriminator loss: 0.6986%, acc.: 48.44%][Generator loss: 0.7274%]\n",
      "3368 [Discriminator loss: 0.6989%, acc.: 50.00%][Generator loss: 0.7277%]\n",
      "3369 [Discriminator loss: 0.6996%, acc.: 47.66%][Generator loss: 0.7296%]\n",
      "3370 [Discriminator loss: 0.6983%, acc.: 49.61%][Generator loss: 0.7268%]\n",
      "3371 [Discriminator loss: 0.6977%, acc.: 49.61%][Generator loss: 0.7268%]\n",
      "3372 [Discriminator loss: 0.6977%, acc.: 49.22%][Generator loss: 0.7259%]\n",
      "3373 [Discriminator loss: 0.6979%, acc.: 47.27%][Generator loss: 0.7258%]\n",
      "3374 [Discriminator loss: 0.6983%, acc.: 48.83%][Generator loss: 0.7276%]\n",
      "3375 [Discriminator loss: 0.6984%, acc.: 46.88%][Generator loss: 0.7286%]\n",
      "3376 [Discriminator loss: 0.7003%, acc.: 51.56%][Generator loss: 0.7266%]\n",
      "3377 [Discriminator loss: 0.6988%, acc.: 47.27%][Generator loss: 0.7259%]\n",
      "3378 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7264%]\n",
      "3379 [Discriminator loss: 0.6989%, acc.: 45.70%][Generator loss: 0.7257%]\n",
      "3380 [Discriminator loss: 0.6999%, acc.: 42.58%][Generator loss: 0.7254%]\n",
      "3381 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7283%]\n",
      "3382 [Discriminator loss: 0.6989%, acc.: 49.61%][Generator loss: 0.7258%]\n",
      "3383 [Discriminator loss: 0.6979%, acc.: 48.83%][Generator loss: 0.7261%]\n",
      "3384 [Discriminator loss: 0.6995%, acc.: 47.27%][Generator loss: 0.7273%]\n",
      "3385 [Discriminator loss: 0.7005%, acc.: 50.00%][Generator loss: 0.7251%]\n",
      "3386 [Discriminator loss: 0.6960%, acc.: 48.44%][Generator loss: 0.7265%]\n",
      "3387 [Discriminator loss: 0.6984%, acc.: 51.17%][Generator loss: 0.7251%]\n",
      "3388 [Discriminator loss: 0.6975%, acc.: 44.92%][Generator loss: 0.7277%]\n",
      "3389 [Discriminator loss: 0.6988%, acc.: 48.83%][Generator loss: 0.7275%]\n",
      "3390 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3391 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7272%]\n",
      "3392 [Discriminator loss: 0.6969%, acc.: 49.22%][Generator loss: 0.7266%]\n",
      "3393 [Discriminator loss: 0.6999%, acc.: 46.48%][Generator loss: 0.7265%]\n",
      "3394 [Discriminator loss: 0.6991%, acc.: 45.31%][Generator loss: 0.7273%]\n",
      "3395 [Discriminator loss: 0.6991%, acc.: 49.22%][Generator loss: 0.7267%]\n",
      "3396 [Discriminator loss: 0.6986%, acc.: 49.22%][Generator loss: 0.7259%]\n",
      "3397 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7269%]\n",
      "3398 [Discriminator loss: 0.6999%, acc.: 46.09%][Generator loss: 0.7253%]\n",
      "3399 [Discriminator loss: 0.6992%, acc.: 49.22%][Generator loss: 0.7252%]\n",
      "3400 [Discriminator loss: 0.6979%, acc.: 50.39%][Generator loss: 0.7258%]\n",
      "3401 [Discriminator loss: 0.6976%, acc.: 48.83%][Generator loss: 0.7263%]\n",
      "3402 [Discriminator loss: 0.6985%, acc.: 47.66%][Generator loss: 0.7243%]\n",
      "3403 [Discriminator loss: 0.7007%, acc.: 43.75%][Generator loss: 0.7256%]\n",
      "3404 [Discriminator loss: 0.6989%, acc.: 49.22%][Generator loss: 0.7263%]\n",
      "3405 [Discriminator loss: 0.6991%, acc.: 47.66%][Generator loss: 0.7257%]\n",
      "3406 [Discriminator loss: 0.6980%, acc.: 49.22%][Generator loss: 0.7267%]\n",
      "3407 [Discriminator loss: 0.6978%, acc.: 48.05%][Generator loss: 0.7248%]\n",
      "3408 [Discriminator loss: 0.6991%, acc.: 48.83%][Generator loss: 0.7283%]\n",
      "3409 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3410 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7244%]\n",
      "3411 [Discriminator loss: 0.6976%, acc.: 49.22%][Generator loss: 0.7266%]\n",
      "3412 [Discriminator loss: 0.6985%, acc.: 49.61%][Generator loss: 0.7267%]\n",
      "3413 [Discriminator loss: 0.6987%, acc.: 48.05%][Generator loss: 0.7267%]\n",
      "3414 [Discriminator loss: 0.6984%, acc.: 48.83%][Generator loss: 0.7263%]\n",
      "3415 [Discriminator loss: 0.6986%, acc.: 49.61%][Generator loss: 0.7253%]\n",
      "3416 [Discriminator loss: 0.6978%, acc.: 47.27%][Generator loss: 0.7263%]\n",
      "3417 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7271%]\n",
      "3418 [Discriminator loss: 0.6999%, acc.: 46.09%][Generator loss: 0.7256%]\n",
      "3419 [Discriminator loss: 0.6988%, acc.: 47.66%][Generator loss: 0.7252%]\n",
      "3420 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7244%]\n",
      "3421 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7256%]\n",
      "3422 [Discriminator loss: 0.6997%, acc.: 44.92%][Generator loss: 0.7256%]\n",
      "3423 [Discriminator loss: 0.6982%, acc.: 46.88%][Generator loss: 0.7283%]\n",
      "3424 [Discriminator loss: 0.6993%, acc.: 49.22%][Generator loss: 0.7256%]\n",
      "3425 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7273%]\n",
      "3426 [Discriminator loss: 0.6987%, acc.: 48.83%][Generator loss: 0.7258%]\n",
      "3427 [Discriminator loss: 0.6970%, acc.: 48.83%][Generator loss: 0.7274%]\n",
      "3428 [Discriminator loss: 0.6984%, acc.: 48.44%][Generator loss: 0.7262%]\n",
      "3429 [Discriminator loss: 0.6978%, acc.: 49.61%][Generator loss: 0.7258%]\n",
      "3430 [Discriminator loss: 0.6970%, acc.: 49.22%][Generator loss: 0.7278%]\n",
      "3431 [Discriminator loss: 0.6993%, acc.: 45.70%][Generator loss: 0.7278%]\n",
      "3432 [Discriminator loss: 0.7000%, acc.: 49.61%][Generator loss: 0.7259%]\n",
      "3433 [Discriminator loss: 0.6983%, acc.: 47.66%][Generator loss: 0.7262%]\n",
      "3434 [Discriminator loss: 0.6994%, acc.: 50.00%][Generator loss: 0.7260%]\n",
      "3435 [Discriminator loss: 0.6991%, acc.: 47.66%][Generator loss: 0.7246%]\n",
      "3436 [Discriminator loss: 0.6977%, acc.: 49.22%][Generator loss: 0.7280%]\n",
      "3437 [Discriminator loss: 0.6995%, acc.: 48.44%][Generator loss: 0.7259%]\n",
      "3438 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7271%]\n",
      "3439 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7258%]\n",
      "3440 [Discriminator loss: 0.6990%, acc.: 47.66%][Generator loss: 0.7245%]\n",
      "3441 [Discriminator loss: 0.6995%, acc.: 46.09%][Generator loss: 0.7246%]\n",
      "3442 [Discriminator loss: 0.6980%, acc.: 46.09%][Generator loss: 0.7261%]\n",
      "3443 [Discriminator loss: 0.6983%, acc.: 49.61%][Generator loss: 0.7305%]\n",
      "3444 [Discriminator loss: 0.6987%, acc.: 49.61%][Generator loss: 0.7260%]\n",
      "3445 [Discriminator loss: 0.6975%, acc.: 48.83%][Generator loss: 0.7246%]\n",
      "3446 [Discriminator loss: 0.6989%, acc.: 49.61%][Generator loss: 0.7239%]\n",
      "3447 [Discriminator loss: 0.6985%, acc.: 49.61%][Generator loss: 0.7257%]\n",
      "3448 [Discriminator loss: 0.6996%, acc.: 50.00%][Generator loss: 0.7244%]\n",
      "3449 [Discriminator loss: 0.6978%, acc.: 49.22%][Generator loss: 0.7258%]\n",
      "3450 [Discriminator loss: 0.6977%, acc.: 49.22%][Generator loss: 0.7266%]\n",
      "3451 [Discriminator loss: 0.6979%, acc.: 43.75%][Generator loss: 0.7298%]\n",
      "3452 [Discriminator loss: 0.7004%, acc.: 47.27%][Generator loss: 0.7261%]\n",
      "3453 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7280%]\n",
      "3454 [Discriminator loss: 0.6989%, acc.: 48.44%][Generator loss: 0.7257%]\n",
      "3455 [Discriminator loss: 0.6976%, acc.: 49.22%][Generator loss: 0.7260%]\n",
      "3456 [Discriminator loss: 0.6968%, acc.: 48.44%][Generator loss: 0.7267%]\n",
      "3457 [Discriminator loss: 0.6980%, acc.: 46.88%][Generator loss: 0.7257%]\n",
      "3458 [Discriminator loss: 0.6989%, acc.: 48.44%][Generator loss: 0.7293%]\n",
      "3459 [Discriminator loss: 0.7008%, acc.: 50.00%][Generator loss: 0.7259%]\n",
      "3460 [Discriminator loss: 0.6983%, acc.: 49.61%][Generator loss: 0.7265%]\n",
      "3461 [Discriminator loss: 0.6983%, acc.: 48.44%][Generator loss: 0.7270%]\n",
      "3462 [Discriminator loss: 0.6990%, acc.: 49.22%][Generator loss: 0.7258%]\n",
      "3463 [Discriminator loss: 0.6982%, acc.: 47.66%][Generator loss: 0.7251%]\n",
      "3464 [Discriminator loss: 0.6968%, acc.: 48.44%][Generator loss: 0.7270%]\n",
      "3465 [Discriminator loss: 0.7000%, acc.: 45.31%][Generator loss: 0.7234%]\n",
      "3466 [Discriminator loss: 0.6979%, acc.: 48.44%][Generator loss: 0.7275%]\n",
      "3467 [Discriminator loss: 0.6999%, acc.: 50.00%][Generator loss: 0.7253%]\n",
      "3468 [Discriminator loss: 0.6985%, acc.: 48.83%][Generator loss: 0.7263%]\n",
      "3469 [Discriminator loss: 0.6981%, acc.: 47.66%][Generator loss: 0.7254%]\n",
      "3470 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7261%]\n",
      "3471 [Discriminator loss: 0.6983%, acc.: 46.88%][Generator loss: 0.7285%]\n",
      "3472 [Discriminator loss: 0.6978%, acc.: 50.39%][Generator loss: 0.7282%]\n",
      "3473 [Discriminator loss: 0.6981%, acc.: 50.39%][Generator loss: 0.7261%]\n",
      "3474 [Discriminator loss: 0.6988%, acc.: 48.44%][Generator loss: 0.7286%]\n",
      "3475 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7268%]\n",
      "3476 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7263%]\n",
      "3477 [Discriminator loss: 0.6980%, acc.: 49.22%][Generator loss: 0.7279%]\n",
      "3478 [Discriminator loss: 0.6971%, acc.: 49.22%][Generator loss: 0.7273%]\n",
      "3479 [Discriminator loss: 0.6978%, acc.: 47.66%][Generator loss: 0.7271%]\n",
      "3480 [Discriminator loss: 0.6994%, acc.: 44.92%][Generator loss: 0.7258%]\n",
      "3481 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7276%]\n",
      "3482 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7276%]\n",
      "3483 [Discriminator loss: 0.6979%, acc.: 49.61%][Generator loss: 0.7292%]\n",
      "3484 [Discriminator loss: 0.6995%, acc.: 48.83%][Generator loss: 0.7264%]\n",
      "3485 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7271%]\n",
      "3486 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7260%]\n",
      "3487 [Discriminator loss: 0.6986%, acc.: 43.75%][Generator loss: 0.7250%]\n",
      "3488 [Discriminator loss: 0.6976%, acc.: 49.61%][Generator loss: 0.7271%]\n",
      "3489 [Discriminator loss: 0.6997%, acc.: 48.05%][Generator loss: 0.7268%]\n",
      "3490 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7283%]\n",
      "3491 [Discriminator loss: 0.6982%, acc.: 50.78%][Generator loss: 0.7262%]\n",
      "3492 [Discriminator loss: 0.6992%, acc.: 45.31%][Generator loss: 0.7258%]\n",
      "3493 [Discriminator loss: 0.6994%, acc.: 48.83%][Generator loss: 0.7258%]\n",
      "3494 [Discriminator loss: 0.6971%, acc.: 48.83%][Generator loss: 0.7253%]\n",
      "3495 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7264%]\n",
      "3496 [Discriminator loss: 0.6993%, acc.: 46.09%][Generator loss: 0.7254%]\n",
      "3497 [Discriminator loss: 0.6981%, acc.: 49.22%][Generator loss: 0.7268%]\n",
      "3498 [Discriminator loss: 0.6997%, acc.: 46.88%][Generator loss: 0.7248%]\n",
      "3499 [Discriminator loss: 0.6998%, acc.: 49.61%][Generator loss: 0.7265%]\n",
      "3500 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7256%]\n",
      "3501 [Discriminator loss: 0.6977%, acc.: 47.66%][Generator loss: 0.7273%]\n",
      "3502 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7256%]\n",
      "3503 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7259%]\n",
      "3504 [Discriminator loss: 0.7005%, acc.: 43.36%][Generator loss: 0.7257%]\n",
      "3505 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3506 [Discriminator loss: 0.6973%, acc.: 48.44%][Generator loss: 0.7258%]\n",
      "3507 [Discriminator loss: 0.6977%, acc.: 48.44%][Generator loss: 0.7239%]\n",
      "3508 [Discriminator loss: 0.6982%, acc.: 47.27%][Generator loss: 0.7263%]\n",
      "3509 [Discriminator loss: 0.6984%, acc.: 49.61%][Generator loss: 0.7267%]\n",
      "3510 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7256%]\n",
      "3511 [Discriminator loss: 0.6983%, acc.: 49.22%][Generator loss: 0.7257%]\n",
      "3512 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7251%]\n",
      "3513 [Discriminator loss: 0.6981%, acc.: 48.44%][Generator loss: 0.7246%]\n",
      "3514 [Discriminator loss: 0.6973%, acc.: 49.22%][Generator loss: 0.7263%]\n",
      "3515 [Discriminator loss: 0.6978%, acc.: 48.83%][Generator loss: 0.7269%]\n",
      "3516 [Discriminator loss: 0.6984%, acc.: 49.61%][Generator loss: 0.7258%]\n",
      "3517 [Discriminator loss: 0.6977%, acc.: 48.83%][Generator loss: 0.7278%]\n",
      "3518 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7271%]\n",
      "3519 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7270%]\n",
      "3520 [Discriminator loss: 0.6987%, acc.: 50.39%][Generator loss: 0.7251%]\n",
      "3521 [Discriminator loss: 0.6977%, acc.: 50.39%][Generator loss: 0.7266%]\n",
      "3522 [Discriminator loss: 0.6990%, acc.: 50.00%][Generator loss: 0.7251%]\n",
      "3523 [Discriminator loss: 0.6984%, acc.: 45.70%][Generator loss: 0.7257%]\n",
      "3524 [Discriminator loss: 0.6993%, acc.: 48.05%][Generator loss: 0.7256%]\n",
      "3525 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7272%]\n",
      "3526 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7269%]\n",
      "3527 [Discriminator loss: 0.6994%, acc.: 50.39%][Generator loss: 0.7261%]\n",
      "3528 [Discriminator loss: 0.6994%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3529 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7253%]\n",
      "3530 [Discriminator loss: 0.6973%, acc.: 47.27%][Generator loss: 0.7248%]\n",
      "3531 [Discriminator loss: 0.6974%, acc.: 48.44%][Generator loss: 0.7258%]\n",
      "3532 [Discriminator loss: 0.6993%, acc.: 48.44%][Generator loss: 0.7256%]\n",
      "3533 [Discriminator loss: 0.6987%, acc.: 50.00%][Generator loss: 0.7258%]\n",
      "3534 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7273%]\n",
      "3535 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7268%]\n",
      "3536 [Discriminator loss: 0.6977%, acc.: 49.61%][Generator loss: 0.7263%]\n",
      "3537 [Discriminator loss: 0.6983%, acc.: 49.22%][Generator loss: 0.7253%]\n",
      "3538 [Discriminator loss: 0.6998%, acc.: 49.22%][Generator loss: 0.7254%]\n",
      "3539 [Discriminator loss: 0.6985%, acc.: 46.48%][Generator loss: 0.7252%]\n",
      "3540 [Discriminator loss: 0.6970%, acc.: 50.39%][Generator loss: 0.7236%]\n",
      "3541 [Discriminator loss: 0.6974%, acc.: 48.05%][Generator loss: 0.7257%]\n",
      "3542 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3543 [Discriminator loss: 0.6983%, acc.: 49.22%][Generator loss: 0.7273%]\n",
      "3544 [Discriminator loss: 0.6994%, acc.: 50.78%][Generator loss: 0.7273%]\n",
      "3545 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7258%]\n",
      "3546 [Discriminator loss: 0.6980%, acc.: 48.83%][Generator loss: 0.7276%]\n",
      "3547 [Discriminator loss: 0.6987%, acc.: 50.00%][Generator loss: 0.7264%]\n",
      "3548 [Discriminator loss: 0.6991%, acc.: 49.22%][Generator loss: 0.7245%]\n",
      "3549 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7299%]\n",
      "3550 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7277%]\n",
      "3551 [Discriminator loss: 0.6993%, acc.: 49.22%][Generator loss: 0.7265%]\n",
      "3552 [Discriminator loss: 0.6972%, acc.: 48.05%][Generator loss: 0.7258%]\n",
      "3553 [Discriminator loss: 0.6987%, acc.: 49.22%][Generator loss: 0.7272%]\n",
      "3554 [Discriminator loss: 0.6992%, acc.: 44.92%][Generator loss: 0.7240%]\n",
      "3555 [Discriminator loss: 0.6976%, acc.: 48.83%][Generator loss: 0.7267%]\n",
      "3556 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7259%]\n",
      "3557 [Discriminator loss: 0.6981%, acc.: 48.83%][Generator loss: 0.7269%]\n",
      "3558 [Discriminator loss: 0.6999%, acc.: 48.83%][Generator loss: 0.7239%]\n",
      "3559 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7264%]\n",
      "3560 [Discriminator loss: 0.6974%, acc.: 49.22%][Generator loss: 0.7252%]\n",
      "3561 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3562 [Discriminator loss: 0.6991%, acc.: 47.66%][Generator loss: 0.7249%]\n",
      "3563 [Discriminator loss: 0.6988%, acc.: 47.27%][Generator loss: 0.7257%]\n",
      "3564 [Discriminator loss: 0.6969%, acc.: 49.61%][Generator loss: 0.7270%]\n",
      "3565 [Discriminator loss: 0.6988%, acc.: 46.48%][Generator loss: 0.7267%]\n",
      "3566 [Discriminator loss: 0.6995%, acc.: 48.83%][Generator loss: 0.7236%]\n",
      "3567 [Discriminator loss: 0.6980%, acc.: 44.53%][Generator loss: 0.7264%]\n",
      "3568 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7244%]\n",
      "3569 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7251%]\n",
      "3570 [Discriminator loss: 0.6975%, acc.: 49.61%][Generator loss: 0.7247%]\n",
      "3571 [Discriminator loss: 0.6970%, acc.: 49.61%][Generator loss: 0.7250%]\n",
      "3572 [Discriminator loss: 0.6982%, acc.: 49.61%][Generator loss: 0.7245%]\n",
      "3573 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3574 [Discriminator loss: 0.6975%, acc.: 48.05%][Generator loss: 0.7293%]\n",
      "3575 [Discriminator loss: 0.6988%, acc.: 49.22%][Generator loss: 0.7293%]\n",
      "3576 [Discriminator loss: 0.6986%, acc.: 50.00%][Generator loss: 0.7277%]\n",
      "3577 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7266%]\n",
      "3578 [Discriminator loss: 0.6983%, acc.: 47.66%][Generator loss: 0.7251%]\n",
      "3579 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7257%]\n",
      "3580 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7257%]\n",
      "3581 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7262%]\n",
      "3582 [Discriminator loss: 0.6984%, acc.: 49.61%][Generator loss: 0.7253%]\n",
      "3583 [Discriminator loss: 0.6987%, acc.: 49.22%][Generator loss: 0.7262%]\n",
      "3584 [Discriminator loss: 0.6980%, acc.: 48.05%][Generator loss: 0.7256%]\n",
      "3585 [Discriminator loss: 0.6971%, acc.: 48.83%][Generator loss: 0.7273%]\n",
      "3586 [Discriminator loss: 0.6995%, acc.: 49.22%][Generator loss: 0.7271%]\n",
      "3587 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7275%]\n",
      "3588 [Discriminator loss: 0.6993%, acc.: 48.83%][Generator loss: 0.7251%]\n",
      "3589 [Discriminator loss: 0.6985%, acc.: 49.61%][Generator loss: 0.7268%]\n",
      "3590 [Discriminator loss: 0.6981%, acc.: 47.66%][Generator loss: 0.7255%]\n",
      "3591 [Discriminator loss: 0.6979%, acc.: 49.22%][Generator loss: 0.7283%]\n",
      "3592 [Discriminator loss: 0.6985%, acc.: 50.39%][Generator loss: 0.7251%]\n",
      "3593 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7292%]\n",
      "3594 [Discriminator loss: 0.6999%, acc.: 49.61%][Generator loss: 0.7275%]\n",
      "3595 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3596 [Discriminator loss: 0.6978%, acc.: 48.05%][Generator loss: 0.7253%]\n",
      "3597 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3598 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7258%]\n",
      "3599 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7266%]\n",
      "3600 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7247%]\n",
      "3601 [Discriminator loss: 0.6981%, acc.: 49.61%][Generator loss: 0.7248%]\n",
      "3602 [Discriminator loss: 0.6975%, acc.: 49.61%][Generator loss: 0.7267%]\n",
      "3603 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7260%]\n",
      "3604 [Discriminator loss: 0.6989%, acc.: 50.00%][Generator loss: 0.7261%]\n",
      "3605 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7263%]\n",
      "3606 [Discriminator loss: 0.6979%, acc.: 49.61%][Generator loss: 0.7243%]\n",
      "3607 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3608 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7281%]\n",
      "3609 [Discriminator loss: 0.6984%, acc.: 46.09%][Generator loss: 0.7273%]\n",
      "3610 [Discriminator loss: 0.6978%, acc.: 46.88%][Generator loss: 0.7257%]\n",
      "3611 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7258%]\n",
      "3612 [Discriminator loss: 0.6973%, acc.: 45.70%][Generator loss: 0.7269%]\n",
      "3613 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7269%]\n",
      "3614 [Discriminator loss: 0.6976%, acc.: 49.61%][Generator loss: 0.7260%]\n",
      "3615 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7257%]\n",
      "3616 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7254%]\n",
      "3617 [Discriminator loss: 0.6981%, acc.: 47.27%][Generator loss: 0.7250%]\n",
      "3618 [Discriminator loss: 0.6994%, acc.: 46.88%][Generator loss: 0.7252%]\n",
      "3619 [Discriminator loss: 0.6979%, acc.: 48.44%][Generator loss: 0.7254%]\n",
      "3620 [Discriminator loss: 0.6972%, acc.: 49.61%][Generator loss: 0.7262%]\n",
      "3621 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7283%]\n",
      "3622 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7256%]\n",
      "3623 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7264%]\n",
      "3624 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7251%]\n",
      "3625 [Discriminator loss: 0.6984%, acc.: 49.61%][Generator loss: 0.7263%]\n",
      "3626 [Discriminator loss: 0.6985%, acc.: 49.22%][Generator loss: 0.7268%]\n",
      "3627 [Discriminator loss: 0.6982%, acc.: 49.22%][Generator loss: 0.7260%]\n",
      "3628 [Discriminator loss: 0.6977%, acc.: 46.09%][Generator loss: 0.7266%]\n",
      "3629 [Discriminator loss: 0.6993%, acc.: 48.83%][Generator loss: 0.7242%]\n",
      "3630 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7248%]\n",
      "3631 [Discriminator loss: 0.6976%, acc.: 47.66%][Generator loss: 0.7255%]\n",
      "3632 [Discriminator loss: 0.6974%, acc.: 48.83%][Generator loss: 0.7247%]\n",
      "3633 [Discriminator loss: 0.6968%, acc.: 47.66%][Generator loss: 0.7253%]\n",
      "3634 [Discriminator loss: 0.6993%, acc.: 49.61%][Generator loss: 0.7265%]\n",
      "3635 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3636 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7258%]\n",
      "3637 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7250%]\n",
      "3638 [Discriminator loss: 0.6970%, acc.: 49.61%][Generator loss: 0.7270%]\n",
      "3639 [Discriminator loss: 0.6976%, acc.: 48.44%][Generator loss: 0.7278%]\n",
      "3640 [Discriminator loss: 0.7002%, acc.: 44.53%][Generator loss: 0.7252%]\n",
      "3641 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7247%]\n",
      "3642 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3643 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3644 [Discriminator loss: 0.6988%, acc.: 46.48%][Generator loss: 0.7239%]\n",
      "3645 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7242%]\n",
      "3646 [Discriminator loss: 0.6981%, acc.: 48.44%][Generator loss: 0.7266%]\n",
      "3647 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7245%]\n",
      "3648 [Discriminator loss: 0.6982%, acc.: 48.83%][Generator loss: 0.7256%]\n",
      "3649 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3650 [Discriminator loss: 0.6969%, acc.: 49.22%][Generator loss: 0.7259%]\n",
      "3651 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7249%]\n",
      "3652 [Discriminator loss: 0.6966%, acc.: 48.83%][Generator loss: 0.7258%]\n",
      "3653 [Discriminator loss: 0.6981%, acc.: 48.83%][Generator loss: 0.7246%]\n",
      "3654 [Discriminator loss: 0.6986%, acc.: 46.09%][Generator loss: 0.7258%]\n",
      "3655 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7260%]\n",
      "3656 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3657 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7264%]\n",
      "3658 [Discriminator loss: 0.6992%, acc.: 50.39%][Generator loss: 0.7265%]\n",
      "3659 [Discriminator loss: 0.6974%, acc.: 48.83%][Generator loss: 0.7269%]\n",
      "3660 [Discriminator loss: 0.6992%, acc.: 47.66%][Generator loss: 0.7247%]\n",
      "3661 [Discriminator loss: 0.6972%, acc.: 48.44%][Generator loss: 0.7255%]\n",
      "3662 [Discriminator loss: 0.6980%, acc.: 46.48%][Generator loss: 0.7253%]\n",
      "3663 [Discriminator loss: 0.6983%, acc.: 47.66%][Generator loss: 0.7243%]\n",
      "3664 [Discriminator loss: 0.6975%, acc.: 49.22%][Generator loss: 0.7247%]\n",
      "3665 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7240%]\n",
      "3666 [Discriminator loss: 0.6979%, acc.: 48.44%][Generator loss: 0.7259%]\n",
      "3667 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7241%]\n",
      "3668 [Discriminator loss: 0.6968%, acc.: 50.39%][Generator loss: 0.7268%]\n",
      "3669 [Discriminator loss: 0.6982%, acc.: 49.22%][Generator loss: 0.7264%]\n",
      "3670 [Discriminator loss: 0.6983%, acc.: 49.61%][Generator loss: 0.7257%]\n",
      "3671 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7271%]\n",
      "3672 [Discriminator loss: 0.6985%, acc.: 48.05%][Generator loss: 0.7237%]\n",
      "3673 [Discriminator loss: 0.7012%, acc.: 44.14%][Generator loss: 0.7246%]\n",
      "3674 [Discriminator loss: 0.6988%, acc.: 49.61%][Generator loss: 0.7231%]\n",
      "3675 [Discriminator loss: 0.6972%, acc.: 47.27%][Generator loss: 0.7253%]\n",
      "3676 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7240%]\n",
      "3677 [Discriminator loss: 0.6967%, acc.: 49.61%][Generator loss: 0.7245%]\n",
      "3678 [Discriminator loss: 0.6979%, acc.: 48.05%][Generator loss: 0.7239%]\n",
      "3679 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7268%]\n",
      "3680 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7259%]\n",
      "3681 [Discriminator loss: 0.6973%, acc.: 49.22%][Generator loss: 0.7257%]\n",
      "3682 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7249%]\n",
      "3683 [Discriminator loss: 0.6981%, acc.: 49.22%][Generator loss: 0.7238%]\n",
      "3684 [Discriminator loss: 0.6981%, acc.: 49.61%][Generator loss: 0.7231%]\n",
      "3685 [Discriminator loss: 0.6989%, acc.: 49.22%][Generator loss: 0.7253%]\n",
      "3686 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7261%]\n",
      "3687 [Discriminator loss: 0.6967%, acc.: 49.61%][Generator loss: 0.7288%]\n",
      "3688 [Discriminator loss: 0.7002%, acc.: 50.39%][Generator loss: 0.7273%]\n",
      "3689 [Discriminator loss: 0.6978%, acc.: 48.44%][Generator loss: 0.7251%]\n",
      "3690 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7252%]\n",
      "3691 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7243%]\n",
      "3692 [Discriminator loss: 0.6981%, acc.: 50.39%][Generator loss: 0.7239%]\n",
      "3693 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7271%]\n",
      "3694 [Discriminator loss: 0.6978%, acc.: 49.61%][Generator loss: 0.7261%]\n",
      "3695 [Discriminator loss: 0.6992%, acc.: 44.14%][Generator loss: 0.7241%]\n",
      "3696 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7260%]\n",
      "3697 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7249%]\n",
      "3698 [Discriminator loss: 0.6975%, acc.: 48.44%][Generator loss: 0.7266%]\n",
      "3699 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7254%]\n",
      "3700 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7257%]\n",
      "3701 [Discriminator loss: 0.6979%, acc.: 48.83%][Generator loss: 0.7252%]\n",
      "3702 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7254%]\n",
      "3703 [Discriminator loss: 0.6983%, acc.: 46.88%][Generator loss: 0.7263%]\n",
      "3704 [Discriminator loss: 0.6979%, acc.: 48.44%][Generator loss: 0.7266%]\n",
      "3705 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7249%]\n",
      "3706 [Discriminator loss: 0.6977%, acc.: 48.83%][Generator loss: 0.7257%]\n",
      "3707 [Discriminator loss: 0.6975%, acc.: 49.61%][Generator loss: 0.7253%]\n",
      "3708 [Discriminator loss: 0.6969%, acc.: 48.83%][Generator loss: 0.7245%]\n",
      "3709 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3710 [Discriminator loss: 0.6994%, acc.: 47.27%][Generator loss: 0.7248%]\n",
      "3711 [Discriminator loss: 0.6978%, acc.: 48.83%][Generator loss: 0.7242%]\n",
      "3712 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7246%]\n",
      "3713 [Discriminator loss: 0.6975%, acc.: 48.05%][Generator loss: 0.7235%]\n",
      "3714 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7236%]\n",
      "3715 [Discriminator loss: 0.6968%, acc.: 47.66%][Generator loss: 0.7262%]\n",
      "3716 [Discriminator loss: 0.6990%, acc.: 50.00%][Generator loss: 0.7262%]\n",
      "3717 [Discriminator loss: 0.6993%, acc.: 47.66%][Generator loss: 0.7259%]\n",
      "3718 [Discriminator loss: 0.6990%, acc.: 50.00%][Generator loss: 0.7247%]\n",
      "3719 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7235%]\n",
      "3720 [Discriminator loss: 0.6961%, acc.: 49.22%][Generator loss: 0.7247%]\n",
      "3721 [Discriminator loss: 0.6984%, acc.: 49.61%][Generator loss: 0.7244%]\n",
      "3722 [Discriminator loss: 0.6968%, acc.: 49.61%][Generator loss: 0.7271%]\n",
      "3723 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3724 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7253%]\n",
      "3725 [Discriminator loss: 0.6973%, acc.: 48.83%][Generator loss: 0.7263%]\n",
      "3726 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7261%]\n",
      "3727 [Discriminator loss: 0.6977%, acc.: 48.83%][Generator loss: 0.7260%]\n",
      "3728 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7248%]\n",
      "3729 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7247%]\n",
      "3730 [Discriminator loss: 0.6961%, acc.: 48.05%][Generator loss: 0.7275%]\n",
      "3731 [Discriminator loss: 0.6988%, acc.: 48.83%][Generator loss: 0.7263%]\n",
      "3732 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7304%]\n",
      "3733 [Discriminator loss: 0.6997%, acc.: 50.00%][Generator loss: 0.7275%]\n",
      "3734 [Discriminator loss: 0.6983%, acc.: 49.61%][Generator loss: 0.7246%]\n",
      "3735 [Discriminator loss: 0.6971%, acc.: 49.61%][Generator loss: 0.7234%]\n",
      "3736 [Discriminator loss: 0.6975%, acc.: 49.61%][Generator loss: 0.7246%]\n",
      "3737 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7236%]\n",
      "3738 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7253%]\n",
      "3739 [Discriminator loss: 0.6979%, acc.: 48.44%][Generator loss: 0.7245%]\n",
      "3740 [Discriminator loss: 0.6984%, acc.: 49.61%][Generator loss: 0.7243%]\n",
      "3741 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7243%]\n",
      "3742 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7251%]\n",
      "3743 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7244%]\n",
      "3744 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3745 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7265%]\n",
      "3746 [Discriminator loss: 0.6992%, acc.: 50.00%][Generator loss: 0.7237%]\n",
      "3747 [Discriminator loss: 0.6964%, acc.: 49.61%][Generator loss: 0.7237%]\n",
      "3748 [Discriminator loss: 0.6966%, acc.: 49.61%][Generator loss: 0.7245%]\n",
      "3749 [Discriminator loss: 0.6976%, acc.: 49.22%][Generator loss: 0.7259%]\n",
      "3750 [Discriminator loss: 0.6989%, acc.: 46.09%][Generator loss: 0.7253%]\n",
      "3751 [Discriminator loss: 0.6987%, acc.: 49.22%][Generator loss: 0.7244%]\n",
      "3752 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7240%]\n",
      "3753 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7251%]\n",
      "3754 [Discriminator loss: 0.6975%, acc.: 49.61%][Generator loss: 0.7244%]\n",
      "3755 [Discriminator loss: 0.6982%, acc.: 48.44%][Generator loss: 0.7260%]\n",
      "3756 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7244%]\n",
      "3757 [Discriminator loss: 0.6984%, acc.: 49.61%][Generator loss: 0.7249%]\n",
      "3758 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7256%]\n",
      "3759 [Discriminator loss: 0.6994%, acc.: 47.66%][Generator loss: 0.7250%]\n",
      "3760 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7244%]\n",
      "3761 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7251%]\n",
      "3762 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7244%]\n",
      "3763 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7236%]\n",
      "3764 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7244%]\n",
      "3765 [Discriminator loss: 0.6978%, acc.: 47.27%][Generator loss: 0.7270%]\n",
      "3766 [Discriminator loss: 0.6980%, acc.: 47.66%][Generator loss: 0.7257%]\n",
      "3767 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7268%]\n",
      "3768 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7246%]\n",
      "3769 [Discriminator loss: 0.6978%, acc.: 49.61%][Generator loss: 0.7235%]\n",
      "3770 [Discriminator loss: 0.6978%, acc.: 49.61%][Generator loss: 0.7245%]\n",
      "3771 [Discriminator loss: 0.6973%, acc.: 46.88%][Generator loss: 0.7259%]\n",
      "3772 [Discriminator loss: 0.6983%, acc.: 46.88%][Generator loss: 0.7245%]\n",
      "3773 [Discriminator loss: 0.6969%, acc.: 50.39%][Generator loss: 0.7242%]\n",
      "3774 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7245%]\n",
      "3775 [Discriminator loss: 0.6984%, acc.: 47.66%][Generator loss: 0.7252%]\n",
      "3776 [Discriminator loss: 0.6969%, acc.: 48.44%][Generator loss: 0.7261%]\n",
      "3777 [Discriminator loss: 0.6995%, acc.: 46.88%][Generator loss: 0.7236%]\n",
      "3778 [Discriminator loss: 0.6981%, acc.: 49.22%][Generator loss: 0.7236%]\n",
      "3779 [Discriminator loss: 0.6970%, acc.: 50.39%][Generator loss: 0.7246%]\n",
      "3780 [Discriminator loss: 0.6978%, acc.: 47.27%][Generator loss: 0.7249%]\n",
      "3781 [Discriminator loss: 0.6972%, acc.: 49.61%][Generator loss: 0.7239%]\n",
      "3782 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7249%]\n",
      "3783 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7238%]\n",
      "3784 [Discriminator loss: 0.6968%, acc.: 48.83%][Generator loss: 0.7248%]\n",
      "3785 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7245%]\n",
      "3786 [Discriminator loss: 0.6963%, acc.: 49.22%][Generator loss: 0.7265%]\n",
      "3787 [Discriminator loss: 0.6986%, acc.: 49.22%][Generator loss: 0.7253%]\n",
      "3788 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7243%]\n",
      "3789 [Discriminator loss: 0.6978%, acc.: 48.05%][Generator loss: 0.7246%]\n",
      "3790 [Discriminator loss: 0.6988%, acc.: 48.05%][Generator loss: 0.7239%]\n",
      "3791 [Discriminator loss: 0.6974%, acc.: 48.44%][Generator loss: 0.7250%]\n",
      "3792 [Discriminator loss: 0.6979%, acc.: 46.88%][Generator loss: 0.7275%]\n",
      "3793 [Discriminator loss: 0.6982%, acc.: 48.83%][Generator loss: 0.7265%]\n",
      "3794 [Discriminator loss: 0.6982%, acc.: 49.61%][Generator loss: 0.7249%]\n",
      "3795 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7228%]\n",
      "3796 [Discriminator loss: 0.6963%, acc.: 49.61%][Generator loss: 0.7252%]\n",
      "3797 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7262%]\n",
      "3798 [Discriminator loss: 0.6986%, acc.: 49.22%][Generator loss: 0.7261%]\n",
      "3799 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7249%]\n",
      "3800 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7248%]\n",
      "3801 [Discriminator loss: 0.6980%, acc.: 47.27%][Generator loss: 0.7245%]\n",
      "3802 [Discriminator loss: 0.6975%, acc.: 48.44%][Generator loss: 0.7235%]\n",
      "3803 [Discriminator loss: 0.6975%, acc.: 46.88%][Generator loss: 0.7246%]\n",
      "3804 [Discriminator loss: 0.6984%, acc.: 48.44%][Generator loss: 0.7232%]\n",
      "3805 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7261%]\n",
      "3806 [Discriminator loss: 0.6976%, acc.: 49.22%][Generator loss: 0.7260%]\n",
      "3807 [Discriminator loss: 0.6970%, acc.: 49.22%][Generator loss: 0.7257%]\n",
      "3808 [Discriminator loss: 0.6967%, acc.: 48.83%][Generator loss: 0.7253%]\n",
      "3809 [Discriminator loss: 0.6971%, acc.: 47.27%][Generator loss: 0.7257%]\n",
      "3810 [Discriminator loss: 0.6987%, acc.: 48.44%][Generator loss: 0.7260%]\n",
      "3811 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7260%]\n",
      "3812 [Discriminator loss: 0.6969%, acc.: 49.22%][Generator loss: 0.7243%]\n",
      "3813 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7247%]\n",
      "3814 [Discriminator loss: 0.6967%, acc.: 48.83%][Generator loss: 0.7241%]\n",
      "3815 [Discriminator loss: 0.6972%, acc.: 50.39%][Generator loss: 0.7257%]\n",
      "3816 [Discriminator loss: 0.6979%, acc.: 47.66%][Generator loss: 0.7246%]\n",
      "3817 [Discriminator loss: 0.6988%, acc.: 45.70%][Generator loss: 0.7242%]\n",
      "3818 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7227%]\n",
      "3819 [Discriminator loss: 0.6963%, acc.: 48.44%][Generator loss: 0.7257%]\n",
      "3820 [Discriminator loss: 0.6965%, acc.: 49.61%][Generator loss: 0.7248%]\n",
      "3821 [Discriminator loss: 0.6972%, acc.: 50.39%][Generator loss: 0.7276%]\n",
      "3822 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7274%]\n",
      "3823 [Discriminator loss: 0.6989%, acc.: 50.00%][Generator loss: 0.7248%]\n",
      "3824 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7249%]\n",
      "3825 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7250%]\n",
      "3826 [Discriminator loss: 0.6972%, acc.: 46.48%][Generator loss: 0.7257%]\n",
      "3827 [Discriminator loss: 0.6972%, acc.: 48.44%][Generator loss: 0.7259%]\n",
      "3828 [Discriminator loss: 0.6985%, acc.: 47.27%][Generator loss: 0.7244%]\n",
      "3829 [Discriminator loss: 0.6984%, acc.: 50.00%][Generator loss: 0.7237%]\n",
      "3830 [Discriminator loss: 0.6969%, acc.: 48.05%][Generator loss: 0.7248%]\n",
      "3831 [Discriminator loss: 0.6972%, acc.: 47.27%][Generator loss: 0.7232%]\n",
      "3832 [Discriminator loss: 0.6965%, acc.: 49.22%][Generator loss: 0.7255%]\n",
      "3833 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7259%]\n",
      "3834 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7248%]\n",
      "3835 [Discriminator loss: 0.6972%, acc.: 49.61%][Generator loss: 0.7252%]\n",
      "3836 [Discriminator loss: 0.6972%, acc.: 46.88%][Generator loss: 0.7241%]\n",
      "3837 [Discriminator loss: 0.6973%, acc.: 48.83%][Generator loss: 0.7247%]\n",
      "3838 [Discriminator loss: 0.6979%, acc.: 46.88%][Generator loss: 0.7239%]\n",
      "3839 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7247%]\n",
      "3840 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7245%]\n",
      "3841 [Discriminator loss: 0.6966%, acc.: 50.39%][Generator loss: 0.7235%]\n",
      "3842 [Discriminator loss: 0.6968%, acc.: 49.61%][Generator loss: 0.7273%]\n",
      "3843 [Discriminator loss: 0.6986%, acc.: 49.22%][Generator loss: 0.7250%]\n",
      "3844 [Discriminator loss: 0.6978%, acc.: 48.83%][Generator loss: 0.7247%]\n",
      "3845 [Discriminator loss: 0.6986%, acc.: 49.61%][Generator loss: 0.7245%]\n",
      "3846 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7257%]\n",
      "3847 [Discriminator loss: 0.7002%, acc.: 42.97%][Generator loss: 0.7225%]\n",
      "3848 [Discriminator loss: 0.6986%, acc.: 49.22%][Generator loss: 0.7240%]\n",
      "3849 [Discriminator loss: 0.6972%, acc.: 49.22%][Generator loss: 0.7232%]\n",
      "3850 [Discriminator loss: 0.6969%, acc.: 49.61%][Generator loss: 0.7241%]\n",
      "3851 [Discriminator loss: 0.6963%, acc.: 49.22%][Generator loss: 0.7235%]\n",
      "3852 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7267%]\n",
      "3853 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7242%]\n",
      "3854 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7247%]\n",
      "3855 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7231%]\n",
      "3856 [Discriminator loss: 0.6967%, acc.: 49.61%][Generator loss: 0.7251%]\n",
      "3857 [Discriminator loss: 0.6979%, acc.: 49.22%][Generator loss: 0.7231%]\n",
      "3858 [Discriminator loss: 0.6983%, acc.: 49.61%][Generator loss: 0.7235%]\n",
      "3859 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7230%]\n",
      "3860 [Discriminator loss: 0.6968%, acc.: 49.22%][Generator loss: 0.7266%]\n",
      "3861 [Discriminator loss: 0.6981%, acc.: 50.78%][Generator loss: 0.7238%]\n",
      "3862 [Discriminator loss: 0.6975%, acc.: 48.05%][Generator loss: 0.7233%]\n",
      "3863 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7252%]\n",
      "3864 [Discriminator loss: 0.6974%, acc.: 47.66%][Generator loss: 0.7248%]\n",
      "3865 [Discriminator loss: 0.6986%, acc.: 49.61%][Generator loss: 0.7244%]\n",
      "3866 [Discriminator loss: 0.6968%, acc.: 49.22%][Generator loss: 0.7247%]\n",
      "3867 [Discriminator loss: 0.6975%, acc.: 48.05%][Generator loss: 0.7224%]\n",
      "3868 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7230%]\n",
      "3869 [Discriminator loss: 0.6966%, acc.: 48.44%][Generator loss: 0.7242%]\n",
      "3870 [Discriminator loss: 0.6982%, acc.: 44.92%][Generator loss: 0.7234%]\n",
      "3871 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7239%]\n",
      "3872 [Discriminator loss: 0.6982%, acc.: 49.22%][Generator loss: 0.7223%]\n",
      "3873 [Discriminator loss: 0.6977%, acc.: 48.83%][Generator loss: 0.7232%]\n",
      "3874 [Discriminator loss: 0.6963%, acc.: 49.61%][Generator loss: 0.7243%]\n",
      "3875 [Discriminator loss: 0.6981%, acc.: 48.05%][Generator loss: 0.7233%]\n",
      "3876 [Discriminator loss: 0.6974%, acc.: 48.83%][Generator loss: 0.7243%]\n",
      "3877 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7254%]\n",
      "3878 [Discriminator loss: 0.6988%, acc.: 48.83%][Generator loss: 0.7246%]\n",
      "3879 [Discriminator loss: 0.6971%, acc.: 50.78%][Generator loss: 0.7232%]\n",
      "3880 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7231%]\n",
      "3881 [Discriminator loss: 0.6971%, acc.: 48.83%][Generator loss: 0.7256%]\n",
      "3882 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7229%]\n",
      "3883 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7231%]\n",
      "3884 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7237%]\n",
      "3885 [Discriminator loss: 0.6997%, acc.: 47.66%][Generator loss: 0.7226%]\n",
      "3886 [Discriminator loss: 0.6982%, acc.: 47.27%][Generator loss: 0.7226%]\n",
      "3887 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7235%]\n",
      "3888 [Discriminator loss: 0.6970%, acc.: 49.61%][Generator loss: 0.7248%]\n",
      "3889 [Discriminator loss: 0.6987%, acc.: 49.61%][Generator loss: 0.7231%]\n",
      "3890 [Discriminator loss: 0.6980%, acc.: 46.88%][Generator loss: 0.7232%]\n",
      "3891 [Discriminator loss: 0.6967%, acc.: 48.05%][Generator loss: 0.7237%]\n",
      "3892 [Discriminator loss: 0.6965%, acc.: 50.78%][Generator loss: 0.7217%]\n",
      "3893 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7234%]\n",
      "3894 [Discriminator loss: 0.6986%, acc.: 49.61%][Generator loss: 0.7253%]\n",
      "3895 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7251%]\n",
      "3896 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7252%]\n",
      "3897 [Discriminator loss: 0.6976%, acc.: 49.61%][Generator loss: 0.7249%]\n",
      "3898 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7239%]\n",
      "3899 [Discriminator loss: 0.6977%, acc.: 46.88%][Generator loss: 0.7261%]\n",
      "3900 [Discriminator loss: 0.6981%, acc.: 50.39%][Generator loss: 0.7228%]\n",
      "3901 [Discriminator loss: 0.6974%, acc.: 48.83%][Generator loss: 0.7239%]\n",
      "3902 [Discriminator loss: 0.6982%, acc.: 51.17%][Generator loss: 0.7221%]\n",
      "3903 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7214%]\n",
      "3904 [Discriminator loss: 0.6961%, acc.: 49.61%][Generator loss: 0.7240%]\n",
      "3905 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7228%]\n",
      "3906 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7237%]\n",
      "3907 [Discriminator loss: 0.6966%, acc.: 47.27%][Generator loss: 0.7235%]\n",
      "3908 [Discriminator loss: 0.6983%, acc.: 46.88%][Generator loss: 0.7253%]\n",
      "3909 [Discriminator loss: 0.6986%, acc.: 48.44%][Generator loss: 0.7237%]\n",
      "3910 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7234%]\n",
      "3911 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7226%]\n",
      "3912 [Discriminator loss: 0.6983%, acc.: 48.44%][Generator loss: 0.7232%]\n",
      "3913 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7227%]\n",
      "3914 [Discriminator loss: 0.6972%, acc.: 49.22%][Generator loss: 0.7231%]\n",
      "3915 [Discriminator loss: 0.6965%, acc.: 50.39%][Generator loss: 0.7227%]\n",
      "3916 [Discriminator loss: 0.6963%, acc.: 49.61%][Generator loss: 0.7237%]\n",
      "3917 [Discriminator loss: 0.6984%, acc.: 46.48%][Generator loss: 0.7233%]\n",
      "3918 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7247%]\n",
      "3919 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7233%]\n",
      "3920 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7231%]\n",
      "3921 [Discriminator loss: 0.6969%, acc.: 47.27%][Generator loss: 0.7223%]\n",
      "3922 [Discriminator loss: 0.6969%, acc.: 47.66%][Generator loss: 0.7235%]\n",
      "3923 [Discriminator loss: 0.6972%, acc.: 49.22%][Generator loss: 0.7260%]\n",
      "3924 [Discriminator loss: 0.6977%, acc.: 48.05%][Generator loss: 0.7236%]\n",
      "3925 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7231%]\n",
      "3926 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7236%]\n",
      "3927 [Discriminator loss: 0.6981%, acc.: 48.44%][Generator loss: 0.7250%]\n",
      "3928 [Discriminator loss: 0.6977%, acc.: 46.88%][Generator loss: 0.7247%]\n",
      "3929 [Discriminator loss: 0.6978%, acc.: 48.44%][Generator loss: 0.7220%]\n",
      "3930 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7227%]\n",
      "3931 [Discriminator loss: 0.6976%, acc.: 47.66%][Generator loss: 0.7244%]\n",
      "3932 [Discriminator loss: 0.6969%, acc.: 49.22%][Generator loss: 0.7239%]\n",
      "3933 [Discriminator loss: 0.6978%, acc.: 48.83%][Generator loss: 0.7232%]\n",
      "3934 [Discriminator loss: 0.6980%, acc.: 49.61%][Generator loss: 0.7230%]\n",
      "3935 [Discriminator loss: 0.6977%, acc.: 48.05%][Generator loss: 0.7223%]\n",
      "3936 [Discriminator loss: 0.6972%, acc.: 49.22%][Generator loss: 0.7228%]\n",
      "3937 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7222%]\n",
      "3938 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7228%]\n",
      "3939 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7232%]\n",
      "3940 [Discriminator loss: 0.6968%, acc.: 50.39%][Generator loss: 0.7238%]\n",
      "3941 [Discriminator loss: 0.6978%, acc.: 48.83%][Generator loss: 0.7215%]\n",
      "3942 [Discriminator loss: 0.6975%, acc.: 48.05%][Generator loss: 0.7232%]\n",
      "3943 [Discriminator loss: 0.6966%, acc.: 46.88%][Generator loss: 0.7241%]\n",
      "3944 [Discriminator loss: 0.6977%, acc.: 50.39%][Generator loss: 0.7227%]\n",
      "3945 [Discriminator loss: 0.6974%, acc.: 48.44%][Generator loss: 0.7226%]\n",
      "3946 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7238%]\n",
      "3947 [Discriminator loss: 0.6971%, acc.: 46.88%][Generator loss: 0.7224%]\n",
      "3948 [Discriminator loss: 0.6976%, acc.: 49.61%][Generator loss: 0.7258%]\n",
      "3949 [Discriminator loss: 0.6983%, acc.: 50.00%][Generator loss: 0.7243%]\n",
      "3950 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7223%]\n",
      "3951 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7229%]\n",
      "3952 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7226%]\n",
      "3953 [Discriminator loss: 0.6972%, acc.: 48.83%][Generator loss: 0.7219%]\n",
      "3954 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7233%]\n",
      "3955 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7246%]\n",
      "3956 [Discriminator loss: 0.6968%, acc.: 47.27%][Generator loss: 0.7263%]\n",
      "3957 [Discriminator loss: 0.6988%, acc.: 51.56%][Generator loss: 0.7241%]\n",
      "3958 [Discriminator loss: 0.6969%, acc.: 48.83%][Generator loss: 0.7253%]\n",
      "3959 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3960 [Discriminator loss: 0.6991%, acc.: 48.83%][Generator loss: 0.7223%]\n",
      "3961 [Discriminator loss: 0.6974%, acc.: 48.44%][Generator loss: 0.7223%]\n",
      "3962 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7232%]\n",
      "3963 [Discriminator loss: 0.6975%, acc.: 49.22%][Generator loss: 0.7229%]\n",
      "3964 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7230%]\n",
      "3965 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7228%]\n",
      "3966 [Discriminator loss: 0.6970%, acc.: 49.61%][Generator loss: 0.7228%]\n",
      "3967 [Discriminator loss: 0.6972%, acc.: 48.83%][Generator loss: 0.7233%]\n",
      "3968 [Discriminator loss: 0.6974%, acc.: 48.44%][Generator loss: 0.7221%]\n",
      "3969 [Discriminator loss: 0.6983%, acc.: 46.48%][Generator loss: 0.7237%]\n",
      "3970 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7227%]\n",
      "3971 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7255%]\n",
      "3972 [Discriminator loss: 0.6978%, acc.: 46.48%][Generator loss: 0.7226%]\n",
      "3973 [Discriminator loss: 0.6972%, acc.: 49.22%][Generator loss: 0.7226%]\n",
      "3974 [Discriminator loss: 0.6986%, acc.: 46.09%][Generator loss: 0.7217%]\n",
      "3975 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7218%]\n",
      "3976 [Discriminator loss: 0.6970%, acc.: 47.27%][Generator loss: 0.7215%]\n",
      "3977 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7229%]\n",
      "3978 [Discriminator loss: 0.6970%, acc.: 49.61%][Generator loss: 0.7235%]\n",
      "3979 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7226%]\n",
      "3980 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7232%]\n",
      "3981 [Discriminator loss: 0.6973%, acc.: 49.22%][Generator loss: 0.7237%]\n",
      "3982 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7238%]\n",
      "3983 [Discriminator loss: 0.6972%, acc.: 49.61%][Generator loss: 0.7236%]\n",
      "3984 [Discriminator loss: 0.6983%, acc.: 48.05%][Generator loss: 0.7225%]\n",
      "3985 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7219%]\n",
      "3986 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7239%]\n",
      "3987 [Discriminator loss: 0.6972%, acc.: 47.27%][Generator loss: 0.7233%]\n",
      "3988 [Discriminator loss: 0.6976%, acc.: 49.22%][Generator loss: 0.7248%]\n",
      "3989 [Discriminator loss: 0.6977%, acc.: 49.61%][Generator loss: 0.7245%]\n",
      "3990 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7230%]\n",
      "3991 [Discriminator loss: 0.6970%, acc.: 49.61%][Generator loss: 0.7230%]\n",
      "3992 [Discriminator loss: 0.6966%, acc.: 50.78%][Generator loss: 0.7217%]\n",
      "3993 [Discriminator loss: 0.6975%, acc.: 48.44%][Generator loss: 0.7245%]\n",
      "3994 [Discriminator loss: 0.6981%, acc.: 50.00%][Generator loss: 0.7228%]\n",
      "3995 [Discriminator loss: 0.6969%, acc.: 48.83%][Generator loss: 0.7236%]\n",
      "3996 [Discriminator loss: 0.6982%, acc.: 49.61%][Generator loss: 0.7215%]\n",
      "3997 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7229%]\n",
      "3998 [Discriminator loss: 0.6971%, acc.: 47.66%][Generator loss: 0.7226%]\n",
      "3999 [Discriminator loss: 0.6979%, acc.: 47.66%][Generator loss: 0.7231%]\n",
      "4000 [Discriminator loss: 0.6967%, acc.: 49.61%][Generator loss: 0.7226%]\n",
      "4001 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7241%]\n",
      "4002 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7228%]\n",
      "4003 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7233%]\n",
      "4004 [Discriminator loss: 0.6971%, acc.: 49.22%][Generator loss: 0.7224%]\n",
      "4005 [Discriminator loss: 0.6972%, acc.: 46.88%][Generator loss: 0.7236%]\n",
      "4006 [Discriminator loss: 0.6974%, acc.: 48.05%][Generator loss: 0.7222%]\n",
      "4007 [Discriminator loss: 0.6979%, acc.: 50.00%][Generator loss: 0.7219%]\n",
      "4008 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7211%]\n",
      "4009 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7230%]\n",
      "4010 [Discriminator loss: 0.6970%, acc.: 47.66%][Generator loss: 0.7225%]\n",
      "4011 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7220%]\n",
      "4012 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7230%]\n",
      "4013 [Discriminator loss: 0.6977%, acc.: 48.05%][Generator loss: 0.7223%]\n",
      "4014 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7230%]\n",
      "4015 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7224%]\n",
      "4016 [Discriminator loss: 0.6962%, acc.: 50.39%][Generator loss: 0.7237%]\n",
      "4017 [Discriminator loss: 0.6982%, acc.: 48.83%][Generator loss: 0.7222%]\n",
      "4018 [Discriminator loss: 0.6970%, acc.: 48.44%][Generator loss: 0.7223%]\n",
      "4019 [Discriminator loss: 0.6971%, acc.: 47.27%][Generator loss: 0.7212%]\n",
      "4020 [Discriminator loss: 0.6961%, acc.: 48.83%][Generator loss: 0.7229%]\n",
      "4021 [Discriminator loss: 0.6969%, acc.: 48.44%][Generator loss: 0.7229%]\n",
      "4022 [Discriminator loss: 0.6992%, acc.: 45.70%][Generator loss: 0.7248%]\n",
      "4023 [Discriminator loss: 0.6981%, acc.: 47.66%][Generator loss: 0.7222%]\n",
      "4024 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7225%]\n",
      "4025 [Discriminator loss: 0.6959%, acc.: 48.44%][Generator loss: 0.7223%]\n",
      "4026 [Discriminator loss: 0.6966%, acc.: 49.61%][Generator loss: 0.7225%]\n",
      "4027 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7223%]\n",
      "4028 [Discriminator loss: 0.6969%, acc.: 48.05%][Generator loss: 0.7209%]\n",
      "4029 [Discriminator loss: 0.6983%, acc.: 44.53%][Generator loss: 0.7227%]\n",
      "4030 [Discriminator loss: 0.6983%, acc.: 50.39%][Generator loss: 0.7221%]\n",
      "4031 [Discriminator loss: 0.6970%, acc.: 46.88%][Generator loss: 0.7246%]\n",
      "4032 [Discriminator loss: 0.6969%, acc.: 49.61%][Generator loss: 0.7225%]\n",
      "4033 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7224%]\n",
      "4034 [Discriminator loss: 0.6982%, acc.: 48.44%][Generator loss: 0.7212%]\n",
      "4035 [Discriminator loss: 0.6986%, acc.: 48.05%][Generator loss: 0.7211%]\n",
      "4036 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7214%]\n",
      "4037 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7223%]\n",
      "4038 [Discriminator loss: 0.6962%, acc.: 49.61%][Generator loss: 0.7220%]\n",
      "4039 [Discriminator loss: 0.6968%, acc.: 48.05%][Generator loss: 0.7221%]\n",
      "4040 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7219%]\n",
      "4041 [Discriminator loss: 0.6955%, acc.: 47.66%][Generator loss: 0.7229%]\n",
      "4042 [Discriminator loss: 0.6980%, acc.: 46.09%][Generator loss: 0.7219%]\n",
      "4043 [Discriminator loss: 0.6982%, acc.: 48.05%][Generator loss: 0.7208%]\n",
      "4044 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7233%]\n",
      "4045 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7235%]\n",
      "4046 [Discriminator loss: 0.6976%, acc.: 49.22%][Generator loss: 0.7227%]\n",
      "4047 [Discriminator loss: 0.6972%, acc.: 49.61%][Generator loss: 0.7232%]\n",
      "4048 [Discriminator loss: 0.6976%, acc.: 48.83%][Generator loss: 0.7200%]\n",
      "4049 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7207%]\n",
      "4050 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7208%]\n",
      "4051 [Discriminator loss: 0.6968%, acc.: 48.05%][Generator loss: 0.7216%]\n",
      "4052 [Discriminator loss: 0.6964%, acc.: 49.22%][Generator loss: 0.7215%]\n",
      "4053 [Discriminator loss: 0.6978%, acc.: 46.88%][Generator loss: 0.7216%]\n",
      "4054 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7216%]\n",
      "4055 [Discriminator loss: 0.6961%, acc.: 50.39%][Generator loss: 0.7205%]\n",
      "4056 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7206%]\n",
      "4057 [Discriminator loss: 0.6983%, acc.: 49.22%][Generator loss: 0.7217%]\n",
      "4058 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7233%]\n",
      "4059 [Discriminator loss: 0.6957%, acc.: 49.61%][Generator loss: 0.7212%]\n",
      "4060 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7218%]\n",
      "4061 [Discriminator loss: 0.6971%, acc.: 48.05%][Generator loss: 0.7216%]\n",
      "4062 [Discriminator loss: 0.6966%, acc.: 49.61%][Generator loss: 0.7228%]\n",
      "4063 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7213%]\n",
      "4064 [Discriminator loss: 0.6979%, acc.: 48.44%][Generator loss: 0.7207%]\n",
      "4065 [Discriminator loss: 0.6967%, acc.: 49.61%][Generator loss: 0.7212%]\n",
      "4066 [Discriminator loss: 0.6968%, acc.: 48.83%][Generator loss: 0.7223%]\n",
      "4067 [Discriminator loss: 0.6960%, acc.: 50.39%][Generator loss: 0.7214%]\n",
      "4068 [Discriminator loss: 0.6969%, acc.: 47.66%][Generator loss: 0.7228%]\n",
      "4069 [Discriminator loss: 0.6976%, acc.: 50.78%][Generator loss: 0.7229%]\n",
      "4070 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7229%]\n",
      "4071 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7216%]\n",
      "4072 [Discriminator loss: 0.6965%, acc.: 46.48%][Generator loss: 0.7238%]\n",
      "4073 [Discriminator loss: 0.6993%, acc.: 48.83%][Generator loss: 0.7207%]\n",
      "4074 [Discriminator loss: 0.6983%, acc.: 48.05%][Generator loss: 0.7213%]\n",
      "4075 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7208%]\n",
      "4076 [Discriminator loss: 0.6969%, acc.: 47.66%][Generator loss: 0.7209%]\n",
      "4077 [Discriminator loss: 0.6969%, acc.: 49.22%][Generator loss: 0.7221%]\n",
      "4078 [Discriminator loss: 0.6973%, acc.: 48.83%][Generator loss: 0.7227%]\n",
      "4079 [Discriminator loss: 0.6976%, acc.: 50.00%][Generator loss: 0.7208%]\n",
      "4080 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7203%]\n",
      "4081 [Discriminator loss: 0.6960%, acc.: 48.05%][Generator loss: 0.7205%]\n",
      "4082 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7206%]\n",
      "4083 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7212%]\n",
      "4084 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7227%]\n",
      "4085 [Discriminator loss: 0.6973%, acc.: 49.22%][Generator loss: 0.7223%]\n",
      "4086 [Discriminator loss: 0.6985%, acc.: 50.00%][Generator loss: 0.7225%]\n",
      "4087 [Discriminator loss: 0.6961%, acc.: 49.22%][Generator loss: 0.7226%]\n",
      "4088 [Discriminator loss: 0.6973%, acc.: 47.27%][Generator loss: 0.7213%]\n",
      "4089 [Discriminator loss: 0.6985%, acc.: 49.61%][Generator loss: 0.7215%]\n",
      "4090 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7200%]\n",
      "4091 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7204%]\n",
      "4092 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7201%]\n",
      "4093 [Discriminator loss: 0.6974%, acc.: 49.22%][Generator loss: 0.7218%]\n",
      "4094 [Discriminator loss: 0.6964%, acc.: 48.44%][Generator loss: 0.7228%]\n",
      "4095 [Discriminator loss: 0.6977%, acc.: 51.56%][Generator loss: 0.7212%]\n",
      "4096 [Discriminator loss: 0.6965%, acc.: 48.44%][Generator loss: 0.7199%]\n",
      "4097 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7202%]\n",
      "4098 [Discriminator loss: 0.6971%, acc.: 50.39%][Generator loss: 0.7197%]\n",
      "4099 [Discriminator loss: 0.6970%, acc.: 49.22%][Generator loss: 0.7206%]\n",
      "4100 [Discriminator loss: 0.6963%, acc.: 49.61%][Generator loss: 0.7238%]\n",
      "4101 [Discriminator loss: 0.6977%, acc.: 50.78%][Generator loss: 0.7219%]\n",
      "4102 [Discriminator loss: 0.6981%, acc.: 49.61%][Generator loss: 0.7203%]\n",
      "4103 [Discriminator loss: 0.6970%, acc.: 46.88%][Generator loss: 0.7206%]\n",
      "4104 [Discriminator loss: 0.6978%, acc.: 49.61%][Generator loss: 0.7209%]\n",
      "4105 [Discriminator loss: 0.6964%, acc.: 49.22%][Generator loss: 0.7218%]\n",
      "4106 [Discriminator loss: 0.6968%, acc.: 50.78%][Generator loss: 0.7205%]\n",
      "4107 [Discriminator loss: 0.6963%, acc.: 47.66%][Generator loss: 0.7212%]\n",
      "4108 [Discriminator loss: 0.6968%, acc.: 46.48%][Generator loss: 0.7216%]\n",
      "4109 [Discriminator loss: 0.6968%, acc.: 46.48%][Generator loss: 0.7216%]\n",
      "4110 [Discriminator loss: 0.6978%, acc.: 47.27%][Generator loss: 0.7208%]\n",
      "4111 [Discriminator loss: 0.6974%, acc.: 49.61%][Generator loss: 0.7208%]\n",
      "4112 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7209%]\n",
      "4113 [Discriminator loss: 0.6966%, acc.: 48.05%][Generator loss: 0.7228%]\n",
      "4114 [Discriminator loss: 0.6965%, acc.: 50.39%][Generator loss: 0.7210%]\n",
      "4115 [Discriminator loss: 0.6981%, acc.: 47.27%][Generator loss: 0.7199%]\n",
      "4116 [Discriminator loss: 0.6979%, acc.: 47.27%][Generator loss: 0.7208%]\n",
      "4117 [Discriminator loss: 0.6967%, acc.: 49.22%][Generator loss: 0.7203%]\n",
      "4118 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7205%]\n",
      "4119 [Discriminator loss: 0.6967%, acc.: 49.22%][Generator loss: 0.7210%]\n",
      "4120 [Discriminator loss: 0.6958%, acc.: 49.61%][Generator loss: 0.7206%]\n",
      "4121 [Discriminator loss: 0.6968%, acc.: 49.61%][Generator loss: 0.7212%]\n",
      "4122 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7211%]\n",
      "4123 [Discriminator loss: 0.6966%, acc.: 48.44%][Generator loss: 0.7206%]\n",
      "4124 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7199%]\n",
      "4125 [Discriminator loss: 0.6970%, acc.: 48.83%][Generator loss: 0.7203%]\n",
      "4126 [Discriminator loss: 0.6970%, acc.: 49.22%][Generator loss: 0.7215%]\n",
      "4127 [Discriminator loss: 0.6961%, acc.: 46.88%][Generator loss: 0.7228%]\n",
      "4128 [Discriminator loss: 0.6983%, acc.: 44.92%][Generator loss: 0.7203%]\n",
      "4129 [Discriminator loss: 0.6971%, acc.: 49.22%][Generator loss: 0.7216%]\n",
      "4130 [Discriminator loss: 0.6974%, acc.: 48.44%][Generator loss: 0.7208%]\n",
      "4131 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7201%]\n",
      "4132 [Discriminator loss: 0.6964%, acc.: 50.39%][Generator loss: 0.7203%]\n",
      "4133 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7214%]\n",
      "4134 [Discriminator loss: 0.6976%, acc.: 47.66%][Generator loss: 0.7199%]\n",
      "4135 [Discriminator loss: 0.6966%, acc.: 49.22%][Generator loss: 0.7224%]\n",
      "4136 [Discriminator loss: 0.6971%, acc.: 49.61%][Generator loss: 0.7221%]\n",
      "4137 [Discriminator loss: 0.6970%, acc.: 49.61%][Generator loss: 0.7199%]\n",
      "4138 [Discriminator loss: 0.6984%, acc.: 43.75%][Generator loss: 0.7194%]\n",
      "4139 [Discriminator loss: 0.6976%, acc.: 49.22%][Generator loss: 0.7209%]\n",
      "4140 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7212%]\n",
      "4141 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7199%]\n",
      "4142 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7202%]\n",
      "4143 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7198%]\n",
      "4144 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7206%]\n",
      "4145 [Discriminator loss: 0.6967%, acc.: 49.22%][Generator loss: 0.7211%]\n",
      "4146 [Discriminator loss: 0.6971%, acc.: 48.05%][Generator loss: 0.7202%]\n",
      "4147 [Discriminator loss: 0.6964%, acc.: 46.88%][Generator loss: 0.7228%]\n",
      "4148 [Discriminator loss: 0.6990%, acc.: 46.88%][Generator loss: 0.7211%]\n",
      "4149 [Discriminator loss: 0.6980%, acc.: 49.61%][Generator loss: 0.7200%]\n",
      "4150 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7195%]\n",
      "4151 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7196%]\n",
      "4152 [Discriminator loss: 0.6964%, acc.: 49.61%][Generator loss: 0.7197%]\n",
      "4153 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7200%]\n",
      "4154 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7198%]\n",
      "4155 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7212%]\n",
      "4156 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7222%]\n",
      "4157 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7205%]\n",
      "4158 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7197%]\n",
      "4159 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7202%]\n",
      "4160 [Discriminator loss: 0.6962%, acc.: 48.83%][Generator loss: 0.7212%]\n",
      "4161 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7203%]\n",
      "4162 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7191%]\n",
      "4163 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7199%]\n",
      "4164 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7188%]\n",
      "4165 [Discriminator loss: 0.6980%, acc.: 50.00%][Generator loss: 0.7192%]\n",
      "4166 [Discriminator loss: 0.6973%, acc.: 50.39%][Generator loss: 0.7201%]\n",
      "4167 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7207%]\n",
      "4168 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7206%]\n",
      "4169 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7202%]\n",
      "4170 [Discriminator loss: 0.6974%, acc.: 46.88%][Generator loss: 0.7200%]\n",
      "4171 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7195%]\n",
      "4172 [Discriminator loss: 0.6977%, acc.: 49.61%][Generator loss: 0.7188%]\n",
      "4173 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7199%]\n",
      "4174 [Discriminator loss: 0.6965%, acc.: 48.83%][Generator loss: 0.7208%]\n",
      "4175 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7194%]\n",
      "4176 [Discriminator loss: 0.6966%, acc.: 48.83%][Generator loss: 0.7211%]\n",
      "4177 [Discriminator loss: 0.6986%, acc.: 47.66%][Generator loss: 0.7201%]\n",
      "4178 [Discriminator loss: 0.6959%, acc.: 48.83%][Generator loss: 0.7198%]\n",
      "4179 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7204%]\n",
      "4180 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7203%]\n",
      "4181 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7199%]\n",
      "4182 [Discriminator loss: 0.6976%, acc.: 45.70%][Generator loss: 0.7207%]\n",
      "4183 [Discriminator loss: 0.6968%, acc.: 49.61%][Generator loss: 0.7203%]\n",
      "4184 [Discriminator loss: 0.6971%, acc.: 49.61%][Generator loss: 0.7201%]\n",
      "4185 [Discriminator loss: 0.6958%, acc.: 49.61%][Generator loss: 0.7213%]\n",
      "4186 [Discriminator loss: 0.6969%, acc.: 49.61%][Generator loss: 0.7203%]\n",
      "4187 [Discriminator loss: 0.6965%, acc.: 49.61%][Generator loss: 0.7212%]\n",
      "4188 [Discriminator loss: 0.6971%, acc.: 48.44%][Generator loss: 0.7226%]\n",
      "4189 [Discriminator loss: 0.6972%, acc.: 48.83%][Generator loss: 0.7204%]\n",
      "4190 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7212%]\n",
      "4191 [Discriminator loss: 0.6966%, acc.: 48.44%][Generator loss: 0.7202%]\n",
      "4192 [Discriminator loss: 0.6971%, acc.: 46.09%][Generator loss: 0.7205%]\n",
      "4193 [Discriminator loss: 0.6969%, acc.: 49.61%][Generator loss: 0.7197%]\n",
      "4194 [Discriminator loss: 0.6977%, acc.: 50.39%][Generator loss: 0.7206%]\n",
      "4195 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7203%]\n",
      "4196 [Discriminator loss: 0.6965%, acc.: 49.61%][Generator loss: 0.7201%]\n",
      "4197 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7191%]\n",
      "4198 [Discriminator loss: 0.6966%, acc.: 46.88%][Generator loss: 0.7193%]\n",
      "4199 [Discriminator loss: 0.6972%, acc.: 48.05%][Generator loss: 0.7206%]\n",
      "4200 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7209%]\n",
      "4201 [Discriminator loss: 0.6970%, acc.: 49.61%][Generator loss: 0.7215%]\n",
      "4202 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7202%]\n",
      "4203 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7202%]\n",
      "4204 [Discriminator loss: 0.6985%, acc.: 43.75%][Generator loss: 0.7201%]\n",
      "4205 [Discriminator loss: 0.6970%, acc.: 50.39%][Generator loss: 0.7188%]\n",
      "4206 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7199%]\n",
      "4207 [Discriminator loss: 0.6970%, acc.: 47.27%][Generator loss: 0.7219%]\n",
      "4208 [Discriminator loss: 0.6970%, acc.: 50.39%][Generator loss: 0.7221%]\n",
      "4209 [Discriminator loss: 0.6969%, acc.: 45.31%][Generator loss: 0.7212%]\n",
      "4210 [Discriminator loss: 0.6975%, acc.: 50.39%][Generator loss: 0.7190%]\n",
      "4211 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7189%]\n",
      "4212 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7207%]\n",
      "4213 [Discriminator loss: 0.6974%, acc.: 48.83%][Generator loss: 0.7198%]\n",
      "4214 [Discriminator loss: 0.6974%, acc.: 49.22%][Generator loss: 0.7191%]\n",
      "4215 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7196%]\n",
      "4216 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7194%]\n",
      "4217 [Discriminator loss: 0.6961%, acc.: 49.61%][Generator loss: 0.7198%]\n",
      "4218 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7197%]\n",
      "4219 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7191%]\n",
      "4220 [Discriminator loss: 0.6967%, acc.: 48.44%][Generator loss: 0.7203%]\n",
      "4221 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7197%]\n",
      "4222 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7210%]\n",
      "4223 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4224 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7197%]\n",
      "4225 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7190%]\n",
      "4226 [Discriminator loss: 0.6976%, acc.: 49.61%][Generator loss: 0.7221%]\n",
      "4227 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7208%]\n",
      "4228 [Discriminator loss: 0.6962%, acc.: 49.22%][Generator loss: 0.7205%]\n",
      "4229 [Discriminator loss: 0.6967%, acc.: 50.78%][Generator loss: 0.7202%]\n",
      "4230 [Discriminator loss: 0.6965%, acc.: 48.83%][Generator loss: 0.7208%]\n",
      "4231 [Discriminator loss: 0.6965%, acc.: 51.17%][Generator loss: 0.7191%]\n",
      "4232 [Discriminator loss: 0.6975%, acc.: 48.83%][Generator loss: 0.7202%]\n",
      "4233 [Discriminator loss: 0.6966%, acc.: 49.22%][Generator loss: 0.7195%]\n",
      "4234 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7186%]\n",
      "4235 [Discriminator loss: 0.6972%, acc.: 48.44%][Generator loss: 0.7207%]\n",
      "4236 [Discriminator loss: 0.6978%, acc.: 49.22%][Generator loss: 0.7197%]\n",
      "4237 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7198%]\n",
      "4238 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7211%]\n",
      "4239 [Discriminator loss: 0.6988%, acc.: 50.00%][Generator loss: 0.7208%]\n",
      "4240 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7205%]\n",
      "4241 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7196%]\n",
      "4242 [Discriminator loss: 0.6971%, acc.: 48.83%][Generator loss: 0.7200%]\n",
      "4243 [Discriminator loss: 0.6964%, acc.: 48.83%][Generator loss: 0.7187%]\n",
      "4244 [Discriminator loss: 0.6961%, acc.: 50.39%][Generator loss: 0.7195%]\n",
      "4245 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7190%]\n",
      "4246 [Discriminator loss: 0.6969%, acc.: 47.66%][Generator loss: 0.7199%]\n",
      "4247 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7196%]\n",
      "4248 [Discriminator loss: 0.6965%, acc.: 47.66%][Generator loss: 0.7207%]\n",
      "4249 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7203%]\n",
      "4250 [Discriminator loss: 0.6969%, acc.: 48.83%][Generator loss: 0.7211%]\n",
      "4251 [Discriminator loss: 0.6977%, acc.: 48.83%][Generator loss: 0.7205%]\n",
      "4252 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7186%]\n",
      "4253 [Discriminator loss: 0.6959%, acc.: 48.83%][Generator loss: 0.7202%]\n",
      "4254 [Discriminator loss: 0.6962%, acc.: 49.61%][Generator loss: 0.7183%]\n",
      "4255 [Discriminator loss: 0.6960%, acc.: 47.66%][Generator loss: 0.7204%]\n",
      "4256 [Discriminator loss: 0.6967%, acc.: 49.61%][Generator loss: 0.7199%]\n",
      "4257 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7204%]\n",
      "4258 [Discriminator loss: 0.6976%, acc.: 48.83%][Generator loss: 0.7198%]\n",
      "4259 [Discriminator loss: 0.6970%, acc.: 49.22%][Generator loss: 0.7189%]\n",
      "4260 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7185%]\n",
      "4261 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7191%]\n",
      "4262 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7195%]\n",
      "4263 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7186%]\n",
      "4264 [Discriminator loss: 0.6970%, acc.: 48.83%][Generator loss: 0.7199%]\n",
      "4265 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7194%]\n",
      "4266 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7197%]\n",
      "4267 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7193%]\n",
      "4268 [Discriminator loss: 0.6984%, acc.: 49.22%][Generator loss: 0.7210%]\n",
      "4269 [Discriminator loss: 0.6963%, acc.: 48.83%][Generator loss: 0.7206%]\n",
      "4270 [Discriminator loss: 0.6968%, acc.: 49.61%][Generator loss: 0.7187%]\n",
      "4271 [Discriminator loss: 0.6967%, acc.: 50.78%][Generator loss: 0.7190%]\n",
      "4272 [Discriminator loss: 0.6967%, acc.: 48.44%][Generator loss: 0.7189%]\n",
      "4273 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4274 [Discriminator loss: 0.6962%, acc.: 48.83%][Generator loss: 0.7196%]\n",
      "4275 [Discriminator loss: 0.6961%, acc.: 48.83%][Generator loss: 0.7202%]\n",
      "4276 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7196%]\n",
      "4277 [Discriminator loss: 0.6969%, acc.: 50.00%][Generator loss: 0.7195%]\n",
      "4278 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7213%]\n",
      "4279 [Discriminator loss: 0.6971%, acc.: 48.44%][Generator loss: 0.7189%]\n",
      "4280 [Discriminator loss: 0.6969%, acc.: 48.83%][Generator loss: 0.7185%]\n",
      "4281 [Discriminator loss: 0.6962%, acc.: 49.61%][Generator loss: 0.7185%]\n",
      "4282 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7190%]\n",
      "4283 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7185%]\n",
      "4284 [Discriminator loss: 0.6963%, acc.: 49.61%][Generator loss: 0.7188%]\n",
      "4285 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7200%]\n",
      "4286 [Discriminator loss: 0.6969%, acc.: 49.61%][Generator loss: 0.7201%]\n",
      "4287 [Discriminator loss: 0.6971%, acc.: 48.05%][Generator loss: 0.7189%]\n",
      "4288 [Discriminator loss: 0.6968%, acc.: 47.66%][Generator loss: 0.7184%]\n",
      "4289 [Discriminator loss: 0.6961%, acc.: 49.22%][Generator loss: 0.7198%]\n",
      "4290 [Discriminator loss: 0.6968%, acc.: 47.66%][Generator loss: 0.7188%]\n",
      "4291 [Discriminator loss: 0.6957%, acc.: 49.22%][Generator loss: 0.7187%]\n",
      "4292 [Discriminator loss: 0.6971%, acc.: 48.44%][Generator loss: 0.7189%]\n",
      "4293 [Discriminator loss: 0.6967%, acc.: 50.39%][Generator loss: 0.7176%]\n",
      "4294 [Discriminator loss: 0.6964%, acc.: 49.22%][Generator loss: 0.7199%]\n",
      "4295 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7202%]\n",
      "4296 [Discriminator loss: 0.6983%, acc.: 51.17%][Generator loss: 0.7207%]\n",
      "4297 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7186%]\n",
      "4298 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7176%]\n",
      "4299 [Discriminator loss: 0.6977%, acc.: 46.88%][Generator loss: 0.7186%]\n",
      "4300 [Discriminator loss: 0.6964%, acc.: 49.61%][Generator loss: 0.7203%]\n",
      "4301 [Discriminator loss: 0.6964%, acc.: 47.27%][Generator loss: 0.7195%]\n",
      "4302 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7193%]\n",
      "4303 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7184%]\n",
      "4304 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7197%]\n",
      "4305 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7188%]\n",
      "4306 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7204%]\n",
      "4307 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7186%]\n",
      "4308 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7202%]\n",
      "4309 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7207%]\n",
      "4310 [Discriminator loss: 0.6971%, acc.: 48.83%][Generator loss: 0.7186%]\n",
      "4311 [Discriminator loss: 0.6959%, acc.: 48.44%][Generator loss: 0.7196%]\n",
      "4312 [Discriminator loss: 0.6967%, acc.: 48.83%][Generator loss: 0.7183%]\n",
      "4313 [Discriminator loss: 0.6968%, acc.: 48.83%][Generator loss: 0.7196%]\n",
      "4314 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7198%]\n",
      "4315 [Discriminator loss: 0.6966%, acc.: 48.83%][Generator loss: 0.7197%]\n",
      "4316 [Discriminator loss: 0.6970%, acc.: 49.22%][Generator loss: 0.7196%]\n",
      "4317 [Discriminator loss: 0.6962%, acc.: 48.83%][Generator loss: 0.7186%]\n",
      "4318 [Discriminator loss: 0.6967%, acc.: 49.22%][Generator loss: 0.7194%]\n",
      "4319 [Discriminator loss: 0.6975%, acc.: 50.00%][Generator loss: 0.7194%]\n",
      "4320 [Discriminator loss: 0.6966%, acc.: 48.44%][Generator loss: 0.7190%]\n",
      "4321 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7206%]\n",
      "4322 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7196%]\n",
      "4323 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7187%]\n",
      "4324 [Discriminator loss: 0.6972%, acc.: 49.22%][Generator loss: 0.7183%]\n",
      "4325 [Discriminator loss: 0.6965%, acc.: 48.83%][Generator loss: 0.7188%]\n",
      "4326 [Discriminator loss: 0.6964%, acc.: 49.22%][Generator loss: 0.7187%]\n",
      "4327 [Discriminator loss: 0.6966%, acc.: 44.14%][Generator loss: 0.7204%]\n",
      "4328 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7188%]\n",
      "4329 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7187%]\n",
      "4330 [Discriminator loss: 0.6955%, acc.: 48.05%][Generator loss: 0.7202%]\n",
      "4331 [Discriminator loss: 0.6952%, acc.: 48.44%][Generator loss: 0.7208%]\n",
      "4332 [Discriminator loss: 0.6980%, acc.: 50.78%][Generator loss: 0.7190%]\n",
      "4333 [Discriminator loss: 0.6966%, acc.: 50.39%][Generator loss: 0.7183%]\n",
      "4334 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7204%]\n",
      "4335 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7188%]\n",
      "4336 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7191%]\n",
      "4337 [Discriminator loss: 0.6972%, acc.: 45.31%][Generator loss: 0.7197%]\n",
      "4338 [Discriminator loss: 0.6962%, acc.: 47.27%][Generator loss: 0.7181%]\n",
      "4339 [Discriminator loss: 0.6976%, acc.: 48.05%][Generator loss: 0.7179%]\n",
      "4340 [Discriminator loss: 0.6973%, acc.: 47.66%][Generator loss: 0.7178%]\n",
      "4341 [Discriminator loss: 0.6964%, acc.: 49.61%][Generator loss: 0.7182%]\n",
      "4342 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7195%]\n",
      "4343 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7182%]\n",
      "4344 [Discriminator loss: 0.6956%, acc.: 48.05%][Generator loss: 0.7194%]\n",
      "4345 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7187%]\n",
      "4346 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7188%]\n",
      "4347 [Discriminator loss: 0.6962%, acc.: 48.05%][Generator loss: 0.7190%]\n",
      "4348 [Discriminator loss: 0.6965%, acc.: 48.83%][Generator loss: 0.7185%]\n",
      "4349 [Discriminator loss: 0.6957%, acc.: 48.05%][Generator loss: 0.7210%]\n",
      "4350 [Discriminator loss: 0.6982%, acc.: 47.27%][Generator loss: 0.7189%]\n",
      "4351 [Discriminator loss: 0.6974%, acc.: 50.39%][Generator loss: 0.7188%]\n",
      "4352 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7181%]\n",
      "4353 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7187%]\n",
      "4354 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7185%]\n",
      "4355 [Discriminator loss: 0.6969%, acc.: 46.88%][Generator loss: 0.7189%]\n",
      "4356 [Discriminator loss: 0.6968%, acc.: 47.66%][Generator loss: 0.7181%]\n",
      "4357 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7188%]\n",
      "4358 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7184%]\n",
      "4359 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7190%]\n",
      "4360 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7181%]\n",
      "4361 [Discriminator loss: 0.6974%, acc.: 48.05%][Generator loss: 0.7186%]\n",
      "4362 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7200%]\n",
      "4363 [Discriminator loss: 0.6973%, acc.: 45.70%][Generator loss: 0.7172%]\n",
      "4364 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7184%]\n",
      "4365 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7196%]\n",
      "4366 [Discriminator loss: 0.6974%, acc.: 44.14%][Generator loss: 0.7190%]\n",
      "4367 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7176%]\n",
      "4368 [Discriminator loss: 0.6962%, acc.: 48.83%][Generator loss: 0.7172%]\n",
      "4369 [Discriminator loss: 0.6963%, acc.: 48.44%][Generator loss: 0.7195%]\n",
      "4370 [Discriminator loss: 0.6961%, acc.: 47.27%][Generator loss: 0.7198%]\n",
      "4371 [Discriminator loss: 0.6969%, acc.: 50.39%][Generator loss: 0.7182%]\n",
      "4372 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7184%]\n",
      "4373 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7184%]\n",
      "4374 [Discriminator loss: 0.6967%, acc.: 49.22%][Generator loss: 0.7187%]\n",
      "4375 [Discriminator loss: 0.6964%, acc.: 49.61%][Generator loss: 0.7179%]\n",
      "4376 [Discriminator loss: 0.6958%, acc.: 49.22%][Generator loss: 0.7186%]\n",
      "4377 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7209%]\n",
      "4378 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7186%]\n",
      "4379 [Discriminator loss: 0.6962%, acc.: 49.61%][Generator loss: 0.7188%]\n",
      "4380 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7193%]\n",
      "4381 [Discriminator loss: 0.6978%, acc.: 44.14%][Generator loss: 0.7181%]\n",
      "4382 [Discriminator loss: 0.6964%, acc.: 49.22%][Generator loss: 0.7180%]\n",
      "4383 [Discriminator loss: 0.6966%, acc.: 47.66%][Generator loss: 0.7185%]\n",
      "4384 [Discriminator loss: 0.6965%, acc.: 47.66%][Generator loss: 0.7173%]\n",
      "4385 [Discriminator loss: 0.6967%, acc.: 47.27%][Generator loss: 0.7199%]\n",
      "4386 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7194%]\n",
      "4387 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7197%]\n",
      "4388 [Discriminator loss: 0.6965%, acc.: 49.61%][Generator loss: 0.7174%]\n",
      "4389 [Discriminator loss: 0.6965%, acc.: 49.61%][Generator loss: 0.7178%]\n",
      "4390 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4391 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4392 [Discriminator loss: 0.6965%, acc.: 47.27%][Generator loss: 0.7182%]\n",
      "4393 [Discriminator loss: 0.6963%, acc.: 47.66%][Generator loss: 0.7184%]\n",
      "4394 [Discriminator loss: 0.6967%, acc.: 49.61%][Generator loss: 0.7192%]\n",
      "4395 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7180%]\n",
      "4396 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7181%]\n",
      "4397 [Discriminator loss: 0.6960%, acc.: 50.39%][Generator loss: 0.7172%]\n",
      "4398 [Discriminator loss: 0.6959%, acc.: 49.61%][Generator loss: 0.7183%]\n",
      "4399 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7189%]\n",
      "4400 [Discriminator loss: 0.6982%, acc.: 50.00%][Generator loss: 0.7180%]\n",
      "4401 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7182%]\n",
      "4402 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7176%]\n",
      "4403 [Discriminator loss: 0.6960%, acc.: 48.83%][Generator loss: 0.7192%]\n",
      "4404 [Discriminator loss: 0.6967%, acc.: 50.39%][Generator loss: 0.7190%]\n",
      "4405 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7173%]\n",
      "4406 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7204%]\n",
      "4407 [Discriminator loss: 0.6976%, acc.: 48.44%][Generator loss: 0.7190%]\n",
      "4408 [Discriminator loss: 0.6962%, acc.: 46.88%][Generator loss: 0.7200%]\n",
      "4409 [Discriminator loss: 0.6968%, acc.: 48.83%][Generator loss: 0.7186%]\n",
      "4410 [Discriminator loss: 0.6963%, acc.: 47.27%][Generator loss: 0.7180%]\n",
      "4411 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7187%]\n",
      "4412 [Discriminator loss: 0.6962%, acc.: 49.22%][Generator loss: 0.7184%]\n",
      "4413 [Discriminator loss: 0.6962%, acc.: 49.61%][Generator loss: 0.7183%]\n",
      "4414 [Discriminator loss: 0.6970%, acc.: 48.05%][Generator loss: 0.7177%]\n",
      "4415 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4416 [Discriminator loss: 0.6958%, acc.: 48.83%][Generator loss: 0.7185%]\n",
      "4417 [Discriminator loss: 0.6970%, acc.: 49.61%][Generator loss: 0.7170%]\n",
      "4418 [Discriminator loss: 0.6961%, acc.: 46.88%][Generator loss: 0.7186%]\n",
      "4419 [Discriminator loss: 0.6964%, acc.: 50.39%][Generator loss: 0.7182%]\n",
      "4420 [Discriminator loss: 0.6970%, acc.: 46.09%][Generator loss: 0.7172%]\n",
      "4421 [Discriminator loss: 0.6962%, acc.: 49.22%][Generator loss: 0.7178%]\n",
      "4422 [Discriminator loss: 0.6963%, acc.: 49.61%][Generator loss: 0.7171%]\n",
      "4423 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7174%]\n",
      "4424 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7170%]\n",
      "4425 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7187%]\n",
      "4426 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7174%]\n",
      "4427 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7188%]\n",
      "4428 [Discriminator loss: 0.6972%, acc.: 48.83%][Generator loss: 0.7190%]\n",
      "4429 [Discriminator loss: 0.6971%, acc.: 48.05%][Generator loss: 0.7177%]\n",
      "4430 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7179%]\n",
      "4431 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7182%]\n",
      "4432 [Discriminator loss: 0.6967%, acc.: 47.66%][Generator loss: 0.7183%]\n",
      "4433 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7184%]\n",
      "4434 [Discriminator loss: 0.6956%, acc.: 49.22%][Generator loss: 0.7184%]\n",
      "4435 [Discriminator loss: 0.6967%, acc.: 48.05%][Generator loss: 0.7177%]\n",
      "4436 [Discriminator loss: 0.6961%, acc.: 49.22%][Generator loss: 0.7176%]\n",
      "4437 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7180%]\n",
      "4438 [Discriminator loss: 0.6960%, acc.: 49.22%][Generator loss: 0.7189%]\n",
      "4439 [Discriminator loss: 0.6969%, acc.: 46.88%][Generator loss: 0.7182%]\n",
      "4440 [Discriminator loss: 0.6964%, acc.: 48.83%][Generator loss: 0.7181%]\n",
      "4441 [Discriminator loss: 0.6960%, acc.: 48.05%][Generator loss: 0.7187%]\n",
      "4442 [Discriminator loss: 0.6968%, acc.: 46.48%][Generator loss: 0.7171%]\n",
      "4443 [Discriminator loss: 0.6964%, acc.: 49.61%][Generator loss: 0.7180%]\n",
      "4444 [Discriminator loss: 0.6957%, acc.: 48.05%][Generator loss: 0.7166%]\n",
      "4445 [Discriminator loss: 0.6960%, acc.: 50.39%][Generator loss: 0.7169%]\n",
      "4446 [Discriminator loss: 0.6958%, acc.: 46.09%][Generator loss: 0.7172%]\n",
      "4447 [Discriminator loss: 0.6969%, acc.: 48.05%][Generator loss: 0.7200%]\n",
      "4448 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7180%]\n",
      "4449 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7179%]\n",
      "4450 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4451 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7197%]\n",
      "4452 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4453 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7170%]\n",
      "4454 [Discriminator loss: 0.6953%, acc.: 50.39%][Generator loss: 0.7169%]\n",
      "4455 [Discriminator loss: 0.6956%, acc.: 49.22%][Generator loss: 0.7173%]\n",
      "4456 [Discriminator loss: 0.6965%, acc.: 49.22%][Generator loss: 0.7179%]\n",
      "4457 [Discriminator loss: 0.6967%, acc.: 49.22%][Generator loss: 0.7178%]\n",
      "4458 [Discriminator loss: 0.6975%, acc.: 46.09%][Generator loss: 0.7185%]\n",
      "4459 [Discriminator loss: 0.6970%, acc.: 50.78%][Generator loss: 0.7174%]\n",
      "4460 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7178%]\n",
      "4461 [Discriminator loss: 0.6958%, acc.: 49.22%][Generator loss: 0.7181%]\n",
      "4462 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7192%]\n",
      "4463 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7186%]\n",
      "4464 [Discriminator loss: 0.6970%, acc.: 49.61%][Generator loss: 0.7179%]\n",
      "4465 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7182%]\n",
      "4466 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7179%]\n",
      "4467 [Discriminator loss: 0.6967%, acc.: 46.09%][Generator loss: 0.7174%]\n",
      "4468 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7171%]\n",
      "4469 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7172%]\n",
      "4470 [Discriminator loss: 0.6967%, acc.: 49.61%][Generator loss: 0.7174%]\n",
      "4471 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7180%]\n",
      "4472 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7178%]\n",
      "4473 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7160%]\n",
      "4474 [Discriminator loss: 0.6950%, acc.: 49.61%][Generator loss: 0.7184%]\n",
      "4475 [Discriminator loss: 0.6963%, acc.: 48.83%][Generator loss: 0.7190%]\n",
      "4476 [Discriminator loss: 0.6978%, acc.: 45.31%][Generator loss: 0.7179%]\n",
      "4477 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7165%]\n",
      "4478 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4479 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7190%]\n",
      "4480 [Discriminator loss: 0.6970%, acc.: 49.22%][Generator loss: 0.7169%]\n",
      "4481 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7173%]\n",
      "4482 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7170%]\n",
      "4483 [Discriminator loss: 0.6964%, acc.: 49.22%][Generator loss: 0.7170%]\n",
      "4484 [Discriminator loss: 0.6953%, acc.: 49.22%][Generator loss: 0.7173%]\n",
      "4485 [Discriminator loss: 0.6968%, acc.: 48.44%][Generator loss: 0.7173%]\n",
      "4486 [Discriminator loss: 0.6966%, acc.: 47.27%][Generator loss: 0.7177%]\n",
      "4487 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7175%]\n",
      "4488 [Discriminator loss: 0.6959%, acc.: 49.61%][Generator loss: 0.7175%]\n",
      "4489 [Discriminator loss: 0.6961%, acc.: 49.61%][Generator loss: 0.7173%]\n",
      "4490 [Discriminator loss: 0.6968%, acc.: 49.22%][Generator loss: 0.7160%]\n",
      "4491 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4492 [Discriminator loss: 0.6965%, acc.: 48.05%][Generator loss: 0.7181%]\n",
      "4493 [Discriminator loss: 0.6977%, acc.: 50.00%][Generator loss: 0.7191%]\n",
      "4494 [Discriminator loss: 0.6966%, acc.: 50.39%][Generator loss: 0.7177%]\n",
      "4495 [Discriminator loss: 0.6964%, acc.: 46.48%][Generator loss: 0.7167%]\n",
      "4496 [Discriminator loss: 0.6960%, acc.: 48.83%][Generator loss: 0.7171%]\n",
      "4497 [Discriminator loss: 0.6971%, acc.: 50.78%][Generator loss: 0.7171%]\n",
      "4498 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7174%]\n",
      "4499 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7168%]\n",
      "4500 [Discriminator loss: 0.6961%, acc.: 48.83%][Generator loss: 0.7179%]\n",
      "4501 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7173%]\n",
      "4502 [Discriminator loss: 0.6956%, acc.: 48.83%][Generator loss: 0.7178%]\n",
      "4503 [Discriminator loss: 0.6965%, acc.: 48.83%][Generator loss: 0.7175%]\n",
      "4504 [Discriminator loss: 0.6963%, acc.: 50.39%][Generator loss: 0.7179%]\n",
      "4505 [Discriminator loss: 0.6973%, acc.: 45.31%][Generator loss: 0.7180%]\n",
      "4506 [Discriminator loss: 0.6962%, acc.: 50.39%][Generator loss: 0.7171%]\n",
      "4507 [Discriminator loss: 0.6965%, acc.: 48.83%][Generator loss: 0.7172%]\n",
      "4508 [Discriminator loss: 0.6963%, acc.: 50.78%][Generator loss: 0.7181%]\n",
      "4509 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7200%]\n",
      "4510 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7208%]\n",
      "4511 [Discriminator loss: 0.6974%, acc.: 50.00%][Generator loss: 0.7178%]\n",
      "4512 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7175%]\n",
      "4513 [Discriminator loss: 0.6954%, acc.: 49.61%][Generator loss: 0.7172%]\n",
      "4514 [Discriminator loss: 0.6962%, acc.: 45.70%][Generator loss: 0.7170%]\n",
      "4515 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7172%]\n",
      "4516 [Discriminator loss: 0.6960%, acc.: 48.05%][Generator loss: 0.7171%]\n",
      "4517 [Discriminator loss: 0.6956%, acc.: 50.39%][Generator loss: 0.7177%]\n",
      "4518 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7177%]\n",
      "4519 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7167%]\n",
      "4520 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7170%]\n",
      "4521 [Discriminator loss: 0.6958%, acc.: 49.22%][Generator loss: 0.7185%]\n",
      "4522 [Discriminator loss: 0.6969%, acc.: 50.78%][Generator loss: 0.7160%]\n",
      "4523 [Discriminator loss: 0.6959%, acc.: 46.48%][Generator loss: 0.7181%]\n",
      "4524 [Discriminator loss: 0.6960%, acc.: 51.17%][Generator loss: 0.7177%]\n",
      "4525 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7187%]\n",
      "4526 [Discriminator loss: 0.6977%, acc.: 47.66%][Generator loss: 0.7183%]\n",
      "4527 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7178%]\n",
      "4528 [Discriminator loss: 0.6959%, acc.: 49.22%][Generator loss: 0.7156%]\n",
      "4529 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7173%]\n",
      "4530 [Discriminator loss: 0.6960%, acc.: 46.09%][Generator loss: 0.7170%]\n",
      "4531 [Discriminator loss: 0.6961%, acc.: 50.39%][Generator loss: 0.7173%]\n",
      "4532 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7176%]\n",
      "4533 [Discriminator loss: 0.6965%, acc.: 51.56%][Generator loss: 0.7168%]\n",
      "4534 [Discriminator loss: 0.6964%, acc.: 48.83%][Generator loss: 0.7176%]\n",
      "4535 [Discriminator loss: 0.6966%, acc.: 49.22%][Generator loss: 0.7169%]\n",
      "4536 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7174%]\n",
      "4537 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7162%]\n",
      "4538 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4539 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7169%]\n",
      "4540 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7169%]\n",
      "4541 [Discriminator loss: 0.6975%, acc.: 45.31%][Generator loss: 0.7163%]\n",
      "4542 [Discriminator loss: 0.6965%, acc.: 49.61%][Generator loss: 0.7161%]\n",
      "4543 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7159%]\n",
      "4544 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7164%]\n",
      "4545 [Discriminator loss: 0.6966%, acc.: 48.05%][Generator loss: 0.7169%]\n",
      "4546 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7189%]\n",
      "4547 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7184%]\n",
      "4548 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7194%]\n",
      "4549 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7177%]\n",
      "4550 [Discriminator loss: 0.6965%, acc.: 50.39%][Generator loss: 0.7156%]\n",
      "4551 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7163%]\n",
      "4552 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7167%]\n",
      "4553 [Discriminator loss: 0.6963%, acc.: 46.09%][Generator loss: 0.7172%]\n",
      "4554 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7172%]\n",
      "4555 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7155%]\n",
      "4556 [Discriminator loss: 0.6967%, acc.: 50.78%][Generator loss: 0.7164%]\n",
      "4557 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7171%]\n",
      "4558 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7170%]\n",
      "4559 [Discriminator loss: 0.6963%, acc.: 49.61%][Generator loss: 0.7165%]\n",
      "4560 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7177%]\n",
      "4561 [Discriminator loss: 0.6957%, acc.: 48.83%][Generator loss: 0.7175%]\n",
      "4562 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7177%]\n",
      "4563 [Discriminator loss: 0.6954%, acc.: 49.22%][Generator loss: 0.7177%]\n",
      "4564 [Discriminator loss: 0.6967%, acc.: 45.31%][Generator loss: 0.7169%]\n",
      "4565 [Discriminator loss: 0.6965%, acc.: 50.39%][Generator loss: 0.7167%]\n",
      "4566 [Discriminator loss: 0.6957%, acc.: 49.22%][Generator loss: 0.7162%]\n",
      "4567 [Discriminator loss: 0.6971%, acc.: 50.00%][Generator loss: 0.7171%]\n",
      "4568 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7175%]\n",
      "4569 [Discriminator loss: 0.6963%, acc.: 50.78%][Generator loss: 0.7161%]\n",
      "4570 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7163%]\n",
      "4571 [Discriminator loss: 0.6964%, acc.: 47.27%][Generator loss: 0.7165%]\n",
      "4572 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7166%]\n",
      "4573 [Discriminator loss: 0.6967%, acc.: 48.83%][Generator loss: 0.7171%]\n",
      "4574 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7167%]\n",
      "4575 [Discriminator loss: 0.6966%, acc.: 50.39%][Generator loss: 0.7158%]\n",
      "4576 [Discriminator loss: 0.6960%, acc.: 46.48%][Generator loss: 0.7161%]\n",
      "4577 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7158%]\n",
      "4578 [Discriminator loss: 0.6962%, acc.: 46.48%][Generator loss: 0.7175%]\n",
      "4579 [Discriminator loss: 0.6960%, acc.: 48.05%][Generator loss: 0.7171%]\n",
      "4580 [Discriminator loss: 0.6973%, acc.: 46.09%][Generator loss: 0.7162%]\n",
      "4581 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7163%]\n",
      "4582 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7159%]\n",
      "4583 [Discriminator loss: 0.6958%, acc.: 49.61%][Generator loss: 0.7170%]\n",
      "4584 [Discriminator loss: 0.6965%, acc.: 48.05%][Generator loss: 0.7173%]\n",
      "4585 [Discriminator loss: 0.6959%, acc.: 51.17%][Generator loss: 0.7162%]\n",
      "4586 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7162%]\n",
      "4587 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7174%]\n",
      "4588 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7162%]\n",
      "4589 [Discriminator loss: 0.6968%, acc.: 49.61%][Generator loss: 0.7161%]\n",
      "4590 [Discriminator loss: 0.6960%, acc.: 48.05%][Generator loss: 0.7163%]\n",
      "4591 [Discriminator loss: 0.6964%, acc.: 47.27%][Generator loss: 0.7162%]\n",
      "4592 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7167%]\n",
      "4593 [Discriminator loss: 0.6967%, acc.: 49.61%][Generator loss: 0.7157%]\n",
      "4594 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7159%]\n",
      "4595 [Discriminator loss: 0.6956%, acc.: 49.22%][Generator loss: 0.7159%]\n",
      "4596 [Discriminator loss: 0.6960%, acc.: 46.48%][Generator loss: 0.7165%]\n",
      "4597 [Discriminator loss: 0.6972%, acc.: 50.39%][Generator loss: 0.7163%]\n",
      "4598 [Discriminator loss: 0.6964%, acc.: 49.61%][Generator loss: 0.7157%]\n",
      "4599 [Discriminator loss: 0.6959%, acc.: 50.39%][Generator loss: 0.7160%]\n",
      "4600 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7159%]\n",
      "4601 [Discriminator loss: 0.6950%, acc.: 49.61%][Generator loss: 0.7167%]\n",
      "4602 [Discriminator loss: 0.6961%, acc.: 46.88%][Generator loss: 0.7162%]\n",
      "4603 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7191%]\n",
      "4604 [Discriminator loss: 0.6970%, acc.: 50.00%][Generator loss: 0.7167%]\n",
      "4605 [Discriminator loss: 0.6960%, acc.: 49.22%][Generator loss: 0.7162%]\n",
      "4606 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7166%]\n",
      "4607 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7154%]\n",
      "4608 [Discriminator loss: 0.6958%, acc.: 44.53%][Generator loss: 0.7160%]\n",
      "4609 [Discriminator loss: 0.6985%, acc.: 45.31%][Generator loss: 0.7150%]\n",
      "4610 [Discriminator loss: 0.6972%, acc.: 48.44%][Generator loss: 0.7160%]\n",
      "4611 [Discriminator loss: 0.6963%, acc.: 48.44%][Generator loss: 0.7157%]\n",
      "4612 [Discriminator loss: 0.6955%, acc.: 49.61%][Generator loss: 0.7166%]\n",
      "4613 [Discriminator loss: 0.6962%, acc.: 48.44%][Generator loss: 0.7162%]\n",
      "4614 [Discriminator loss: 0.6967%, acc.: 44.92%][Generator loss: 0.7157%]\n",
      "4615 [Discriminator loss: 0.6960%, acc.: 49.22%][Generator loss: 0.7152%]\n",
      "4616 [Discriminator loss: 0.6959%, acc.: 49.61%][Generator loss: 0.7154%]\n",
      "4617 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7163%]\n",
      "4618 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7158%]\n",
      "4619 [Discriminator loss: 0.6959%, acc.: 47.66%][Generator loss: 0.7154%]\n",
      "4620 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7217%]\n",
      "4621 [Discriminator loss: 0.6978%, acc.: 50.00%][Generator loss: 0.7180%]\n",
      "4622 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7157%]\n",
      "4623 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7155%]\n",
      "4624 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7158%]\n",
      "4625 [Discriminator loss: 0.6966%, acc.: 49.61%][Generator loss: 0.7159%]\n",
      "4626 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7166%]\n",
      "4627 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7159%]\n",
      "4628 [Discriminator loss: 0.6952%, acc.: 49.22%][Generator loss: 0.7165%]\n",
      "4629 [Discriminator loss: 0.6963%, acc.: 46.88%][Generator loss: 0.7164%]\n",
      "4630 [Discriminator loss: 0.6959%, acc.: 50.78%][Generator loss: 0.7155%]\n",
      "4631 [Discriminator loss: 0.6958%, acc.: 49.61%][Generator loss: 0.7161%]\n",
      "4632 [Discriminator loss: 0.6967%, acc.: 46.09%][Generator loss: 0.7160%]\n",
      "4633 [Discriminator loss: 0.6966%, acc.: 49.61%][Generator loss: 0.7156%]\n",
      "4634 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7161%]\n",
      "4635 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7165%]\n",
      "4636 [Discriminator loss: 0.6966%, acc.: 49.61%][Generator loss: 0.7155%]\n",
      "4637 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7167%]\n",
      "4638 [Discriminator loss: 0.6963%, acc.: 47.27%][Generator loss: 0.7152%]\n",
      "4639 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7152%]\n",
      "4640 [Discriminator loss: 0.6968%, acc.: 49.22%][Generator loss: 0.7153%]\n",
      "4641 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7154%]\n",
      "4642 [Discriminator loss: 0.6954%, acc.: 49.22%][Generator loss: 0.7170%]\n",
      "4643 [Discriminator loss: 0.6964%, acc.: 49.22%][Generator loss: 0.7152%]\n",
      "4644 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7152%]\n",
      "4645 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7153%]\n",
      "4646 [Discriminator loss: 0.6963%, acc.: 46.88%][Generator loss: 0.7159%]\n",
      "4647 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7150%]\n",
      "4648 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7164%]\n",
      "4649 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7161%]\n",
      "4650 [Discriminator loss: 0.6954%, acc.: 49.61%][Generator loss: 0.7161%]\n",
      "4651 [Discriminator loss: 0.6966%, acc.: 47.66%][Generator loss: 0.7163%]\n",
      "4652 [Discriminator loss: 0.6958%, acc.: 48.83%][Generator loss: 0.7172%]\n",
      "4653 [Discriminator loss: 0.6973%, acc.: 49.61%][Generator loss: 0.7163%]\n",
      "4654 [Discriminator loss: 0.6964%, acc.: 48.44%][Generator loss: 0.7158%]\n",
      "4655 [Discriminator loss: 0.6961%, acc.: 49.61%][Generator loss: 0.7160%]\n",
      "4656 [Discriminator loss: 0.6966%, acc.: 49.61%][Generator loss: 0.7157%]\n",
      "4657 [Discriminator loss: 0.6957%, acc.: 49.22%][Generator loss: 0.7160%]\n",
      "4658 [Discriminator loss: 0.6962%, acc.: 49.22%][Generator loss: 0.7166%]\n",
      "4659 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7156%]\n",
      "4660 [Discriminator loss: 0.6963%, acc.: 48.05%][Generator loss: 0.7149%]\n",
      "4661 [Discriminator loss: 0.6955%, acc.: 49.22%][Generator loss: 0.7154%]\n",
      "4662 [Discriminator loss: 0.6962%, acc.: 48.44%][Generator loss: 0.7167%]\n",
      "4663 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7160%]\n",
      "4664 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7182%]\n",
      "4665 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7160%]\n",
      "4666 [Discriminator loss: 0.6961%, acc.: 49.61%][Generator loss: 0.7159%]\n",
      "4667 [Discriminator loss: 0.6959%, acc.: 45.70%][Generator loss: 0.7165%]\n",
      "4668 [Discriminator loss: 0.6956%, acc.: 50.39%][Generator loss: 0.7167%]\n",
      "4669 [Discriminator loss: 0.6969%, acc.: 46.09%][Generator loss: 0.7148%]\n",
      "4670 [Discriminator loss: 0.6967%, acc.: 48.44%][Generator loss: 0.7155%]\n",
      "4671 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7156%]\n",
      "4672 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7171%]\n",
      "4673 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7168%]\n",
      "4674 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7150%]\n",
      "4675 [Discriminator loss: 0.6957%, acc.: 49.61%][Generator loss: 0.7159%]\n",
      "4676 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7156%]\n",
      "4677 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7156%]\n",
      "4678 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7170%]\n",
      "4679 [Discriminator loss: 0.6963%, acc.: 47.27%][Generator loss: 0.7174%]\n",
      "4680 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7157%]\n",
      "4681 [Discriminator loss: 0.6955%, acc.: 49.61%][Generator loss: 0.7159%]\n",
      "4682 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7161%]\n",
      "4683 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7148%]\n",
      "4684 [Discriminator loss: 0.6960%, acc.: 47.66%][Generator loss: 0.7168%]\n",
      "4685 [Discriminator loss: 0.6972%, acc.: 49.61%][Generator loss: 0.7151%]\n",
      "4686 [Discriminator loss: 0.6958%, acc.: 48.83%][Generator loss: 0.7157%]\n",
      "4687 [Discriminator loss: 0.6965%, acc.: 50.39%][Generator loss: 0.7149%]\n",
      "4688 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7164%]\n",
      "4689 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7154%]\n",
      "4690 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7170%]\n",
      "4691 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7169%]\n",
      "4692 [Discriminator loss: 0.6971%, acc.: 48.44%][Generator loss: 0.7149%]\n",
      "4693 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7160%]\n",
      "4694 [Discriminator loss: 0.6959%, acc.: 48.05%][Generator loss: 0.7160%]\n",
      "4695 [Discriminator loss: 0.6963%, acc.: 49.61%][Generator loss: 0.7152%]\n",
      "4696 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7157%]\n",
      "4697 [Discriminator loss: 0.6956%, acc.: 48.44%][Generator loss: 0.7151%]\n",
      "4698 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7150%]\n",
      "4699 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7149%]\n",
      "4700 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7151%]\n",
      "4701 [Discriminator loss: 0.6952%, acc.: 49.22%][Generator loss: 0.7176%]\n",
      "4702 [Discriminator loss: 0.6969%, acc.: 47.27%][Generator loss: 0.7192%]\n",
      "4703 [Discriminator loss: 0.6969%, acc.: 50.39%][Generator loss: 0.7165%]\n",
      "4704 [Discriminator loss: 0.6960%, acc.: 48.44%][Generator loss: 0.7158%]\n",
      "4705 [Discriminator loss: 0.6963%, acc.: 46.48%][Generator loss: 0.7157%]\n",
      "4706 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7153%]\n",
      "4707 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7148%]\n",
      "4708 [Discriminator loss: 0.6953%, acc.: 49.22%][Generator loss: 0.7153%]\n",
      "4709 [Discriminator loss: 0.6963%, acc.: 48.83%][Generator loss: 0.7152%]\n",
      "4710 [Discriminator loss: 0.6954%, acc.: 49.22%][Generator loss: 0.7160%]\n",
      "4711 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7165%]\n",
      "4712 [Discriminator loss: 0.6971%, acc.: 46.48%][Generator loss: 0.7152%]\n",
      "4713 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7153%]\n",
      "4714 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7150%]\n",
      "4715 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7164%]\n",
      "4716 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7164%]\n",
      "4717 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7161%]\n",
      "4718 [Discriminator loss: 0.6955%, acc.: 48.83%][Generator loss: 0.7156%]\n",
      "4719 [Discriminator loss: 0.6958%, acc.: 49.61%][Generator loss: 0.7150%]\n",
      "4720 [Discriminator loss: 0.6952%, acc.: 46.48%][Generator loss: 0.7160%]\n",
      "4721 [Discriminator loss: 0.6970%, acc.: 48.05%][Generator loss: 0.7166%]\n",
      "4722 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7163%]\n",
      "4723 [Discriminator loss: 0.6966%, acc.: 48.05%][Generator loss: 0.7158%]\n",
      "4724 [Discriminator loss: 0.6960%, acc.: 49.22%][Generator loss: 0.7158%]\n",
      "4725 [Discriminator loss: 0.6956%, acc.: 50.78%][Generator loss: 0.7145%]\n",
      "4726 [Discriminator loss: 0.6957%, acc.: 48.05%][Generator loss: 0.7146%]\n",
      "4727 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7158%]\n",
      "4728 [Discriminator loss: 0.6963%, acc.: 49.22%][Generator loss: 0.7158%]\n",
      "4729 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7161%]\n",
      "4730 [Discriminator loss: 0.6954%, acc.: 48.44%][Generator loss: 0.7166%]\n",
      "4731 [Discriminator loss: 0.6959%, acc.: 48.83%][Generator loss: 0.7155%]\n",
      "4732 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7149%]\n",
      "4733 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7163%]\n",
      "4734 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7162%]\n",
      "4735 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7149%]\n",
      "4736 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7152%]\n",
      "4737 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7151%]\n",
      "4738 [Discriminator loss: 0.6955%, acc.: 48.83%][Generator loss: 0.7152%]\n",
      "4739 [Discriminator loss: 0.6961%, acc.: 49.61%][Generator loss: 0.7153%]\n",
      "4740 [Discriminator loss: 0.6961%, acc.: 49.22%][Generator loss: 0.7157%]\n",
      "4741 [Discriminator loss: 0.6964%, acc.: 49.61%][Generator loss: 0.7160%]\n",
      "4742 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7152%]\n",
      "4743 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7147%]\n",
      "4744 [Discriminator loss: 0.6955%, acc.: 49.61%][Generator loss: 0.7153%]\n",
      "4745 [Discriminator loss: 0.6954%, acc.: 45.31%][Generator loss: 0.7165%]\n",
      "4746 [Discriminator loss: 0.6977%, acc.: 49.61%][Generator loss: 0.7144%]\n",
      "4747 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7159%]\n",
      "4748 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7153%]\n",
      "4749 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7158%]\n",
      "4750 [Discriminator loss: 0.6956%, acc.: 47.66%][Generator loss: 0.7153%]\n",
      "4751 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7155%]\n",
      "4752 [Discriminator loss: 0.6962%, acc.: 49.22%][Generator loss: 0.7147%]\n",
      "4753 [Discriminator loss: 0.6951%, acc.: 48.83%][Generator loss: 0.7161%]\n",
      "4754 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7183%]\n",
      "4755 [Discriminator loss: 0.6972%, acc.: 50.00%][Generator loss: 0.7165%]\n",
      "4756 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7153%]\n",
      "4757 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7156%]\n",
      "4758 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7143%]\n",
      "4759 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7154%]\n",
      "4760 [Discriminator loss: 0.6958%, acc.: 49.22%][Generator loss: 0.7157%]\n",
      "4761 [Discriminator loss: 0.6966%, acc.: 49.22%][Generator loss: 0.7151%]\n",
      "4762 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7149%]\n",
      "4763 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7155%]\n",
      "4764 [Discriminator loss: 0.6962%, acc.: 48.44%][Generator loss: 0.7161%]\n",
      "4765 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7146%]\n",
      "4766 [Discriminator loss: 0.6950%, acc.: 49.22%][Generator loss: 0.7149%]\n",
      "4767 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7155%]\n",
      "4768 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7158%]\n",
      "4769 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7156%]\n",
      "4770 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7155%]\n",
      "4771 [Discriminator loss: 0.6955%, acc.: 49.22%][Generator loss: 0.7153%]\n",
      "4772 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7154%]\n",
      "4773 [Discriminator loss: 0.6960%, acc.: 46.88%][Generator loss: 0.7152%]\n",
      "4774 [Discriminator loss: 0.6962%, acc.: 47.66%][Generator loss: 0.7152%]\n",
      "4775 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7147%]\n",
      "4776 [Discriminator loss: 0.6955%, acc.: 47.66%][Generator loss: 0.7145%]\n",
      "4777 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7153%]\n",
      "4778 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7153%]\n",
      "4779 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7164%]\n",
      "4780 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7154%]\n",
      "4781 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7152%]\n",
      "4782 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7159%]\n",
      "4783 [Discriminator loss: 0.6953%, acc.: 49.61%][Generator loss: 0.7157%]\n",
      "4784 [Discriminator loss: 0.6964%, acc.: 47.27%][Generator loss: 0.7144%]\n",
      "4785 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7154%]\n",
      "4786 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7156%]\n",
      "4787 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7156%]\n",
      "4788 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7162%]\n",
      "4789 [Discriminator loss: 0.6972%, acc.: 49.61%][Generator loss: 0.7167%]\n",
      "4790 [Discriminator loss: 0.6962%, acc.: 48.44%][Generator loss: 0.7171%]\n",
      "4791 [Discriminator loss: 0.6961%, acc.: 51.56%][Generator loss: 0.7149%]\n",
      "4792 [Discriminator loss: 0.6958%, acc.: 48.44%][Generator loss: 0.7144%]\n",
      "4793 [Discriminator loss: 0.6962%, acc.: 46.09%][Generator loss: 0.7144%]\n",
      "4794 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7143%]\n",
      "4795 [Discriminator loss: 0.6968%, acc.: 50.00%][Generator loss: 0.7150%]\n",
      "4796 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7139%]\n",
      "4797 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7152%]\n",
      "4798 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7153%]\n",
      "4799 [Discriminator loss: 0.6945%, acc.: 49.22%][Generator loss: 0.7173%]\n",
      "4800 [Discriminator loss: 0.6974%, acc.: 46.09%][Generator loss: 0.7141%]\n",
      "4801 [Discriminator loss: 0.6965%, acc.: 49.61%][Generator loss: 0.7144%]\n",
      "4802 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7150%]\n",
      "4803 [Discriminator loss: 0.6954%, acc.: 48.05%][Generator loss: 0.7141%]\n",
      "4804 [Discriminator loss: 0.6961%, acc.: 44.14%][Generator loss: 0.7148%]\n",
      "4805 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7145%]\n",
      "4806 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7152%]\n",
      "4807 [Discriminator loss: 0.6958%, acc.: 47.66%][Generator loss: 0.7151%]\n",
      "4808 [Discriminator loss: 0.6964%, acc.: 49.61%][Generator loss: 0.7136%]\n",
      "4809 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7149%]\n",
      "4810 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7147%]\n",
      "4811 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7150%]\n",
      "4812 [Discriminator loss: 0.6962%, acc.: 48.44%][Generator loss: 0.7138%]\n",
      "4813 [Discriminator loss: 0.6964%, acc.: 49.22%][Generator loss: 0.7141%]\n",
      "4814 [Discriminator loss: 0.6959%, acc.: 48.83%][Generator loss: 0.7148%]\n",
      "4815 [Discriminator loss: 0.6956%, acc.: 50.39%][Generator loss: 0.7141%]\n",
      "4816 [Discriminator loss: 0.6948%, acc.: 49.61%][Generator loss: 0.7151%]\n",
      "4817 [Discriminator loss: 0.6959%, acc.: 50.39%][Generator loss: 0.7152%]\n",
      "4818 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7147%]\n",
      "4819 [Discriminator loss: 0.6953%, acc.: 49.61%][Generator loss: 0.7147%]\n",
      "4820 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7150%]\n",
      "4821 [Discriminator loss: 0.6967%, acc.: 45.31%][Generator loss: 0.7149%]\n",
      "4822 [Discriminator loss: 0.6961%, acc.: 49.22%][Generator loss: 0.7144%]\n",
      "4823 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7145%]\n",
      "4824 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7145%]\n",
      "4825 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7149%]\n",
      "4826 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7147%]\n",
      "4827 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7143%]\n",
      "4828 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7152%]\n",
      "4829 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7145%]\n",
      "4830 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7151%]\n",
      "4831 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7145%]\n",
      "4832 [Discriminator loss: 0.6968%, acc.: 47.66%][Generator loss: 0.7148%]\n",
      "4833 [Discriminator loss: 0.6957%, acc.: 49.61%][Generator loss: 0.7154%]\n",
      "4834 [Discriminator loss: 0.6955%, acc.: 50.39%][Generator loss: 0.7146%]\n",
      "4835 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7145%]\n",
      "4836 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7157%]\n",
      "4837 [Discriminator loss: 0.6956%, acc.: 48.83%][Generator loss: 0.7155%]\n",
      "4838 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7261%]\n",
      "4839 [Discriminator loss: 0.6998%, acc.: 48.83%][Generator loss: 0.7207%]\n",
      "4840 [Discriminator loss: 0.6977%, acc.: 48.05%][Generator loss: 0.7151%]\n",
      "4841 [Discriminator loss: 0.6962%, acc.: 50.78%][Generator loss: 0.7138%]\n",
      "4842 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7137%]\n",
      "4843 [Discriminator loss: 0.6962%, acc.: 48.05%][Generator loss: 0.7157%]\n",
      "4844 [Discriminator loss: 0.6956%, acc.: 50.78%][Generator loss: 0.7148%]\n",
      "4845 [Discriminator loss: 0.6952%, acc.: 48.83%][Generator loss: 0.7143%]\n",
      "4846 [Discriminator loss: 0.6952%, acc.: 49.61%][Generator loss: 0.7142%]\n",
      "4847 [Discriminator loss: 0.6952%, acc.: 48.83%][Generator loss: 0.7140%]\n",
      "4848 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7142%]\n",
      "4849 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7144%]\n",
      "4850 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7143%]\n",
      "4851 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7144%]\n",
      "4852 [Discriminator loss: 0.6958%, acc.: 46.88%][Generator loss: 0.7140%]\n",
      "4853 [Discriminator loss: 0.6966%, acc.: 48.05%][Generator loss: 0.7140%]\n",
      "4854 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7144%]\n",
      "4855 [Discriminator loss: 0.6951%, acc.: 49.22%][Generator loss: 0.7151%]\n",
      "4856 [Discriminator loss: 0.6961%, acc.: 50.78%][Generator loss: 0.7158%]\n",
      "4857 [Discriminator loss: 0.6960%, acc.: 47.66%][Generator loss: 0.7159%]\n",
      "4858 [Discriminator loss: 0.6967%, acc.: 50.00%][Generator loss: 0.7139%]\n",
      "4859 [Discriminator loss: 0.6949%, acc.: 49.61%][Generator loss: 0.7140%]\n",
      "4860 [Discriminator loss: 0.6950%, acc.: 49.22%][Generator loss: 0.7137%]\n",
      "4861 [Discriminator loss: 0.6961%, acc.: 47.66%][Generator loss: 0.7144%]\n",
      "4862 [Discriminator loss: 0.6969%, acc.: 47.66%][Generator loss: 0.7139%]\n",
      "4863 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7137%]\n",
      "4864 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7140%]\n",
      "4865 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7141%]\n",
      "4866 [Discriminator loss: 0.6956%, acc.: 49.61%][Generator loss: 0.7136%]\n",
      "4867 [Discriminator loss: 0.6958%, acc.: 49.61%][Generator loss: 0.7148%]\n",
      "4868 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7146%]\n",
      "4869 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7148%]\n",
      "4870 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7136%]\n",
      "4871 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7131%]\n",
      "4872 [Discriminator loss: 0.6958%, acc.: 49.22%][Generator loss: 0.7134%]\n",
      "4873 [Discriminator loss: 0.6958%, acc.: 49.61%][Generator loss: 0.7146%]\n",
      "4874 [Discriminator loss: 0.6963%, acc.: 49.61%][Generator loss: 0.7148%]\n",
      "4875 [Discriminator loss: 0.6956%, acc.: 50.78%][Generator loss: 0.7143%]\n",
      "4876 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7150%]\n",
      "4877 [Discriminator loss: 0.6956%, acc.: 47.66%][Generator loss: 0.7142%]\n",
      "4878 [Discriminator loss: 0.6968%, acc.: 47.27%][Generator loss: 0.7131%]\n",
      "4879 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7132%]\n",
      "4880 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7132%]\n",
      "4881 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7137%]\n",
      "4882 [Discriminator loss: 0.6950%, acc.: 49.61%][Generator loss: 0.7142%]\n",
      "4883 [Discriminator loss: 0.6955%, acc.: 48.05%][Generator loss: 0.7143%]\n",
      "4884 [Discriminator loss: 0.6955%, acc.: 49.61%][Generator loss: 0.7156%]\n",
      "4885 [Discriminator loss: 0.6960%, acc.: 49.22%][Generator loss: 0.7145%]\n",
      "4886 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7148%]\n",
      "4887 [Discriminator loss: 0.6957%, acc.: 48.05%][Generator loss: 0.7146%]\n",
      "4888 [Discriminator loss: 0.6953%, acc.: 49.61%][Generator loss: 0.7137%]\n",
      "4889 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7141%]\n",
      "4890 [Discriminator loss: 0.6959%, acc.: 48.83%][Generator loss: 0.7146%]\n",
      "4891 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7145%]\n",
      "4892 [Discriminator loss: 0.6959%, acc.: 50.39%][Generator loss: 0.7140%]\n",
      "4893 [Discriminator loss: 0.6954%, acc.: 48.83%][Generator loss: 0.7150%]\n",
      "4894 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7147%]\n",
      "4895 [Discriminator loss: 0.6953%, acc.: 48.05%][Generator loss: 0.7147%]\n",
      "4896 [Discriminator loss: 0.6966%, acc.: 49.22%][Generator loss: 0.7137%]\n",
      "4897 [Discriminator loss: 0.6954%, acc.: 46.88%][Generator loss: 0.7138%]\n",
      "4898 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7141%]\n",
      "4899 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7138%]\n",
      "4900 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7149%]\n",
      "4901 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7147%]\n",
      "4902 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7144%]\n",
      "4903 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7149%]\n",
      "4904 [Discriminator loss: 0.6968%, acc.: 45.70%][Generator loss: 0.7150%]\n",
      "4905 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7139%]\n",
      "4906 [Discriminator loss: 0.6963%, acc.: 48.05%][Generator loss: 0.7146%]\n",
      "4907 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7133%]\n",
      "4908 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7142%]\n",
      "4909 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7138%]\n",
      "4910 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7143%]\n",
      "4911 [Discriminator loss: 0.6951%, acc.: 49.22%][Generator loss: 0.7135%]\n",
      "4912 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7133%]\n",
      "4913 [Discriminator loss: 0.6951%, acc.: 47.66%][Generator loss: 0.7143%]\n",
      "4914 [Discriminator loss: 0.6957%, acc.: 48.83%][Generator loss: 0.7145%]\n",
      "4915 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7146%]\n",
      "4916 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7141%]\n",
      "4917 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7151%]\n",
      "4918 [Discriminator loss: 0.6956%, acc.: 49.22%][Generator loss: 0.7140%]\n",
      "4919 [Discriminator loss: 0.6954%, acc.: 49.22%][Generator loss: 0.7136%]\n",
      "4920 [Discriminator loss: 0.6957%, acc.: 49.22%][Generator loss: 0.7139%]\n",
      "4921 [Discriminator loss: 0.6959%, acc.: 46.09%][Generator loss: 0.7147%]\n",
      "4922 [Discriminator loss: 0.6964%, acc.: 48.83%][Generator loss: 0.7134%]\n",
      "4923 [Discriminator loss: 0.6946%, acc.: 49.61%][Generator loss: 0.7151%]\n",
      "4924 [Discriminator loss: 0.6964%, acc.: 48.05%][Generator loss: 0.7136%]\n",
      "4925 [Discriminator loss: 0.6955%, acc.: 50.39%][Generator loss: 0.7132%]\n",
      "4926 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7133%]\n",
      "4927 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7149%]\n",
      "4928 [Discriminator loss: 0.6963%, acc.: 50.00%][Generator loss: 0.7133%]\n",
      "4929 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7138%]\n",
      "4930 [Discriminator loss: 0.6951%, acc.: 48.05%][Generator loss: 0.7141%]\n",
      "4931 [Discriminator loss: 0.6955%, acc.: 50.39%][Generator loss: 0.7150%]\n",
      "4932 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7135%]\n",
      "4933 [Discriminator loss: 0.6949%, acc.: 49.61%][Generator loss: 0.7141%]\n",
      "4934 [Discriminator loss: 0.6951%, acc.: 49.61%][Generator loss: 0.7146%]\n",
      "4935 [Discriminator loss: 0.6964%, acc.: 48.05%][Generator loss: 0.7139%]\n",
      "4936 [Discriminator loss: 0.6963%, acc.: 48.05%][Generator loss: 0.7134%]\n",
      "4937 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7140%]\n",
      "4938 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7140%]\n",
      "4939 [Discriminator loss: 0.6951%, acc.: 50.39%][Generator loss: 0.7137%]\n",
      "4940 [Discriminator loss: 0.6958%, acc.: 49.61%][Generator loss: 0.7136%]\n",
      "4941 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7136%]\n",
      "4942 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7140%]\n",
      "4943 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7129%]\n",
      "4944 [Discriminator loss: 0.6945%, acc.: 49.22%][Generator loss: 0.7147%]\n",
      "4945 [Discriminator loss: 0.6957%, acc.: 50.39%][Generator loss: 0.7137%]\n",
      "4946 [Discriminator loss: 0.6964%, acc.: 48.05%][Generator loss: 0.7137%]\n",
      "4947 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7140%]\n",
      "4948 [Discriminator loss: 0.6956%, acc.: 50.39%][Generator loss: 0.7143%]\n",
      "4949 [Discriminator loss: 0.6956%, acc.: 48.44%][Generator loss: 0.7157%]\n",
      "4950 [Discriminator loss: 0.6962%, acc.: 49.61%][Generator loss: 0.7137%]\n",
      "4951 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7142%]\n",
      "4952 [Discriminator loss: 0.6949%, acc.: 49.22%][Generator loss: 0.7138%]\n",
      "4953 [Discriminator loss: 0.6950%, acc.: 48.05%][Generator loss: 0.7134%]\n",
      "4954 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7135%]\n",
      "4955 [Discriminator loss: 0.6958%, acc.: 49.22%][Generator loss: 0.7135%]\n",
      "4956 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7140%]\n",
      "4957 [Discriminator loss: 0.6966%, acc.: 50.00%][Generator loss: 0.7141%]\n",
      "4958 [Discriminator loss: 0.6957%, acc.: 48.83%][Generator loss: 0.7152%]\n",
      "4959 [Discriminator loss: 0.6965%, acc.: 50.78%][Generator loss: 0.7131%]\n",
      "4960 [Discriminator loss: 0.6952%, acc.: 48.44%][Generator loss: 0.7143%]\n",
      "4961 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7138%]\n",
      "4962 [Discriminator loss: 0.6953%, acc.: 49.61%][Generator loss: 0.7138%]\n",
      "4963 [Discriminator loss: 0.6958%, acc.: 48.05%][Generator loss: 0.7132%]\n",
      "4964 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7140%]\n",
      "4965 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7143%]\n",
      "4966 [Discriminator loss: 0.6953%, acc.: 50.39%][Generator loss: 0.7130%]\n",
      "4967 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7138%]\n",
      "4968 [Discriminator loss: 0.6963%, acc.: 46.88%][Generator loss: 0.7139%]\n",
      "4969 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7140%]\n",
      "4970 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7138%]\n",
      "4971 [Discriminator loss: 0.6955%, acc.: 49.22%][Generator loss: 0.7143%]\n",
      "4972 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7139%]\n",
      "4973 [Discriminator loss: 0.6954%, acc.: 48.83%][Generator loss: 0.7135%]\n",
      "4974 [Discriminator loss: 0.6956%, acc.: 50.39%][Generator loss: 0.7135%]\n",
      "4975 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7137%]\n",
      "4976 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7145%]\n",
      "4977 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7130%]\n",
      "4978 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7132%]\n",
      "4979 [Discriminator loss: 0.6957%, acc.: 48.83%][Generator loss: 0.7133%]\n",
      "4980 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7137%]\n",
      "4981 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7133%]\n",
      "4982 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7144%]\n",
      "4983 [Discriminator loss: 0.6954%, acc.: 49.61%][Generator loss: 0.7136%]\n",
      "4984 [Discriminator loss: 0.6959%, acc.: 47.66%][Generator loss: 0.7132%]\n",
      "4985 [Discriminator loss: 0.6959%, acc.: 49.22%][Generator loss: 0.7129%]\n",
      "4986 [Discriminator loss: 0.6951%, acc.: 49.22%][Generator loss: 0.7133%]\n",
      "4987 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7142%]\n",
      "4988 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7136%]\n",
      "4989 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7133%]\n",
      "4990 [Discriminator loss: 0.6954%, acc.: 47.66%][Generator loss: 0.7137%]\n",
      "4991 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7132%]\n",
      "4992 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7141%]\n",
      "4993 [Discriminator loss: 0.6952%, acc.: 48.44%][Generator loss: 0.7137%]\n",
      "4994 [Discriminator loss: 0.6957%, acc.: 49.22%][Generator loss: 0.7141%]\n",
      "4995 [Discriminator loss: 0.6961%, acc.: 50.39%][Generator loss: 0.7137%]\n",
      "4996 [Discriminator loss: 0.6961%, acc.: 46.88%][Generator loss: 0.7134%]\n",
      "4997 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7132%]\n",
      "4998 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7131%]\n",
      "4999 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7138%]\n",
      "5000 [Discriminator loss: 0.6956%, acc.: 47.27%][Generator loss: 0.7129%]\n",
      "5001 [Discriminator loss: 0.6958%, acc.: 45.31%][Generator loss: 0.7126%]\n",
      "5002 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7127%]\n",
      "5003 [Discriminator loss: 0.6942%, acc.: 50.00%][Generator loss: 0.7149%]\n",
      "5004 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7147%]\n",
      "5005 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7137%]\n",
      "5006 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7127%]\n",
      "5007 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7135%]\n",
      "5008 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7144%]\n",
      "5009 [Discriminator loss: 0.6956%, acc.: 50.39%][Generator loss: 0.7128%]\n",
      "5010 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7129%]\n",
      "5011 [Discriminator loss: 0.6969%, acc.: 42.97%][Generator loss: 0.7126%]\n",
      "5012 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7126%]\n",
      "5013 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7123%]\n",
      "5014 [Discriminator loss: 0.6950%, acc.: 49.61%][Generator loss: 0.7127%]\n",
      "5015 [Discriminator loss: 0.6948%, acc.: 50.39%][Generator loss: 0.7136%]\n",
      "5016 [Discriminator loss: 0.6952%, acc.: 50.39%][Generator loss: 0.7138%]\n",
      "5017 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7142%]\n",
      "5018 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7132%]\n",
      "5019 [Discriminator loss: 0.6952%, acc.: 49.61%][Generator loss: 0.7133%]\n",
      "5020 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7132%]\n",
      "5021 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7148%]\n",
      "5022 [Discriminator loss: 0.6966%, acc.: 50.39%][Generator loss: 0.7124%]\n",
      "5023 [Discriminator loss: 0.6948%, acc.: 49.22%][Generator loss: 0.7133%]\n",
      "5024 [Discriminator loss: 0.6947%, acc.: 50.39%][Generator loss: 0.7128%]\n",
      "5025 [Discriminator loss: 0.6953%, acc.: 50.39%][Generator loss: 0.7125%]\n",
      "5026 [Discriminator loss: 0.6951%, acc.: 49.22%][Generator loss: 0.7139%]\n",
      "5027 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7128%]\n",
      "5028 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7136%]\n",
      "5029 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7141%]\n",
      "5030 [Discriminator loss: 0.6952%, acc.: 48.44%][Generator loss: 0.7135%]\n",
      "5031 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7123%]\n",
      "5032 [Discriminator loss: 0.6953%, acc.: 49.22%][Generator loss: 0.7124%]\n",
      "5033 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7138%]\n",
      "5034 [Discriminator loss: 0.6962%, acc.: 50.00%][Generator loss: 0.7132%]\n",
      "5035 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7127%]\n",
      "5036 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7143%]\n",
      "5037 [Discriminator loss: 0.6965%, acc.: 48.83%][Generator loss: 0.7155%]\n",
      "5038 [Discriminator loss: 0.6957%, acc.: 49.22%][Generator loss: 0.7161%]\n",
      "5039 [Discriminator loss: 0.6962%, acc.: 49.22%][Generator loss: 0.7133%]\n",
      "5040 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7129%]\n",
      "5041 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7126%]\n",
      "5042 [Discriminator loss: 0.6947%, acc.: 49.61%][Generator loss: 0.7130%]\n",
      "5043 [Discriminator loss: 0.6965%, acc.: 48.05%][Generator loss: 0.7128%]\n",
      "5044 [Discriminator loss: 0.6956%, acc.: 49.61%][Generator loss: 0.7131%]\n",
      "5045 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7125%]\n",
      "5046 [Discriminator loss: 0.6948%, acc.: 49.22%][Generator loss: 0.7137%]\n",
      "5047 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7115%]\n",
      "5048 [Discriminator loss: 0.6965%, acc.: 44.92%][Generator loss: 0.7122%]\n",
      "5049 [Discriminator loss: 0.6956%, acc.: 47.27%][Generator loss: 0.7138%]\n",
      "5050 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7125%]\n",
      "5051 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7127%]\n",
      "5052 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7146%]\n",
      "5053 [Discriminator loss: 0.6957%, acc.: 50.39%][Generator loss: 0.7134%]\n",
      "5054 [Discriminator loss: 0.6957%, acc.: 50.78%][Generator loss: 0.7124%]\n",
      "5055 [Discriminator loss: 0.6955%, acc.: 50.78%][Generator loss: 0.7130%]\n",
      "5056 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7129%]\n",
      "5057 [Discriminator loss: 0.6948%, acc.: 49.61%][Generator loss: 0.7142%]\n",
      "5058 [Discriminator loss: 0.6960%, acc.: 50.78%][Generator loss: 0.7124%]\n",
      "5059 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7137%]\n",
      "5060 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7151%]\n",
      "5061 [Discriminator loss: 0.6960%, acc.: 50.00%][Generator loss: 0.7134%]\n",
      "5062 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7124%]\n",
      "5063 [Discriminator loss: 0.6950%, acc.: 48.44%][Generator loss: 0.7124%]\n",
      "5064 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7124%]\n",
      "5065 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7133%]\n",
      "5066 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7137%]\n",
      "5067 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7129%]\n",
      "5068 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7126%]\n",
      "5069 [Discriminator loss: 0.6952%, acc.: 49.61%][Generator loss: 0.7129%]\n",
      "5070 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7133%]\n",
      "5071 [Discriminator loss: 0.6960%, acc.: 49.61%][Generator loss: 0.7121%]\n",
      "5072 [Discriminator loss: 0.6959%, acc.: 45.70%][Generator loss: 0.7124%]\n",
      "5073 [Discriminator loss: 0.6961%, acc.: 49.61%][Generator loss: 0.7117%]\n",
      "5074 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7140%]\n",
      "5075 [Discriminator loss: 0.6963%, acc.: 50.39%][Generator loss: 0.7129%]\n",
      "5076 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7124%]\n",
      "5077 [Discriminator loss: 0.6948%, acc.: 48.83%][Generator loss: 0.7116%]\n",
      "5078 [Discriminator loss: 0.6950%, acc.: 49.22%][Generator loss: 0.7128%]\n",
      "5079 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7129%]\n",
      "5080 [Discriminator loss: 0.6950%, acc.: 49.22%][Generator loss: 0.7128%]\n",
      "5081 [Discriminator loss: 0.6953%, acc.: 48.44%][Generator loss: 0.7140%]\n",
      "5082 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7146%]\n",
      "5083 [Discriminator loss: 0.6959%, acc.: 48.44%][Generator loss: 0.7149%]\n",
      "5084 [Discriminator loss: 0.6964%, acc.: 50.00%][Generator loss: 0.7133%]\n",
      "5085 [Discriminator loss: 0.6955%, acc.: 50.39%][Generator loss: 0.7122%]\n",
      "5086 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7129%]\n",
      "5087 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7139%]\n",
      "5088 [Discriminator loss: 0.6955%, acc.: 51.17%][Generator loss: 0.7135%]\n",
      "5089 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7124%]\n",
      "5090 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7126%]\n",
      "5091 [Discriminator loss: 0.6950%, acc.: 48.05%][Generator loss: 0.7123%]\n",
      "5092 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7127%]\n",
      "5093 [Discriminator loss: 0.6947%, acc.: 49.61%][Generator loss: 0.7141%]\n",
      "5094 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7126%]\n",
      "5095 [Discriminator loss: 0.6954%, acc.: 48.05%][Generator loss: 0.7128%]\n",
      "5096 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7132%]\n",
      "5097 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7148%]\n",
      "5098 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7172%]\n",
      "5099 [Discriminator loss: 0.6973%, acc.: 50.00%][Generator loss: 0.7144%]\n",
      "5100 [Discriminator loss: 0.6953%, acc.: 50.39%][Generator loss: 0.7128%]\n",
      "5101 [Discriminator loss: 0.6952%, acc.: 51.17%][Generator loss: 0.7125%]\n",
      "5102 [Discriminator loss: 0.6954%, acc.: 48.44%][Generator loss: 0.7120%]\n",
      "5103 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7136%]\n",
      "5104 [Discriminator loss: 0.6950%, acc.: 49.61%][Generator loss: 0.7124%]\n",
      "5105 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7132%]\n",
      "5106 [Discriminator loss: 0.6955%, acc.: 49.61%][Generator loss: 0.7144%]\n",
      "5107 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7138%]\n",
      "5108 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7130%]\n",
      "5109 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7135%]\n",
      "5110 [Discriminator loss: 0.6951%, acc.: 50.78%][Generator loss: 0.7126%]\n",
      "5111 [Discriminator loss: 0.6953%, acc.: 49.61%][Generator loss: 0.7123%]\n",
      "5112 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7129%]\n",
      "5113 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7125%]\n",
      "5114 [Discriminator loss: 0.6947%, acc.: 49.61%][Generator loss: 0.7135%]\n",
      "5115 [Discriminator loss: 0.6953%, acc.: 51.17%][Generator loss: 0.7122%]\n",
      "5116 [Discriminator loss: 0.6959%, acc.: 46.88%][Generator loss: 0.7128%]\n",
      "5117 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7128%]\n",
      "5118 [Discriminator loss: 0.6950%, acc.: 49.22%][Generator loss: 0.7131%]\n",
      "5119 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7128%]\n",
      "5120 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7118%]\n",
      "5121 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7123%]\n",
      "5122 [Discriminator loss: 0.6962%, acc.: 46.48%][Generator loss: 0.7121%]\n",
      "5123 [Discriminator loss: 0.6957%, acc.: 49.61%][Generator loss: 0.7128%]\n",
      "5124 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7134%]\n",
      "5125 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7133%]\n",
      "5126 [Discriminator loss: 0.6954%, acc.: 50.78%][Generator loss: 0.7131%]\n",
      "5127 [Discriminator loss: 0.6947%, acc.: 49.22%][Generator loss: 0.7128%]\n",
      "5128 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7116%]\n",
      "5129 [Discriminator loss: 0.6953%, acc.: 46.48%][Generator loss: 0.7128%]\n",
      "5130 [Discriminator loss: 0.6949%, acc.: 49.61%][Generator loss: 0.7137%]\n",
      "5131 [Discriminator loss: 0.6957%, acc.: 48.83%][Generator loss: 0.7122%]\n",
      "5132 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7130%]\n",
      "5133 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7120%]\n",
      "5134 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7127%]\n",
      "5135 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7130%]\n",
      "5136 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7148%]\n",
      "5137 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7147%]\n",
      "5138 [Discriminator loss: 0.6961%, acc.: 49.22%][Generator loss: 0.7121%]\n",
      "5139 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7118%]\n",
      "5140 [Discriminator loss: 0.6947%, acc.: 49.22%][Generator loss: 0.7122%]\n",
      "5141 [Discriminator loss: 0.6959%, acc.: 49.61%][Generator loss: 0.7120%]\n",
      "5142 [Discriminator loss: 0.6951%, acc.: 47.27%][Generator loss: 0.7116%]\n",
      "5143 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7119%]\n",
      "5144 [Discriminator loss: 0.6952%, acc.: 48.05%][Generator loss: 0.7117%]\n",
      "5145 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7118%]\n",
      "5146 [Discriminator loss: 0.6949%, acc.: 46.88%][Generator loss: 0.7122%]\n",
      "5147 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7126%]\n",
      "5148 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7129%]\n",
      "5149 [Discriminator loss: 0.6954%, acc.: 50.39%][Generator loss: 0.7124%]\n",
      "5150 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7118%]\n",
      "5151 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7128%]\n",
      "5152 [Discriminator loss: 0.6959%, acc.: 49.22%][Generator loss: 0.7129%]\n",
      "5153 [Discriminator loss: 0.6957%, acc.: 49.61%][Generator loss: 0.7120%]\n",
      "5154 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7130%]\n",
      "5155 [Discriminator loss: 0.6961%, acc.: 48.44%][Generator loss: 0.7117%]\n",
      "5156 [Discriminator loss: 0.6951%, acc.: 49.61%][Generator loss: 0.7130%]\n",
      "5157 [Discriminator loss: 0.6956%, acc.: 49.22%][Generator loss: 0.7120%]\n",
      "5158 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7116%]\n",
      "5159 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7125%]\n",
      "5160 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7127%]\n",
      "5161 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7121%]\n",
      "5162 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7122%]\n",
      "5163 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7115%]\n",
      "5164 [Discriminator loss: 0.6944%, acc.: 50.00%][Generator loss: 0.7120%]\n",
      "5165 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7125%]\n",
      "5166 [Discriminator loss: 0.6963%, acc.: 48.83%][Generator loss: 0.7140%]\n",
      "5167 [Discriminator loss: 0.6957%, acc.: 51.95%][Generator loss: 0.7127%]\n",
      "5168 [Discriminator loss: 0.6958%, acc.: 50.78%][Generator loss: 0.7112%]\n",
      "5169 [Discriminator loss: 0.6948%, acc.: 48.44%][Generator loss: 0.7114%]\n",
      "5170 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7115%]\n",
      "5171 [Discriminator loss: 0.6955%, acc.: 48.83%][Generator loss: 0.7116%]\n",
      "5172 [Discriminator loss: 0.6955%, acc.: 48.83%][Generator loss: 0.7117%]\n",
      "5173 [Discriminator loss: 0.6949%, acc.: 50.39%][Generator loss: 0.7117%]\n",
      "5174 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7116%]\n",
      "5175 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7118%]\n",
      "5176 [Discriminator loss: 0.6952%, acc.: 48.44%][Generator loss: 0.7118%]\n",
      "5177 [Discriminator loss: 0.6958%, acc.: 47.27%][Generator loss: 0.7120%]\n",
      "5178 [Discriminator loss: 0.6954%, acc.: 50.78%][Generator loss: 0.7116%]\n",
      "5179 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7116%]\n",
      "5180 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7123%]\n",
      "5181 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7111%]\n",
      "5182 [Discriminator loss: 0.6957%, acc.: 49.22%][Generator loss: 0.7111%]\n",
      "5183 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7117%]\n",
      "5184 [Discriminator loss: 0.6954%, acc.: 48.05%][Generator loss: 0.7127%]\n",
      "5185 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7115%]\n",
      "5186 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7115%]\n",
      "5187 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7114%]\n",
      "5188 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7110%]\n",
      "5189 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7111%]\n",
      "5190 [Discriminator loss: 0.6948%, acc.: 49.61%][Generator loss: 0.7113%]\n",
      "5191 [Discriminator loss: 0.6949%, acc.: 49.22%][Generator loss: 0.7112%]\n",
      "5192 [Discriminator loss: 0.6950%, acc.: 50.39%][Generator loss: 0.7112%]\n",
      "5193 [Discriminator loss: 0.6948%, acc.: 48.05%][Generator loss: 0.7114%]\n",
      "5194 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7119%]\n",
      "5195 [Discriminator loss: 0.6953%, acc.: 50.39%][Generator loss: 0.7122%]\n",
      "5196 [Discriminator loss: 0.6952%, acc.: 48.83%][Generator loss: 0.7142%]\n",
      "5197 [Discriminator loss: 0.6964%, acc.: 49.22%][Generator loss: 0.7140%]\n",
      "5198 [Discriminator loss: 0.6960%, acc.: 48.83%][Generator loss: 0.7118%]\n",
      "5199 [Discriminator loss: 0.6950%, acc.: 50.39%][Generator loss: 0.7124%]\n",
      "5200 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7135%]\n",
      "5201 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7115%]\n",
      "5202 [Discriminator loss: 0.6948%, acc.: 48.83%][Generator loss: 0.7116%]\n",
      "5203 [Discriminator loss: 0.6945%, acc.: 48.44%][Generator loss: 0.7121%]\n",
      "5204 [Discriminator loss: 0.6954%, acc.: 50.78%][Generator loss: 0.7113%]\n",
      "5205 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7117%]\n",
      "5206 [Discriminator loss: 0.6947%, acc.: 49.61%][Generator loss: 0.7124%]\n",
      "5207 [Discriminator loss: 0.6954%, acc.: 50.39%][Generator loss: 0.7104%]\n",
      "5208 [Discriminator loss: 0.6960%, acc.: 45.31%][Generator loss: 0.7116%]\n",
      "5209 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7114%]\n",
      "5210 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7110%]\n",
      "5211 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7111%]\n",
      "5212 [Discriminator loss: 0.6944%, acc.: 49.61%][Generator loss: 0.7114%]\n",
      "5213 [Discriminator loss: 0.6951%, acc.: 48.05%][Generator loss: 0.7112%]\n",
      "5214 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7115%]\n",
      "5215 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7117%]\n",
      "5216 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7106%]\n",
      "5217 [Discriminator loss: 0.6952%, acc.: 48.44%][Generator loss: 0.7116%]\n",
      "5218 [Discriminator loss: 0.6940%, acc.: 51.17%][Generator loss: 0.7133%]\n",
      "5219 [Discriminator loss: 0.6974%, acc.: 49.22%][Generator loss: 0.7101%]\n",
      "5220 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7121%]\n",
      "5221 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7119%]\n",
      "5222 [Discriminator loss: 0.6942%, acc.: 50.00%][Generator loss: 0.7140%]\n",
      "5223 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7120%]\n",
      "5224 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7118%]\n",
      "5225 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7129%]\n",
      "5226 [Discriminator loss: 0.6949%, acc.: 51.17%][Generator loss: 0.7108%]\n",
      "5227 [Discriminator loss: 0.6949%, acc.: 49.22%][Generator loss: 0.7111%]\n",
      "5228 [Discriminator loss: 0.6948%, acc.: 50.78%][Generator loss: 0.7113%]\n",
      "5229 [Discriminator loss: 0.6938%, acc.: 50.39%][Generator loss: 0.7118%]\n",
      "5230 [Discriminator loss: 0.6969%, acc.: 49.61%][Generator loss: 0.7102%]\n",
      "5231 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7121%]\n",
      "5232 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7121%]\n",
      "5233 [Discriminator loss: 0.6948%, acc.: 48.83%][Generator loss: 0.7116%]\n",
      "5234 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7106%]\n",
      "5235 [Discriminator loss: 0.6948%, acc.: 49.61%][Generator loss: 0.7108%]\n",
      "5236 [Discriminator loss: 0.6955%, acc.: 50.78%][Generator loss: 0.7109%]\n",
      "5237 [Discriminator loss: 0.6947%, acc.: 47.27%][Generator loss: 0.7133%]\n",
      "5238 [Discriminator loss: 0.6962%, acc.: 49.22%][Generator loss: 0.7110%]\n",
      "5239 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7105%]\n",
      "5240 [Discriminator loss: 0.6944%, acc.: 50.00%][Generator loss: 0.7106%]\n",
      "5241 [Discriminator loss: 0.6947%, acc.: 50.39%][Generator loss: 0.7110%]\n",
      "5242 [Discriminator loss: 0.6945%, acc.: 49.61%][Generator loss: 0.7111%]\n",
      "5243 [Discriminator loss: 0.6952%, acc.: 49.61%][Generator loss: 0.7109%]\n",
      "5244 [Discriminator loss: 0.6944%, acc.: 50.39%][Generator loss: 0.7109%]\n",
      "5245 [Discriminator loss: 0.6956%, acc.: 49.22%][Generator loss: 0.7106%]\n",
      "5246 [Discriminator loss: 0.6951%, acc.: 48.05%][Generator loss: 0.7114%]\n",
      "5247 [Discriminator loss: 0.6955%, acc.: 49.61%][Generator loss: 0.7110%]\n",
      "5248 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7105%]\n",
      "5249 [Discriminator loss: 0.6944%, acc.: 49.22%][Generator loss: 0.7126%]\n",
      "5250 [Discriminator loss: 0.6957%, acc.: 51.56%][Generator loss: 0.7107%]\n",
      "5251 [Discriminator loss: 0.6954%, acc.: 47.66%][Generator loss: 0.7106%]\n",
      "5252 [Discriminator loss: 0.6953%, acc.: 50.39%][Generator loss: 0.7111%]\n",
      "5253 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7105%]\n",
      "5254 [Discriminator loss: 0.6954%, acc.: 46.09%][Generator loss: 0.7107%]\n",
      "5255 [Discriminator loss: 0.6949%, acc.: 48.83%][Generator loss: 0.7101%]\n",
      "5256 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7109%]\n",
      "5257 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7112%]\n",
      "5258 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7110%]\n",
      "5259 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7103%]\n",
      "5260 [Discriminator loss: 0.6942%, acc.: 50.00%][Generator loss: 0.7111%]\n",
      "5261 [Discriminator loss: 0.6952%, acc.: 48.44%][Generator loss: 0.7112%]\n",
      "5262 [Discriminator loss: 0.6952%, acc.: 49.61%][Generator loss: 0.7110%]\n",
      "5263 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7117%]\n",
      "5264 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7112%]\n",
      "5265 [Discriminator loss: 0.6953%, acc.: 51.17%][Generator loss: 0.7105%]\n",
      "5266 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7109%]\n",
      "5267 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7109%]\n",
      "5268 [Discriminator loss: 0.6950%, acc.: 48.83%][Generator loss: 0.7115%]\n",
      "5269 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7107%]\n",
      "5270 [Discriminator loss: 0.6950%, acc.: 49.61%][Generator loss: 0.7104%]\n",
      "5271 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7126%]\n",
      "5272 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7110%]\n",
      "5273 [Discriminator loss: 0.6958%, acc.: 47.66%][Generator loss: 0.7102%]\n",
      "5274 [Discriminator loss: 0.6948%, acc.: 49.22%][Generator loss: 0.7106%]\n",
      "5275 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7102%]\n",
      "5276 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7113%]\n",
      "5277 [Discriminator loss: 0.6950%, acc.: 47.66%][Generator loss: 0.7103%]\n",
      "5278 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7106%]\n",
      "5279 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7110%]\n",
      "5280 [Discriminator loss: 0.6954%, acc.: 49.22%][Generator loss: 0.7108%]\n",
      "5281 [Discriminator loss: 0.6957%, acc.: 51.17%][Generator loss: 0.7104%]\n",
      "5282 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7103%]\n",
      "5283 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7100%]\n",
      "5284 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7134%]\n",
      "5285 [Discriminator loss: 0.6965%, acc.: 50.00%][Generator loss: 0.7125%]\n",
      "5286 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7102%]\n",
      "5287 [Discriminator loss: 0.6951%, acc.: 50.39%][Generator loss: 0.7098%]\n",
      "5288 [Discriminator loss: 0.6943%, acc.: 50.00%][Generator loss: 0.7101%]\n",
      "5289 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7110%]\n",
      "5290 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7102%]\n",
      "5291 [Discriminator loss: 0.6943%, acc.: 50.00%][Generator loss: 0.7113%]\n",
      "5292 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7115%]\n",
      "5293 [Discriminator loss: 0.6953%, acc.: 49.61%][Generator loss: 0.7102%]\n",
      "5294 [Discriminator loss: 0.6952%, acc.: 50.78%][Generator loss: 0.7098%]\n",
      "5295 [Discriminator loss: 0.6950%, acc.: 49.61%][Generator loss: 0.7104%]\n",
      "5296 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7104%]\n",
      "5297 [Discriminator loss: 0.6950%, acc.: 48.05%][Generator loss: 0.7098%]\n",
      "5298 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7103%]\n",
      "5299 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7109%]\n",
      "5300 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7102%]\n",
      "5301 [Discriminator loss: 0.6951%, acc.: 49.61%][Generator loss: 0.7096%]\n",
      "5302 [Discriminator loss: 0.6946%, acc.: 49.61%][Generator loss: 0.7106%]\n",
      "5303 [Discriminator loss: 0.6952%, acc.: 50.39%][Generator loss: 0.7100%]\n",
      "5304 [Discriminator loss: 0.6950%, acc.: 49.61%][Generator loss: 0.7100%]\n",
      "5305 [Discriminator loss: 0.6954%, acc.: 46.48%][Generator loss: 0.7107%]\n",
      "5306 [Discriminator loss: 0.6951%, acc.: 51.17%][Generator loss: 0.7092%]\n",
      "5307 [Discriminator loss: 0.6942%, acc.: 50.00%][Generator loss: 0.7098%]\n",
      "5308 [Discriminator loss: 0.6949%, acc.: 46.09%][Generator loss: 0.7101%]\n",
      "5309 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7103%]\n",
      "5310 [Discriminator loss: 0.6952%, acc.: 49.61%][Generator loss: 0.7110%]\n",
      "5311 [Discriminator loss: 0.6955%, acc.: 50.78%][Generator loss: 0.7115%]\n",
      "5312 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7103%]\n",
      "5313 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7100%]\n",
      "5314 [Discriminator loss: 0.6949%, acc.: 50.39%][Generator loss: 0.7103%]\n",
      "5315 [Discriminator loss: 0.6947%, acc.: 49.61%][Generator loss: 0.7105%]\n",
      "5316 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7103%]\n",
      "5317 [Discriminator loss: 0.6949%, acc.: 47.66%][Generator loss: 0.7094%]\n",
      "5318 [Discriminator loss: 0.6951%, acc.: 46.48%][Generator loss: 0.7110%]\n",
      "5319 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7106%]\n",
      "5320 [Discriminator loss: 0.6959%, acc.: 50.00%][Generator loss: 0.7101%]\n",
      "5321 [Discriminator loss: 0.6947%, acc.: 49.61%][Generator loss: 0.7096%]\n",
      "5322 [Discriminator loss: 0.6952%, acc.: 48.83%][Generator loss: 0.7099%]\n",
      "5323 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7099%]\n",
      "5324 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7095%]\n",
      "5325 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7099%]\n",
      "5326 [Discriminator loss: 0.6949%, acc.: 48.05%][Generator loss: 0.7100%]\n",
      "5327 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7103%]\n",
      "5328 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7101%]\n",
      "5329 [Discriminator loss: 0.6941%, acc.: 48.83%][Generator loss: 0.7103%]\n",
      "5330 [Discriminator loss: 0.6942%, acc.: 51.56%][Generator loss: 0.7102%]\n",
      "5331 [Discriminator loss: 0.6961%, acc.: 50.00%][Generator loss: 0.7092%]\n",
      "5332 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7100%]\n",
      "5333 [Discriminator loss: 0.6949%, acc.: 48.44%][Generator loss: 0.7102%]\n",
      "5334 [Discriminator loss: 0.6940%, acc.: 50.00%][Generator loss: 0.7109%]\n",
      "5335 [Discriminator loss: 0.6940%, acc.: 49.61%][Generator loss: 0.7136%]\n",
      "5336 [Discriminator loss: 0.6985%, acc.: 48.05%][Generator loss: 0.7117%]\n",
      "5337 [Discriminator loss: 0.6958%, acc.: 51.17%][Generator loss: 0.7089%]\n",
      "5338 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7108%]\n",
      "5339 [Discriminator loss: 0.6944%, acc.: 51.17%][Generator loss: 0.7103%]\n",
      "5340 [Discriminator loss: 0.6949%, acc.: 49.22%][Generator loss: 0.7094%]\n",
      "5341 [Discriminator loss: 0.6942%, acc.: 50.78%][Generator loss: 0.7103%]\n",
      "5342 [Discriminator loss: 0.6951%, acc.: 48.44%][Generator loss: 0.7094%]\n",
      "5343 [Discriminator loss: 0.6952%, acc.: 50.78%][Generator loss: 0.7100%]\n",
      "5344 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7098%]\n",
      "5345 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7122%]\n",
      "5346 [Discriminator loss: 0.6956%, acc.: 49.61%][Generator loss: 0.7091%]\n",
      "5347 [Discriminator loss: 0.6951%, acc.: 49.61%][Generator loss: 0.7094%]\n",
      "5348 [Discriminator loss: 0.6943%, acc.: 50.00%][Generator loss: 0.7094%]\n",
      "5349 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7103%]\n",
      "5350 [Discriminator loss: 0.6948%, acc.: 51.95%][Generator loss: 0.7098%]\n",
      "5351 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7089%]\n",
      "5352 [Discriminator loss: 0.6947%, acc.: 50.39%][Generator loss: 0.7108%]\n",
      "5353 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7091%]\n",
      "5354 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7098%]\n",
      "5355 [Discriminator loss: 0.6945%, acc.: 50.78%][Generator loss: 0.7124%]\n",
      "5356 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7108%]\n",
      "5357 [Discriminator loss: 0.6955%, acc.: 49.22%][Generator loss: 0.7096%]\n",
      "5358 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7102%]\n",
      "5359 [Discriminator loss: 0.6951%, acc.: 48.83%][Generator loss: 0.7101%]\n",
      "5360 [Discriminator loss: 0.6953%, acc.: 51.17%][Generator loss: 0.7095%]\n",
      "5361 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7097%]\n",
      "5362 [Discriminator loss: 0.6946%, acc.: 48.44%][Generator loss: 0.7089%]\n",
      "5363 [Discriminator loss: 0.6945%, acc.: 50.78%][Generator loss: 0.7097%]\n",
      "5364 [Discriminator loss: 0.6947%, acc.: 50.39%][Generator loss: 0.7095%]\n",
      "5365 [Discriminator loss: 0.6944%, acc.: 50.00%][Generator loss: 0.7109%]\n",
      "5366 [Discriminator loss: 0.6953%, acc.: 49.61%][Generator loss: 0.7103%]\n",
      "5367 [Discriminator loss: 0.6952%, acc.: 50.39%][Generator loss: 0.7096%]\n",
      "5368 [Discriminator loss: 0.6944%, acc.: 50.00%][Generator loss: 0.7094%]\n",
      "5369 [Discriminator loss: 0.6952%, acc.: 46.88%][Generator loss: 0.7096%]\n",
      "5370 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7091%]\n",
      "5371 [Discriminator loss: 0.6942%, acc.: 49.61%][Generator loss: 0.7141%]\n",
      "5372 [Discriminator loss: 0.6970%, acc.: 49.22%][Generator loss: 0.7098%]\n",
      "5373 [Discriminator loss: 0.6953%, acc.: 50.78%][Generator loss: 0.7091%]\n",
      "5374 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7095%]\n",
      "5375 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7089%]\n",
      "5376 [Discriminator loss: 0.6941%, acc.: 50.00%][Generator loss: 0.7098%]\n",
      "5377 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7094%]\n",
      "5378 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7097%]\n",
      "5379 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7096%]\n",
      "5380 [Discriminator loss: 0.6946%, acc.: 48.44%][Generator loss: 0.7093%]\n",
      "5381 [Discriminator loss: 0.6956%, acc.: 48.44%][Generator loss: 0.7089%]\n",
      "5382 [Discriminator loss: 0.6950%, acc.: 48.05%][Generator loss: 0.7093%]\n",
      "5383 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7090%]\n",
      "5384 [Discriminator loss: 0.6945%, acc.: 48.44%][Generator loss: 0.7100%]\n",
      "5385 [Discriminator loss: 0.6949%, acc.: 50.39%][Generator loss: 0.7094%]\n",
      "5386 [Discriminator loss: 0.6945%, acc.: 51.56%][Generator loss: 0.7095%]\n",
      "5387 [Discriminator loss: 0.6956%, acc.: 47.66%][Generator loss: 0.7101%]\n",
      "5388 [Discriminator loss: 0.6959%, acc.: 49.22%][Generator loss: 0.7089%]\n",
      "5389 [Discriminator loss: 0.6958%, acc.: 50.00%][Generator loss: 0.7089%]\n",
      "5390 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7092%]\n",
      "5391 [Discriminator loss: 0.6950%, acc.: 48.05%][Generator loss: 0.7086%]\n",
      "5392 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7091%]\n",
      "5393 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7088%]\n",
      "5394 [Discriminator loss: 0.6950%, acc.: 49.22%][Generator loss: 0.7089%]\n",
      "5395 [Discriminator loss: 0.6950%, acc.: 48.05%][Generator loss: 0.7092%]\n",
      "5396 [Discriminator loss: 0.6954%, acc.: 51.17%][Generator loss: 0.7082%]\n",
      "5397 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7088%]\n",
      "5398 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7099%]\n",
      "5399 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7091%]\n",
      "5400 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7087%]\n",
      "5401 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7091%]\n",
      "5402 [Discriminator loss: 0.6949%, acc.: 49.22%][Generator loss: 0.7090%]\n",
      "5403 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7089%]\n",
      "5404 [Discriminator loss: 0.6944%, acc.: 50.39%][Generator loss: 0.7084%]\n",
      "5405 [Discriminator loss: 0.6948%, acc.: 48.83%][Generator loss: 0.7092%]\n",
      "5406 [Discriminator loss: 0.6964%, acc.: 48.44%][Generator loss: 0.7093%]\n",
      "5407 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7081%]\n",
      "5408 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7085%]\n",
      "5409 [Discriminator loss: 0.6947%, acc.: 46.09%][Generator loss: 0.7086%]\n",
      "5410 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7084%]\n",
      "5411 [Discriminator loss: 0.6944%, acc.: 48.83%][Generator loss: 0.7092%]\n",
      "5412 [Discriminator loss: 0.6956%, acc.: 46.88%][Generator loss: 0.7085%]\n",
      "5413 [Discriminator loss: 0.6956%, acc.: 50.00%][Generator loss: 0.7089%]\n",
      "5414 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7088%]\n",
      "5415 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7084%]\n",
      "5416 [Discriminator loss: 0.6942%, acc.: 50.00%][Generator loss: 0.7081%]\n",
      "5417 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7093%]\n",
      "5418 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7089%]\n",
      "5419 [Discriminator loss: 0.6946%, acc.: 48.05%][Generator loss: 0.7092%]\n",
      "5420 [Discriminator loss: 0.6951%, acc.: 50.00%][Generator loss: 0.7081%]\n",
      "5421 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7087%]\n",
      "5422 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7091%]\n",
      "5423 [Discriminator loss: 0.6946%, acc.: 49.61%][Generator loss: 0.7091%]\n",
      "5424 [Discriminator loss: 0.6948%, acc.: 50.39%][Generator loss: 0.7080%]\n",
      "5425 [Discriminator loss: 0.6944%, acc.: 48.83%][Generator loss: 0.7090%]\n",
      "5426 [Discriminator loss: 0.6952%, acc.: 48.83%][Generator loss: 0.7083%]\n",
      "5427 [Discriminator loss: 0.6949%, acc.: 49.22%][Generator loss: 0.7093%]\n",
      "5428 [Discriminator loss: 0.6955%, acc.: 48.83%][Generator loss: 0.7087%]\n",
      "5429 [Discriminator loss: 0.6959%, acc.: 44.53%][Generator loss: 0.7081%]\n",
      "5430 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7090%]\n",
      "5431 [Discriminator loss: 0.6953%, acc.: 50.00%][Generator loss: 0.7081%]\n",
      "5432 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7082%]\n",
      "5433 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7077%]\n",
      "5434 [Discriminator loss: 0.6940%, acc.: 50.00%][Generator loss: 0.7089%]\n",
      "5435 [Discriminator loss: 0.6951%, acc.: 48.44%][Generator loss: 0.7097%]\n",
      "5436 [Discriminator loss: 0.6948%, acc.: 51.17%][Generator loss: 0.7089%]\n",
      "5437 [Discriminator loss: 0.6947%, acc.: 49.61%][Generator loss: 0.7088%]\n",
      "5438 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7083%]\n",
      "5439 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7087%]\n",
      "5440 [Discriminator loss: 0.6950%, acc.: 47.66%][Generator loss: 0.7084%]\n",
      "5441 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7083%]\n",
      "5442 [Discriminator loss: 0.6947%, acc.: 48.44%][Generator loss: 0.7087%]\n",
      "5443 [Discriminator loss: 0.6951%, acc.: 49.61%][Generator loss: 0.7084%]\n",
      "5444 [Discriminator loss: 0.6952%, acc.: 48.83%][Generator loss: 0.7089%]\n",
      "5445 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7079%]\n",
      "5446 [Discriminator loss: 0.6944%, acc.: 50.00%][Generator loss: 0.7094%]\n",
      "5447 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7081%]\n",
      "5448 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7087%]\n",
      "5449 [Discriminator loss: 0.6948%, acc.: 46.88%][Generator loss: 0.7078%]\n",
      "5450 [Discriminator loss: 0.6943%, acc.: 48.44%][Generator loss: 0.7099%]\n",
      "5451 [Discriminator loss: 0.6972%, acc.: 49.22%][Generator loss: 0.7088%]\n",
      "5452 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7104%]\n",
      "5453 [Discriminator loss: 0.6943%, acc.: 50.00%][Generator loss: 0.7083%]\n",
      "5454 [Discriminator loss: 0.6944%, acc.: 50.00%][Generator loss: 0.7083%]\n",
      "5455 [Discriminator loss: 0.6955%, acc.: 50.00%][Generator loss: 0.7092%]\n",
      "5456 [Discriminator loss: 0.6947%, acc.: 50.39%][Generator loss: 0.7083%]\n",
      "5457 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7084%]\n",
      "5458 [Discriminator loss: 0.6946%, acc.: 49.61%][Generator loss: 0.7081%]\n",
      "5459 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7088%]\n",
      "5460 [Discriminator loss: 0.6955%, acc.: 50.78%][Generator loss: 0.7081%]\n",
      "5461 [Discriminator loss: 0.6955%, acc.: 46.88%][Generator loss: 0.7076%]\n",
      "5462 [Discriminator loss: 0.6952%, acc.: 50.00%][Generator loss: 0.7075%]\n",
      "5463 [Discriminator loss: 0.6941%, acc.: 49.22%][Generator loss: 0.7075%]\n",
      "5464 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7079%]\n",
      "5465 [Discriminator loss: 0.6944%, acc.: 50.00%][Generator loss: 0.7083%]\n",
      "5466 [Discriminator loss: 0.6942%, acc.: 50.00%][Generator loss: 0.7098%]\n",
      "5467 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7087%]\n",
      "5468 [Discriminator loss: 0.6943%, acc.: 50.00%][Generator loss: 0.7084%]\n",
      "5469 [Discriminator loss: 0.6953%, acc.: 46.88%][Generator loss: 0.7081%]\n",
      "5470 [Discriminator loss: 0.6948%, acc.: 49.61%][Generator loss: 0.7081%]\n",
      "5471 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7082%]\n",
      "5472 [Discriminator loss: 0.6949%, acc.: 49.61%][Generator loss: 0.7108%]\n",
      "5473 [Discriminator loss: 0.6959%, acc.: 51.17%][Generator loss: 0.7084%]\n",
      "5474 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7086%]\n",
      "5475 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7078%]\n",
      "5476 [Discriminator loss: 0.6946%, acc.: 49.61%][Generator loss: 0.7082%]\n",
      "5477 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7096%]\n",
      "5478 [Discriminator loss: 0.6952%, acc.: 49.61%][Generator loss: 0.7084%]\n",
      "5479 [Discriminator loss: 0.6949%, acc.: 48.83%][Generator loss: 0.7075%]\n",
      "5480 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7076%]\n",
      "5481 [Discriminator loss: 0.6943%, acc.: 49.22%][Generator loss: 0.7091%]\n",
      "5482 [Discriminator loss: 0.6947%, acc.: 51.56%][Generator loss: 0.7077%]\n",
      "5483 [Discriminator loss: 0.6947%, acc.: 51.17%][Generator loss: 0.7072%]\n",
      "5484 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7080%]\n",
      "5485 [Discriminator loss: 0.6944%, acc.: 50.00%][Generator loss: 0.7078%]\n",
      "5486 [Discriminator loss: 0.6951%, acc.: 49.22%][Generator loss: 0.7088%]\n",
      "5487 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7080%]\n",
      "5488 [Discriminator loss: 0.6951%, acc.: 48.83%][Generator loss: 0.7079%]\n",
      "5489 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7076%]\n",
      "5490 [Discriminator loss: 0.6942%, acc.: 49.61%][Generator loss: 0.7081%]\n",
      "5491 [Discriminator loss: 0.6946%, acc.: 50.39%][Generator loss: 0.7081%]\n",
      "5492 [Discriminator loss: 0.6947%, acc.: 47.66%][Generator loss: 0.7098%]\n",
      "5493 [Discriminator loss: 0.6957%, acc.: 50.39%][Generator loss: 0.7085%]\n",
      "5494 [Discriminator loss: 0.6949%, acc.: 50.39%][Generator loss: 0.7079%]\n",
      "5495 [Discriminator loss: 0.6946%, acc.: 48.44%][Generator loss: 0.7070%]\n",
      "5496 [Discriminator loss: 0.6961%, acc.: 45.70%][Generator loss: 0.7070%]\n",
      "5497 [Discriminator loss: 0.6949%, acc.: 50.00%][Generator loss: 0.7081%]\n",
      "5498 [Discriminator loss: 0.6943%, acc.: 50.39%][Generator loss: 0.7079%]\n",
      "5499 [Discriminator loss: 0.6945%, acc.: 48.05%][Generator loss: 0.7076%]\n",
      "5500 [Discriminator loss: 0.6943%, acc.: 50.00%][Generator loss: 0.7082%]\n",
      "5501 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7077%]\n",
      "5502 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7077%]\n",
      "5503 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7082%]\n",
      "5504 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7078%]\n",
      "5505 [Discriminator loss: 0.6955%, acc.: 48.05%][Generator loss: 0.7083%]\n",
      "5506 [Discriminator loss: 0.6945%, acc.: 50.39%][Generator loss: 0.7073%]\n",
      "5507 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7075%]\n",
      "5508 [Discriminator loss: 0.6942%, acc.: 49.61%][Generator loss: 0.7097%]\n",
      "5509 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7078%]\n",
      "5510 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7080%]\n",
      "5511 [Discriminator loss: 0.6944%, acc.: 50.00%][Generator loss: 0.7082%]\n",
      "5512 [Discriminator loss: 0.6946%, acc.: 50.78%][Generator loss: 0.7074%]\n",
      "5513 [Discriminator loss: 0.6946%, acc.: 48.44%][Generator loss: 0.7077%]\n",
      "5514 [Discriminator loss: 0.6942%, acc.: 50.00%][Generator loss: 0.7081%]\n",
      "5515 [Discriminator loss: 0.6954%, acc.: 50.00%][Generator loss: 0.7092%]\n",
      "5516 [Discriminator loss: 0.6954%, acc.: 51.56%][Generator loss: 0.7072%]\n",
      "5517 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7075%]\n",
      "5518 [Discriminator loss: 0.6945%, acc.: 49.61%][Generator loss: 0.7080%]\n",
      "5519 [Discriminator loss: 0.6932%, acc.: 52.73%][Generator loss: 0.7105%]\n",
      "5520 [Discriminator loss: 0.6967%, acc.: 49.22%][Generator loss: 0.7075%]\n",
      "5521 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7081%]\n",
      "5522 [Discriminator loss: 0.6946%, acc.: 48.83%][Generator loss: 0.7078%]\n",
      "5523 [Discriminator loss: 0.6954%, acc.: 44.92%][Generator loss: 0.7070%]\n",
      "5524 [Discriminator loss: 0.6950%, acc.: 47.66%][Generator loss: 0.7075%]\n",
      "5525 [Discriminator loss: 0.6944%, acc.: 48.05%][Generator loss: 0.7073%]\n",
      "5526 [Discriminator loss: 0.6947%, acc.: 51.95%][Generator loss: 0.7074%]\n",
      "5527 [Discriminator loss: 0.6939%, acc.: 50.00%][Generator loss: 0.7075%]\n",
      "5528 [Discriminator loss: 0.6950%, acc.: 50.00%][Generator loss: 0.7077%]\n",
      "5529 [Discriminator loss: 0.6946%, acc.: 49.61%][Generator loss: 0.7080%]\n",
      "5530 [Discriminator loss: 0.6953%, acc.: 49.61%][Generator loss: 0.7073%]\n",
      "5531 [Discriminator loss: 0.6949%, acc.: 49.22%][Generator loss: 0.7071%]\n",
      "5532 [Discriminator loss: 0.6941%, acc.: 50.00%][Generator loss: 0.7082%]\n",
      "5533 [Discriminator loss: 0.6945%, acc.: 50.00%][Generator loss: 0.7093%]\n",
      "5534 [Discriminator loss: 0.6957%, acc.: 50.00%][Generator loss: 0.7076%]\n",
      "5535 [Discriminator loss: 0.6946%, acc.: 50.00%][Generator loss: 0.7077%]\n",
      "5536 [Discriminator loss: 0.6946%, acc.: 51.17%][Generator loss: 0.7083%]\n",
      "5537 [Discriminator loss: 0.6942%, acc.: 49.61%][Generator loss: 0.7079%]\n",
      "5538 [Discriminator loss: 0.6951%, acc.: 49.22%][Generator loss: 0.7068%]\n",
      "5539 [Discriminator loss: 0.6948%, acc.: 50.00%][Generator loss: 0.7073%]\n",
      "5540 [Discriminator loss: 0.6943%, acc.: 48.44%][Generator loss: 0.7072%]\n",
      "5541 [Discriminator loss: 0.6947%, acc.: 50.00%][Generator loss: 0.7067%]\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# Build the generator\n",
    "generator = build_generator(latent_dim)\n",
    "# Generator input z\n",
    "z = Input(shape=(latent_dim,))\n",
    "generated_image = generator(z)\n",
    "# Only train the generator for the combined model\n",
    "discriminator.trainable = False\n",
    "# The discriminator takes generated image as input anddetermines validity\n",
    "real_or_fake = discriminator(generated_image)\n",
    "# Stack the generator and discriminator in a combined model\n",
    "# Trains the generator to deceive the discriminator\n",
    "combined = Model(z, real_or_fake)\n",
    "combined.compile(loss='binary_crossentropy')\n",
    "# train the GAN system\n",
    "train(generator=generator,\n",
    "discriminator=discriminator,\n",
    "combined=combined,\n",
    "steps=15000,\n",
    "batch_size=128)\n",
    "# display some random generated images\n",
    "plot_generated_images(generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284201b3cc239cfd635df38847d38b6d2619aa4e4648e35a57ab63af873cfc0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
